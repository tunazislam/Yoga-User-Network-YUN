{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x124a233f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "import spacy  # For preprocessing\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p  #pip install tweet-preprocessor\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation as punc\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "#from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.models as gsm\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import regex\n",
    "import emoji\n",
    "# Internal dependencies\n",
    "import word_emoji2vec as we2v\n",
    "#from word_emoji2vec import Word_Emoji2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed #python -m spacy download en\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## load embeddings #######\n",
    "#loc_emb = torch.load('data/locationEmbeddings.pt') \n",
    "#des_emb = torch.load('data/descriptionEmbeddings.pt') \n",
    "#twt_emb = torch.load('data/tweetsEmbeddings.pt') \n",
    "\n",
    "#load network embedding\n",
    "net_emb = gsm.KeyedVectors.load_word2vec_format('data/userNetworkEmd.emd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user = net_emb ['000mrs000']\n",
    "#print(user)\n",
    "#print(type(net_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load 1300 user location, description, yoga tweets, utype, umotivation\n",
    "df = pd.read_csv(\"data/yoga_user_name_loc_des_mergetweets_yoga_1300_lb.csv\") \n",
    "#print (df) #[1308 rows x 7 columns] name, location, description, text, utype, umotivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load train users and split into train and validation #######\n",
    "with open(\"data/train.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "random.seed(1)\n",
    "random.shuffle(data)\n",
    "\n",
    "train_data = data[:830] #80% train  \n",
    "#print(train_data, len(train_data)) #830\n",
    "valid_data = data[830:] #20% validation\n",
    "#print(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create Model \n",
    "class NetworkMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkMLP, self).__init__() \n",
    "        self.fc1 = nn.Linear(300, 150)       \n",
    "    def forward(self, X):\n",
    "        #print(X.size()) # torch.Size([300])\n",
    "        #print('resize', X.view(1,len(X)).size()) #resize torch.Size([1, 300])\n",
    "        z1 = self.fc1(X.view(1,len(X)))\n",
    "        #print('z1', z1, z1.size()) # torch.Size([1, 150])\n",
    "        h1 = F.relu(z1) \n",
    "        #logits = self.fc2(h1) #without attention\n",
    "        #print(\"logits\", logits, logits.size()) #torch.Size([1, 3])\n",
    "        #return logits \n",
    "        return h1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.model_des = BiLSTMDesAtt()\n",
    "        #self.model_loc = LSTMLoc()\n",
    "        self.model_net = NetworkMLP()\n",
    "        self.fc1 = nn.Linear(150, 200) \n",
    "        self.fc2 = nn.Linear(200, 3) \n",
    "\n",
    "    def forward(self, x_n): \n",
    "        #prediction_des = self.model_des(x_d)\n",
    "        #print(prediction_des, prediction_des.size()) #torch.Size([1, 3])\n",
    "        #prediction_loc = self.model_loc(x_l)\n",
    "        #print(prediction_loc, prediction_loc.size()) #torch.Size([1, 3])\n",
    "        prediction_net = self.model_net(x_n)\n",
    "        #print(prediction_net, prediction_net.size()) #torch.Size([1, 3])\n",
    "        #concat_pred = torch.cat((prediction_des, prediction_loc, prediction_net), 1) #concat with dim= 1\n",
    "        #print(concat_pred, concat_pred.size()) #torch.Size([1, 6])\n",
    "        out = self.fc1(prediction_net)\n",
    "        out = self.fc2(F.relu(out))\n",
    "        out = F.log_softmax(out, dim = 1)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare data for neural net #########\n",
    "def nn_input_network(train_data,df):\n",
    "    training_data =[]\n",
    "    for i in range (0, len(train_data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (train_data[i] == df.name[j]):\n",
    "                #print(train_data[i]) #print username\n",
    "                utype =  [int(df.utype[j])]\n",
    "                umotivation = [int(float(df.umotivation[j]))]\n",
    "                #print (\"net_emb[train_data[i]] : \", net_emb[train_data[i]], type(net_emb[train_data[i]]), torch.Tensor(net_emb[train_data[i]]), type(torch.Tensor(net_emb[train_data[i]])))\n",
    "                #count = 0\n",
    "                if(train_data[i] not in net_emb ):\n",
    "                    net_emb[train_data[i]] = np.zeros(300) #For users not appearing in the mention network, we set their network embedding vectors as 0.\n",
    "                    #count = count + 1\n",
    "                #print(count)\n",
    "                #print(net_emb[train_data[i]]) #ok\n",
    "                ####.....convert ndarray to torch.tensor........\n",
    "                net_emb_tensor = torch.Tensor(net_emb[train_data[i]])\n",
    "                #print(net_emb_tensor) #ok\n",
    "                training_data.append(net_emb_tensor)\n",
    "                break\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Ground Truth #########\n",
    "def find_groundtruth(data, df):\n",
    "    ground_truths = []\n",
    "    for i in range (0, len(data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (data[i] == df.name[j]):\n",
    "                #print(data[i]) #print username\n",
    "                utype =  [int(df.utype[j])]\n",
    "                umotivation = [int(float(df.umotivation[j]))]\n",
    "                target_type = torch.tensor(utype, dtype=torch.long) #for user type\n",
    "                #target_type = torch.tensor(umotivation, dtype=torch.long) #for user motivation\n",
    "                ground_truths.append(target_type)\n",
    "    return ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_tr(model, training_data_net, ground_truths):\n",
    "    predictions =[]\n",
    "    for i in range (0,len(training_data_net)):\n",
    "        prediction_joint = model(training_data_net[i])\n",
    "        \n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_net)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    return accuracy, macro_f1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_val(model, training_data_net, ground_truths):\n",
    "    predictions =[]\n",
    "    val_losses = []\n",
    "    loss_function = nn.NLLLoss()\n",
    "    for i in range (0,len(training_data_net)):\n",
    "        prediction_joint = model( training_data_net[i])\n",
    "        val_loss = loss_function(prediction_joint, ground_truths[i])\n",
    "        val_losses.append(val_loss.item())\n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_net)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    \n",
    "    #print(type(predictions), type(ground_truths))\n",
    "    #print(\"predictions\", predictions)\n",
    "    #print(\"ground_truths\", ground_truths)\n",
    "    \n",
    "    return accuracy, macro_f1, val_losses\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########......prepare training and validation data\n",
    "# ground truth training\n",
    "train_gt = find_groundtruth(train_data, df)\n",
    "#####prepare training data for neural net #########\n",
    "training_data_net =  nn_input_network(train_data,df)\n",
    "#print(training_data_net, len(training_data_net)) #ok\n",
    "#training_data_des, training_data_loc =  nn_input(train_data,df)\n",
    "\n",
    "# ground truth validation\n",
    "valid_gt = find_groundtruth(valid_data, df)\n",
    "#####prepare validation data for neural net #########\n",
    "validation_data_net =  nn_input_network(valid_data,df)\n",
    "#validation_data_des, validation_data_loc =  nn_input(valid_data,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Starting with epoch:  0 ***********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tunaz/miniconda2/envs/py3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 Train accuracy and macro_f1: 0.6036144578313253 0.4558922109179238\n",
      "epoch : 0 Validation accuracy, macro_f1: 0.6650485436893204 0.48774565596782765\n",
      "train loss per epoch 1.0758338004709727\n",
      "Validation loss per epoch: 1.0419460914088685\n",
      "*************** Starting with epoch:  1 ***********************\n",
      "epoch : 1 Train accuracy and macro_f1: 0.6385542168674698 0.48666187820510415\n",
      "epoch : 1 Validation accuracy, macro_f1: 0.7038834951456311 0.5193236714975845\n",
      "train loss per epoch 1.052294446007315\n",
      "Validation loss per epoch: 0.977743108006357\n",
      "*************** Starting with epoch:  2 ***********************\n",
      "epoch : 2 Train accuracy and macro_f1: 0.6493975903614457 0.4960339532449187\n",
      "epoch : 2 Validation accuracy, macro_f1: 0.7087378640776699 0.5245641531704108\n",
      "train loss per epoch 1.0232047599482248\n",
      "Validation loss per epoch: 0.8959736297431501\n",
      "*************** Starting with epoch:  3 ***********************\n",
      "epoch : 3 Train accuracy and macro_f1: 0.655421686746988 0.5019080455391102\n",
      "epoch : 3 Validation accuracy, macro_f1: 0.7135922330097088 0.5282945736434109\n",
      "train loss per epoch 0.9897199826068189\n",
      "Validation loss per epoch: 0.8134431404974855\n",
      "*************** Starting with epoch:  4 ***********************\n",
      "epoch : 4 Train accuracy and macro_f1: 0.6578313253012048 0.5039580658964484\n",
      "epoch : 4 Validation accuracy, macro_f1: 0.7087378640776699 0.525403954967042\n",
      "train loss per epoch 0.9567831285459449\n",
      "Validation loss per epoch: 0.7574674663613143\n",
      "*************** Starting with epoch:  5 ***********************\n",
      "epoch : 5 Train accuracy and macro_f1: 0.6578313253012048 0.5040148279022573\n",
      "epoch : 5 Validation accuracy, macro_f1: 0.7087378640776699 0.525403954967042\n",
      "train loss per epoch 0.9284023069832699\n",
      "Validation loss per epoch: 0.7302171790484085\n",
      "*************** Starting with epoch:  6 ***********************\n",
      "epoch : 6 Train accuracy and macro_f1: 0.6578313253012048 0.5040148279022573\n",
      "epoch : 6 Validation accuracy, macro_f1: 0.7087378640776699 0.525403954967042\n",
      "train loss per epoch 0.9053011159067925\n",
      "Validation loss per epoch: 0.7192583674366034\n",
      "*************** Starting with epoch:  7 ***********************\n",
      "epoch : 7 Train accuracy and macro_f1: 0.6578313253012048 0.504207478828691\n",
      "epoch : 7 Validation accuracy, macro_f1: 0.7087378640776699 0.525403954967042\n",
      "train loss per epoch 0.8866544968123178\n",
      "Validation loss per epoch: 0.7157352300523554\n",
      "*************** Starting with epoch:  8 ***********************\n",
      "epoch : 8 Train accuracy and macro_f1: 0.6578313253012048 0.5044022508900202\n",
      "epoch : 8 Validation accuracy, macro_f1: 0.7087378640776699 0.525403954967042\n",
      "train loss per epoch 0.8714348354732177\n",
      "Validation loss per epoch: 0.7154429942658804\n",
      "*************** Starting with epoch:  9 ***********************\n",
      "epoch : 9 Train accuracy and macro_f1: 0.6578313253012048 0.5044022508900202\n",
      "epoch : 9 Validation accuracy, macro_f1: 0.7087378640776699 0.525403954967042\n",
      "train loss per epoch 0.8587996555954577\n",
      "Validation loss per epoch: 0.7164786521670887\n",
      "*************** Starting with epoch:  10 ***********************\n",
      "epoch : 10 Train accuracy and macro_f1: 0.6590361445783133 0.5053689724331895\n",
      "epoch : 10 Validation accuracy, macro_f1: 0.7087378640776699 0.525403954967042\n",
      "train loss per epoch 0.8481157530764238\n",
      "Validation loss per epoch: 0.7180064693816657\n",
      "*************** Starting with epoch:  11 ***********************\n",
      "epoch : 11 Train accuracy and macro_f1: 0.6626506024096386 0.5082713208029664\n",
      "epoch : 11 Validation accuracy, macro_f1: 0.7038834951456311 0.5218449911373421\n",
      "train loss per epoch 0.8389159514722097\n",
      "Validation loss per epoch: 0.7196096439384719\n",
      "*************** Starting with epoch:  12 ***********************\n",
      "epoch : 12 Train accuracy and macro_f1: 0.6626506024096386 0.5082713208029664\n",
      "epoch : 12 Validation accuracy, macro_f1: 0.7038834951456311 0.5218449911373421\n",
      "train loss per epoch 0.8308645544834331\n",
      "Validation loss per epoch: 0.7211657701765449\n",
      "*************** Starting with epoch:  13 ***********************\n",
      "epoch : 13 Train accuracy and macro_f1: 0.6626506024096386 0.5082713208029664\n",
      "epoch : 13 Validation accuracy, macro_f1: 0.7038834951456311 0.5218449911373421\n",
      "train loss per epoch 0.8237112641437123\n",
      "Validation loss per epoch: 0.7226236043045822\n",
      "*************** Starting with epoch:  14 ***********************\n",
      "epoch : 14 Train accuracy and macro_f1: 0.6626506024096386 0.5084732536347296\n",
      "epoch : 14 Validation accuracy, macro_f1: 0.6990291262135923 0.5182648401826483\n",
      "train loss per epoch 0.8172664663183641\n",
      "Validation loss per epoch: 0.7239928722960277\n",
      "*************** Starting with epoch:  15 ***********************\n",
      "epoch : 15 Train accuracy and macro_f1: 0.6638554216867469 0.5096481387569858\n",
      "epoch : 15 Validation accuracy, macro_f1: 0.6990291262135923 0.5182648401826483\n",
      "train loss per epoch 0.8113896348480001\n",
      "Validation loss per epoch: 0.7253316756591056\n",
      "*************** Starting with epoch:  16 ***********************\n",
      "epoch : 16 Train accuracy and macro_f1: 0.6638554216867469 0.5096481387569858\n",
      "epoch : 16 Validation accuracy, macro_f1: 0.7038834951456311 0.5219941348973608\n",
      "train loss per epoch 0.8059726338028317\n",
      "Validation loss per epoch: 0.7266217201080137\n",
      "*************** Starting with epoch:  17 ***********************\n",
      "epoch : 17 Train accuracy and macro_f1: 0.6638554216867469 0.5096481387569858\n",
      "epoch : 17 Validation accuracy, macro_f1: 0.7038834951456311 0.5219941348973608\n",
      "train loss per epoch 0.8009309990598336\n",
      "Validation loss per epoch: 0.7278865464393375\n",
      "*************** Starting with epoch:  18 ***********************\n",
      "epoch : 18 Train accuracy and macro_f1: 0.6638554216867469 0.5096481387569858\n",
      "epoch : 18 Validation accuracy, macro_f1: 0.7087378640776699 0.5255824844865941\n",
      "train loss per epoch 0.7962008113999418\n",
      "Validation loss per epoch: 0.7291465547767658\n",
      "*************** Starting with epoch:  19 ***********************\n",
      "epoch : 19 Train accuracy and macro_f1: 0.6650602409638554 0.5106193511022958\n",
      "epoch : 19 Validation accuracy, macro_f1: 0.7087378640776699 0.5255824844865941\n",
      "train loss per epoch 0.791727669881769\n",
      "Validation loss per epoch: 0.7303697527612297\n",
      "*************** Starting with epoch:  20 ***********************\n",
      "epoch : 20 Train accuracy and macro_f1: 0.6662650602409639 0.5115909979552463\n",
      "epoch : 20 Validation accuracy, macro_f1: 0.7087378640776699 0.5255824844865941\n",
      "train loss per epoch 0.7874729532656557\n",
      "Validation loss per epoch: 0.7316495188810292\n",
      "*************** Starting with epoch:  21 ***********************\n",
      "epoch : 21 Train accuracy and macro_f1: 0.6674698795180722 0.512563091229758\n",
      "epoch : 21 Validation accuracy, macro_f1: 0.7087378640776699 0.5255824844865941\n",
      "train loss per epoch 0.7834061405173659\n",
      "Validation loss per epoch: 0.7330585136575606\n",
      "*************** Starting with epoch:  22 ***********************\n",
      "epoch : 22 Train accuracy and macro_f1: 0.6674698795180722 0.5157825547583929\n",
      "epoch : 22 Validation accuracy, macro_f1: 0.7135922330097088 0.5442434597432183\n",
      "train loss per epoch 0.7794985035815871\n",
      "Validation loss per epoch: 0.7345681842959043\n",
      "*************** Starting with epoch:  23 ***********************\n",
      "epoch : 23 Train accuracy and macro_f1: 0.6698795180722892 0.5231142912734953\n",
      "epoch : 23 Validation accuracy, macro_f1: 0.7135922330097088 0.5442434597432183\n",
      "train loss per epoch 0.7757296769494513\n",
      "Validation loss per epoch: 0.7361436541219359\n",
      "*************** Starting with epoch:  24 ***********************\n",
      "epoch : 24 Train accuracy and macro_f1: 0.6759036144578313 0.5439281529076948\n",
      "epoch : 24 Validation accuracy, macro_f1: 0.7087378640776699 0.5418488321714129\n",
      "train loss per epoch 0.7720823612442936\n",
      "Validation loss per epoch: 0.7377747556248915\n",
      "*************** Starting with epoch:  25 ***********************\n",
      "epoch : 25 Train accuracy and macro_f1: 0.6759036144578313 0.5441346433874504\n",
      "epoch : 25 Validation accuracy, macro_f1: 0.7038834951456311 0.5394586894586895\n",
      "train loss per epoch 0.7685415827559585\n",
      "Validation loss per epoch: 0.739494156200909\n",
      "*************** Starting with epoch:  26 ***********************\n",
      "epoch : 26 Train accuracy and macro_f1: 0.672289156626506 0.5421870545600508\n",
      "epoch : 26 Validation accuracy, macro_f1: 0.6941747572815534 0.5334843760623986\n",
      "train loss per epoch 0.7650943331410448\n",
      "Validation loss per epoch: 0.7412154188433897\n",
      "*************** Starting with epoch:  27 ***********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 27 Train accuracy and macro_f1: 0.6783132530120481 0.5589093322571119\n",
      "epoch : 27 Validation accuracy, macro_f1: 0.6893203883495146 0.5298755794428494\n",
      "train loss per epoch 0.761727435480348\n",
      "Validation loss per epoch: 0.7429947705523482\n",
      "*************** Starting with epoch:  28 ***********************\n",
      "epoch : 28 Train accuracy and macro_f1: 0.6831325301204819 0.5781981243211191\n",
      "epoch : 28 Validation accuracy, macro_f1: 0.6893203883495146 0.5298755794428494\n",
      "train loss per epoch 0.7584298468299758\n",
      "Validation loss per epoch: 0.7447995423402601\n",
      "*************** Starting with epoch:  29 ***********************\n",
      "epoch : 29 Train accuracy and macro_f1: 0.6867469879518072 0.5850819475250704\n",
      "epoch : 29 Validation accuracy, macro_f1: 0.6893203883495146 0.5298755794428494\n",
      "train loss per epoch 0.7551935161584352\n",
      "Validation loss per epoch: 0.7466699818094957\n"
     ]
    }
   ],
   "source": [
    "###########.........Start Training...........\n",
    "model = Net()\n",
    "##### Hyperparameter\n",
    "#learning_rate=0.005\n",
    "learning_rate=0.01\n",
    "epochs = 30\n",
    "#opt=\"ADAM\"\n",
    "#opt=\"SGD\" \n",
    "opt=\"ADA\"\n",
    "if(opt==\"SGD\"):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "elif(opt==\"ADA\"):\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=learning_rate, eps=1e-06, weight_decay=0.0001)\n",
    "elif(opt==\"ADAM\"):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "\n",
    "    \n",
    "loss_function = nn.NLLLoss()\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "check_val_acc = 0\n",
    "losses = []\n",
    "per_epoch_train_loss =[]\n",
    "per_epoch_val_loss =[]\n",
    "per_epoch_train_f1 =[]\n",
    "per_epoch_val_f1 = []\n",
    "for epoch in range(epochs): \n",
    "    print('*************** Starting with epoch: ', epoch, '***********************')\n",
    "    for i in range (0,len(train_data)):\n",
    "        #model_des.zero_grad()\n",
    "        #model_loc.zero_grad()\n",
    "        model.zero_grad()\n",
    "        #####Run forward pass.\n",
    "      \n",
    "        prediction_joint = model(training_data_net[i])\n",
    "        \n",
    "        #print(\"prediction_joint :\", torch.argmax(prediction_joint, dim=1)) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        #Compute the loss, gradients, and update the parameters by\n",
    "        #calling optimizer.step()\n",
    "        loss = loss_function(prediction_joint, train_gt[i])\n",
    "        #if (i%200 == 0):\n",
    "            #print (\"loss per example\", loss.item())\n",
    "        losses.append(loss.item())\n",
    "        loss.backward(retain_graph=True)  #backpropagation\n",
    "        optimizer.step()\n",
    "    accuracy, macro_f1 = make_prediction_tr(model, training_data_net, train_gt)\n",
    "    print('epoch :', epoch, 'Train accuracy and macro_f1:', accuracy, macro_f1)\n",
    "    per_epoch_train_f1.append(macro_f1)\n",
    "    val_accuracy, val_macro_f1, val_loss = make_prediction_val(model, validation_data_net, valid_gt)\n",
    "    per_epoch_val_f1.append(val_macro_f1)\n",
    "    print('epoch :', epoch, 'Validation accuracy, macro_f1:', val_accuracy, val_macro_f1)\n",
    "    per_epoch_train_loss.append(np.mean(losses))\n",
    "    print(\"train loss per epoch\", np.mean(losses))\n",
    "    per_epoch_val_loss.append(np.mean(val_loss))\n",
    "    print('Validation loss per epoch:', np.mean(val_loss))\n",
    "    \n",
    "    torch.save(model.state_dict(),\"data/Net_utype_2layer/Net_\"+str(epoch)+\".pt\")\n",
    "#     if (check_val_acc < val_macro_f1): #early stopping\n",
    "#         check_val_acc = val_macro_f1\n",
    "#         print (\"Model saved at epoch :\", epoch)\n",
    "#         torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "#         best_epoch = epoch\n",
    "        \n",
    "#print(\"Best model found at epoch : \", best_epoch)        \n",
    "#torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_plots(train_losses, val_losses, train_accs, test_accs):\n",
    "    \"\"\"Plot\n",
    "\n",
    "        Plot two figures: loss vs. epoch and accuracy vs. epoch\n",
    "    \"\"\"\n",
    "    n = len(train_losses)\n",
    "    xs = np.arange(n)\n",
    "\n",
    "    # plot losses\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_losses, '--', linewidth=2, label='train loss')\n",
    "    ax.plot(xs, val_losses, '-', linewidth=2, label='validation loss')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.savefig('loss_Net_utype.png')\n",
    "\n",
    "    # plot train and test accuracies\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_accs, '--', linewidth=2, label='train')\n",
    "    ax.plot(xs, test_accs, '-', linewidth=2, label='validation')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Macro-avg F1\")\n",
    "    ax.legend(loc='lower right')\n",
    "    plt.savefig('accuracy_Net_utype.png')\n",
    "    \n",
    "save_plots(per_epoch_train_loss, per_epoch_val_loss, per_epoch_train_f1, per_epoch_val_f1)\n",
    "# print(per_epoch_train_loss)\n",
    "# print(per_epoch_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction(training_data_net, ground_truths):\n",
    "    for epoch in range(0,30):\n",
    "        model = Net()\n",
    "        model.load_state_dict(torch.load(\"data/Net_utype_2layer/Net_\"+str(epoch)+\".pt\")) \n",
    "        predictions =[]\n",
    "        for i in range (0,len(training_data_net)):\n",
    "            prediction_joint = model(training_data_net[i])\n",
    "            pred = torch.argmax(prediction_joint, dim=1)\n",
    "            predictions.append(pred.item())\n",
    "        #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "        accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_net)\n",
    "        macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "        print('epoch :', epoch, 'Testing accuracy, macro_f1:', accuracy, macro_f1)\n",
    "        #return accuracy, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "########.....Load Test data.......\n",
    "with open(\"data/test.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "test_data = data[:] \n",
    "#print(test_data, len(test_data)) #262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare testing data for neural net #########\n",
    "testing_data_net =  nn_input_network(test_data,df)\n",
    "test_gt = find_groundtruth(test_data, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 Testing accuracy, macro_f1: 0.6984732824427481 0.49796152741889177\n",
      "epoch : 1 Testing accuracy, macro_f1: 0.7099236641221374 0.507791779075459\n",
      "epoch : 2 Testing accuracy, macro_f1: 0.7175572519083969 0.5139528275078148\n",
      "epoch : 3 Testing accuracy, macro_f1: 0.7213740458015268 0.5169694697253752\n",
      "epoch : 4 Testing accuracy, macro_f1: 0.7251908396946565 0.5199786470401163\n",
      "epoch : 5 Testing accuracy, macro_f1: 0.7251908396946565 0.5204708232596679\n",
      "epoch : 6 Testing accuracy, macro_f1: 0.7251908396946565 0.5204708232596679\n",
      "epoch : 7 Testing accuracy, macro_f1: 0.7290076335877863 0.5234609929078015\n",
      "epoch : 8 Testing accuracy, macro_f1: 0.7290076335877863 0.5236199033421823\n",
      "epoch : 9 Testing accuracy, macro_f1: 0.7290076335877863 0.5236199033421823\n",
      "epoch : 10 Testing accuracy, macro_f1: 0.7366412213740458 0.5295932138037401\n",
      "epoch : 11 Testing accuracy, macro_f1: 0.7404580152671756 0.5325713508181108\n",
      "epoch : 12 Testing accuracy, macro_f1: 0.7404580152671756 0.5325713508181108\n",
      "epoch : 13 Testing accuracy, macro_f1: 0.7404580152671756 0.5325713508181108\n",
      "epoch : 14 Testing accuracy, macro_f1: 0.7404580152671756 0.5325713508181108\n",
      "epoch : 15 Testing accuracy, macro_f1: 0.7404580152671756 0.5325713508181108\n",
      "epoch : 16 Testing accuracy, macro_f1: 0.7404580152671756 0.5325713508181108\n",
      "epoch : 17 Testing accuracy, macro_f1: 0.7442748091603053 0.5355442176870748\n",
      "epoch : 18 Testing accuracy, macro_f1: 0.7442748091603053 0.5355442176870748\n",
      "epoch : 19 Testing accuracy, macro_f1: 0.7404580152671756 0.5325713508181108\n",
      "epoch : 20 Testing accuracy, macro_f1: 0.7442748091603053 0.5355442176870748\n",
      "epoch : 21 Testing accuracy, macro_f1: 0.7442748091603053 0.5355442176870748\n",
      "epoch : 22 Testing accuracy, macro_f1: 0.7442748091603053 0.5353607510970507\n",
      "epoch : 23 Testing accuracy, macro_f1: 0.7519083969465649 0.55663631306181\n",
      "epoch : 24 Testing accuracy, macro_f1: 0.7519083969465649 0.55663631306181\n",
      "epoch : 25 Testing accuracy, macro_f1: 0.7519083969465649 0.55663631306181\n",
      "epoch : 26 Testing accuracy, macro_f1: 0.7519083969465649 0.5706480148227994\n",
      "epoch : 27 Testing accuracy, macro_f1: 0.7519083969465649 0.5706480148227994\n",
      "epoch : 28 Testing accuracy, macro_f1: 0.7480916030534351 0.5681522125291122\n",
      "epoch : 29 Testing accuracy, macro_f1: 0.7442748091603053 0.5778100528545974\n"
     ]
    }
   ],
   "source": [
    "make_prediction(testing_data_net, test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
