{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11b124490>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "import spacy  # For preprocessing\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p  #pip install tweet-preprocessor\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation as punc\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "#from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.models as gsm\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import regex\n",
    "import emoji\n",
    "# Internal dependencies\n",
    "import word_emoji2vec as we2v\n",
    "#from word_emoji2vec import Word_Emoji2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed #python -m spacy download en\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## load embeddings #######\n",
    "loc_emb = torch.load('data/locationEmbeddings.pt') \n",
    "des_emb = torch.load('data/descriptionEmbeddings.pt') \n",
    "twt_emb = torch.load('data/tweetsEmbeddings.pt') \n",
    "\n",
    "#load network embedding\n",
    "net_emb = gsm.KeyedVectors.load_word2vec_format('data/userNetworkEmd.emd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.keyedvectors.Word2VecKeyedVectors'>\n"
     ]
    }
   ],
   "source": [
    "#user = net_emb ['000mrs000']\n",
    "#print(user)\n",
    "print(type(net_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load 1300 user location, description, yoga tweets, utype, umotivation\n",
    "df = pd.read_csv(\"data/yoga_user_name_loc_des_mergetweets_yoga_1300_lb.csv\") \n",
    "#print (df) #[1308 rows x 7 columns] name, location, description, text, utype, umotivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load train users and split into train and validation #######\n",
    "with open(\"data/train.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "random.seed(1)\n",
    "random.shuffle(data)\n",
    "\n",
    "train_data = data[:830] #80% train  \n",
    "#print(train_data, len(train_data)) #830\n",
    "valid_data = data[830:] #20% validation\n",
    "#print(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create BiLSTMAttention Model for Description\n",
    "class BiLSTMDesAtt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiLSTMDesAtt, self).__init__() \n",
    "        self.lstm = nn.LSTM(300, 150//2 , num_layers=1, bidirectional=True ) #BiLSTM with attention \n",
    "        #self.lstm = nn.LSTM(300, 150 , num_layers=1, bidirectional=False) #LSTM with attention\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        self.hidden = self.init_hidden() # <- change here \n",
    "        self.attn_fc = torch.nn.Linear(300, 1) #attention layer\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        #(2*self.num_layers, batch_size, self.hidden_dim // 2)\n",
    "        return (torch.zeros(2 * 1, 1, 150//2), torch.zeros(2 * 1, 1, 150//2)) # <- change here: first dim of hidden needs to be doubled\n",
    "        #return (torch.zeros(1 * 1, 1, 150), torch.zeros(1 * 1, 1, 150))#LSTM with attention\n",
    "    def attention(self, rnn_out, state):\n",
    "        #print(\"rnn_out\", rnn_out.size()) #torch.Size([13, 1, 150])\n",
    "        #rnn_out = rnn_out.squeeze(0).unsqueeze(1) \n",
    "        #rnn_out = rnn_out.permute(2,0,1) \n",
    "        rnn_out = rnn_out.permute(1,0,2) \n",
    "        #print(\"permute rnn_out\", rnn_out.size()) #torch.Size([150, 13, 1])\n",
    "        #print(\"state\", state.size()) #torch.Size([2, 1, 75])\n",
    "        merged_state = torch.cat([s for s in state],1)\n",
    "        #print(\"merged_state\", merged_state.size()) #torch.Size([1, 150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).size()) #torch.Size([150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).size()) #torch.Size([150, 1])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).unsqueeze(2).size()) # torch.Size([150, 1, 1])\n",
    "        #merged_state = merged_state.squeeze(0).unsqueeze(2)\n",
    "        merged_state = merged_state.squeeze(0).unsqueeze(1).unsqueeze(2)\n",
    "        #print(\"merged_state2 :\", merged_state.size()) #torch.Size([150, 1, 1])\n",
    "        merged_state = merged_state.permute(1,0,2)\n",
    "        # (batch, seq_len, cell_size) * (batch, cell_size, 1) = (batch, seq_len, 1)\n",
    "        weights = torch.bmm(rnn_out, merged_state)\n",
    "        #print(\"weights\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        #weights = torch.nn.functional.softmax(weights.squeeze(2)).unsqueeze(2)\n",
    "        weights = F.log_softmax(weights.squeeze(2),dim = 1).unsqueeze(2)\n",
    "         #F.log_softmax(x, dim = 1)\n",
    "        #print(\"weights2 :\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        # (batch, cell_size, seq_len) * (batch, seq_len, 1) = (batch, cell_size, 1)\n",
    "        return torch.bmm(torch.transpose(rnn_out, 1, 2), weights).squeeze(2)\n",
    "    # end method attention\n",
    "\n",
    "    def forward(self, X):\n",
    "        #print(X.size()) # torch.Size([13, 300])\n",
    "        #print('resize', x.view(len(x),1,-1), x.view(len(x),1,-1).size()) #torch.Size([13, 1, 300])\n",
    "        lstm_out, hidden = self.lstm(X.view(len(X),1, -1))\n",
    "        #print('lstm_out', lstm_out, lstm_out.size()) # torch.Size([13, 1, 150])\n",
    "        #print('hidden[0] = h_n', hidden[0], hidden[0].size()) # torch.Size([2, 1, 75])\n",
    "        #print('hidden[1] = c_n', hidden[1], hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        h_n, c_n = hidden\n",
    "        #print('h_n', h_n, h_n.size()) # torch.Size([2, 1, 75])\n",
    "        #print('c_n', c_n, hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        attn_out = self.attention(lstm_out, h_n)\n",
    "        #print(\"attn_out\", attn_out.size()) #torch.Size([150, 1])\n",
    "        #logits = self.fc2(attn_out)\n",
    "        #logits = self.fc2(attn_out.permute(1,0))\n",
    "        #print(\"logits\", logits, logits.size())\n",
    "        #return logits \n",
    "        return attn_out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create BiLSTMAttention Model for Description\n",
    "class BiLSTMTwtAtt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiLSTMTwtAtt, self).__init__() \n",
    "        self.lstm = nn.LSTM(300, 150//2 , num_layers=1, bidirectional=True ) #BiLSTM with attention \n",
    "        #self.lstm = nn.LSTM(300, 150 , num_layers=1, bidirectional=False) #LSTM with attention\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        self.hidden = self.init_hidden() # <- change here \n",
    "        self.attn_fc = torch.nn.Linear(300, 1) #attention layer\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        #(2*self.num_layers, batch_size, self.hidden_dim // 2)\n",
    "        return (torch.zeros(2 * 1, 1, 150//2), torch.zeros(2 * 1, 1, 150//2)) # <- change here: first dim of hidden needs to be doubled\n",
    "        #return (torch.zeros(1 * 1, 1, 150), torch.zeros(1 * 1, 1, 150))#LSTM with attention\n",
    "    def attention(self, rnn_out, state):\n",
    "        #print(\"rnn_out\", rnn_out.size()) #torch.Size([13, 1, 150])\n",
    "        #rnn_out = rnn_out.squeeze(0).unsqueeze(1) \n",
    "        #rnn_out = rnn_out.permute(2,0,1) \n",
    "        rnn_out = rnn_out.permute(1,0,2) \n",
    "        #print(\"permute rnn_out\", rnn_out.size()) #torch.Size([150, 13, 1])\n",
    "        #print(\"state\", state.size()) #torch.Size([2, 1, 75])\n",
    "        merged_state = torch.cat([s for s in state],1)\n",
    "        #print(\"merged_state\", merged_state.size()) #torch.Size([1, 150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).size()) #torch.Size([150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).size()) #torch.Size([150, 1])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).unsqueeze(2).size()) # torch.Size([150, 1, 1])\n",
    "        #merged_state = merged_state.squeeze(0).unsqueeze(2)\n",
    "        merged_state = merged_state.squeeze(0).unsqueeze(1).unsqueeze(2)\n",
    "        #print(\"merged_state2 :\", merged_state.size()) #torch.Size([150, 1, 1])\n",
    "        merged_state = merged_state.permute(1,0,2)\n",
    "        # (batch, seq_len, cell_size) * (batch, cell_size, 1) = (batch, seq_len, 1)\n",
    "        weights = torch.bmm(rnn_out, merged_state)\n",
    "        #print(\"weights\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        #weights = torch.nn.functional.softmax(weights.squeeze(2)).unsqueeze(2)\n",
    "        weights = F.log_softmax(weights.squeeze(2),dim = 1).unsqueeze(2)\n",
    "         #F.log_softmax(x, dim = 1)\n",
    "        #print(\"weights2 :\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        # (batch, cell_size, seq_len) * (batch, seq_len, 1) = (batch, cell_size, 1)\n",
    "        return torch.bmm(torch.transpose(rnn_out, 1, 2), weights).squeeze(2)\n",
    "    # end method attention\n",
    "\n",
    "    def forward(self, X):\n",
    "        #print(X.size()) # torch.Size([13, 300])\n",
    "        #print('resize', x.view(len(x),1,-1), x.view(len(x),1,-1).size()) #torch.Size([13, 1, 300])\n",
    "        lstm_out, hidden = self.lstm(X.view(len(X),1, -1))\n",
    "        #print('lstm_out', lstm_out, lstm_out.size()) # torch.Size([13, 1, 150])\n",
    "        #print('hidden[0] = h_n', hidden[0], hidden[0].size()) # torch.Size([2, 1, 75])\n",
    "        #print('hidden[1] = c_n', hidden[1], hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        h_n, c_n = hidden\n",
    "        #print('h_n', h_n, h_n.size()) # torch.Size([2, 1, 75])\n",
    "        #print('c_n', c_n, hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        attn_out = self.attention(lstm_out, h_n)\n",
    "        #print(\"attn_out\", attn_out.size()) #torch.Size([150, 1])\n",
    "        #logits = self.fc2(attn_out)\n",
    "        #logits = self.fc2(attn_out.permute(1,0))\n",
    "        #print(\"logits\", logits, logits.size())\n",
    "        #return logits \n",
    "        return attn_out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create LSTM Model for Location #############\n",
    "class LSTMLoc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMLoc, self).__init__()\n",
    "        self.lstm = nn.LSTM(300, 150, num_layers=1)\n",
    "        self.fc2 = nn.Linear(150, 50) \n",
    "        self.hidden = self.init_hidden() # <- change here \n",
    "\n",
    "    def init_hidden(self):\n",
    "        #(2*self.num_layers, batch_size, self.hidden_dim // 2)# <- change here: first dim of hidden needs to be doubled\n",
    "        return (torch.zeros(1, 1, 150), torch.zeros(1, 1, 150)) \n",
    "    def forward(self, x):\n",
    "        #x=embeds.permute(1,0,2)\n",
    "        #print('resize', x.view(len(x),1,-1), x.view(len(x),1,-1).size()) #torch.Size([13, 1, 300])\n",
    "        #lstm_out, self.hidden = self.lstm(x.view(len(x),1, -1), self.hidden)\n",
    "        lstm_out, _ = self.lstm(x.view(len(x),1, -1))\n",
    "        #lstm_out, _ = self.lstm(x.view(len(x),1,-1)) \n",
    "        #print('lstm_out', lstm_out, lstm_out.size()) # torch.Size([13, 1, 150])\n",
    "        #print('self.hidden[0]', self.hidden[0], self.hidden[0].size()) # torch.Size([1, 1, 150])\n",
    "        #print(\"lstm_out[-1]\", lstm_out[-1], lstm_out[-1].size())  # torch.Size([1, 150])\n",
    "        #x = self.fc2(lstm_out[-1])  \n",
    "        #out = F.log_softmax(x, dim = 1)\n",
    "        #return out\n",
    "        #return x\n",
    "        return lstm_out[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create Model \n",
    "class NetworkMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkMLP, self).__init__() \n",
    "        self.fc1 = nn.Linear(300, 150)\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #print(X.size()) # torch.Size([300])\n",
    "        #print('resize', X.view(1,len(X)).size()) #resize torch.Size([1, 300])\n",
    "        z1 = self.fc1(X.view(1,len(X)))\n",
    "        #print('z1', z1, z1.size()) # torch.Size([1, 150])\n",
    "        h1 = F.relu(z1)\n",
    "        return h1\n",
    "        #logits = self.fc2(h1) #without attention\n",
    "        #print(\"logits\", logits, logits.size()) #torch.Size([1, 3])\n",
    "        #return logits \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointDLTN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JointDLTN, self).__init__()\n",
    "        self.model_des = BiLSTMDesAtt()\n",
    "        self.model_loc = LSTMLoc()\n",
    "        #self.model_twt = BiLSTMDesAtt()\n",
    "        self.model_twt = BiLSTMTwtAtt()\n",
    "        self.model_net = NetworkMLP()\n",
    "        #self.fc = nn.Linear(200, 3) #4*50 = 150\n",
    "        self.fc1 = nn.Linear(600, 200) #4*150 = 600\n",
    "        self.fc2 = nn.Linear(200, 3)\n",
    "#        self.fc1 = nn.Linear(600, 3)\n",
    "    def forward(self, x_d, x_l, x_t, x_n): \n",
    "        prediction_des = self.model_des(x_d)\n",
    "        #print(prediction_des, prediction_des.size())\n",
    "        prediction_loc = self.model_loc(x_l)\n",
    "        #print(prediction_loc, prediction_loc.size())\n",
    "        prediction_twt = self.model_twt(x_t)\n",
    "        prediction_net = self.model_net(x_n)\n",
    "        concat_pred = torch.cat((prediction_des, prediction_loc, prediction_twt, prediction_net), 1) #concat with dim= 1\n",
    "        #print(concat_pred, concat_pred.size()) \n",
    "#         out = F.log_softmax(self.fc(concat_pred), dim = 1)\n",
    "#         return out\n",
    "        out = self.fc1(concat_pred)\n",
    "        out = self.fc2(F.relu(out))\n",
    "        out = F.log_softmax(out, dim = 1)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare data for neural net input #########\n",
    "def nn_input(train_data,df):\n",
    "    #ground_truths = []\n",
    "    training_data_des =[]\n",
    "    training_data_loc=[]\n",
    "    training_data_twt =[]\n",
    "    for i in range (0, len(train_data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (train_data[i] == df.name[j]):\n",
    "                if (not des_emb[train_data[i]]) and (not loc_emb[train_data[i]]) and (twt_emb[train_data[i]]):\n",
    "                    print ('no description and location for user: ', train_data[i])\n",
    "                    training_data_des.append(torch.zeros(1, 300))\n",
    "                    training_data_loc.append(torch.zeros(1, 300))\n",
    "                    sent_tensor_twt = torch.stack(twt_emb[train_data[i]],dim = 1)\n",
    "                    training_data_twt.append(sent_tensor_twt[-1])\n",
    "                    break\n",
    "                \n",
    "                elif (des_emb[train_data[i]]) and (not loc_emb[train_data[i]]) and (twt_emb[train_data[i]]): \n",
    "                    print ('no location for user: ', train_data[i])\n",
    "                    sent_tensor_des = torch.stack(des_emb[train_data[i]],dim = 1)\n",
    "                    training_data_des.append(sent_tensor_des[-1])\n",
    "                    training_data_loc.append(torch.zeros(1, 300))\n",
    "                    sent_tensor_twt = torch.stack(twt_emb[train_data[i]],dim = 1)\n",
    "                    training_data_twt.append(sent_tensor_twt[-1])\n",
    "                    break\n",
    "                    \n",
    "                elif (not des_emb[train_data[i]]) and (loc_emb[train_data[i]]) and (twt_emb[train_data[i]]): \n",
    "                    print ('no description for user: ', train_data[i])\n",
    "                    training_data_des.append(torch.zeros(1, 300))\n",
    "                    sent_tensor_loc = torch.stack(loc_emb[train_data[i]],dim = 1)\n",
    "                    training_data_loc.append(sent_tensor_loc[-1])\n",
    "                    sent_tensor_twt = torch.stack(twt_emb[train_data[i]],dim = 1)\n",
    "                    training_data_twt.append(sent_tensor_twt[-1])\n",
    "                    break    \n",
    "               \n",
    "                elif (des_emb[train_data[i]]) and (loc_emb[train_data[i]]) and (twt_emb[train_data[i]]): \n",
    "                    sent_tensor_des = torch.stack(des_emb[train_data[i]],dim = 1)\n",
    "                    training_data_des.append(sent_tensor_des[-1])\n",
    "                    sent_tensor_loc = torch.stack(loc_emb[train_data[i]],dim = 1)\n",
    "                    training_data_loc.append(sent_tensor_loc[-1])\n",
    "                    sent_tensor_twt = torch.stack(twt_emb[train_data[i]],dim = 1)\n",
    "                    training_data_twt.append(sent_tensor_twt[-1])\n",
    "                    break\n",
    "    return training_data_des, training_data_loc, training_data_twt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare data for neural net #########\n",
    "def nn_input_network(train_data,df):\n",
    "    training_data =[]\n",
    "    for i in range (0, len(train_data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (train_data[i] == df.name[j]):\n",
    "                #print(train_data[i]) #print username\n",
    "                utype =  [int(df.utype[j])]\n",
    "                umotivation = [int(float(df.umotivation[j]))]\n",
    "                #print (\"net_emb[train_data[i]] : \", net_emb[train_data[i]], type(net_emb[train_data[i]]), torch.Tensor(net_emb[train_data[i]]), type(torch.Tensor(net_emb[train_data[i]])))\n",
    "                #count = 0\n",
    "                if(train_data[i] not in net_emb ):\n",
    "                    net_emb[train_data[i]] = np.zeros(300) #For users not appearing in the mention network, we set their network embedding vectors as 0.\n",
    "                    #count = count + 1\n",
    "                #print(count)\n",
    "                #print(net_emb[train_data[i]]) #ok\n",
    "                ####.....convert ndarray to torch.tensor........\n",
    "                net_emb_tensor = torch.Tensor(net_emb[train_data[i]])\n",
    "                #print(net_emb_tensor) #ok\n",
    "                training_data.append(net_emb_tensor)\n",
    "                break\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Ground Truth #########\n",
    "def find_groundtruth(data, df):\n",
    "    ground_truths = []\n",
    "    for i in range (0, len(data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (data[i] == df.name[j]):\n",
    "                #print(data[i]) #print username\n",
    "                utype =  [int(df.utype[j])]\n",
    "                umotivation = [int(float(df.umotivation[j]))]\n",
    "                target_type = torch.tensor(utype, dtype=torch.long) #for user type\n",
    "                #target_type = torch.tensor(umotivation, dtype=torch.long) #for user motivation\n",
    "                ground_truths.append(target_type)\n",
    "    return ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_tr(model, training_data_des, training_data_loc, training_data_twt, training_data_net, ground_truths):\n",
    "    predictions =[]\n",
    "    for i in range (0,len(training_data_des)):\n",
    "        prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_twt[i], training_data_net[i])\n",
    "        \n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_des)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    \n",
    "    return accuracy, macro_f1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_val(model, training_data_des, training_data_loc, training_data_twt, training_data_net, ground_truths):\n",
    "    predictions =[]\n",
    "    val_losses = []\n",
    "    loss_function = nn.NLLLoss()\n",
    "    for i in range (0,len(training_data_des)):\n",
    "        prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_twt[i], training_data_net[i])\n",
    "        val_loss = loss_function(prediction_joint, ground_truths[i])\n",
    "        val_losses.append(val_loss.item())\n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_des)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    \n",
    "    return accuracy, macro_f1, val_losses\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no description for user:  bchi49\n",
      "no location for user:  Christoph_Tran\n",
      "no description for user:  viecestlavie\n",
      "no description for user:  crystalization_\n",
      "no location for user:  yogitimesonline\n",
      "no description for user:  mimmosamami\n",
      "no description for user:  wenmarbyoga\n",
      "no location for user:  cipherEquality\n",
      "no description for user:  YogaLifeLine\n",
      "no location for user:  thewaywecame\n"
     ]
    }
   ],
   "source": [
    "##########......prepare training and validation data\n",
    "# ground truth training\n",
    "train_gt = find_groundtruth(train_data, df)\n",
    "#####prepare training data for neural net #########\n",
    "training_data_net =  nn_input_network(train_data,df)\n",
    "#print(training_data_net, len(training_data_net)) #ok\n",
    "training_data_des, training_data_loc, training_data_twt =  nn_input(train_data,df)\n",
    "\n",
    "# ground truth validation\n",
    "valid_gt = find_groundtruth(valid_data, df)\n",
    "#####prepare validation data for neural net #########\n",
    "validation_data_net =  nn_input_network(valid_data,df)\n",
    "validation_data_des, validation_data_loc, validation_data_twt =  nn_input(valid_data,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Starting with epoch:  0 ***********************\n",
      "epoch : 0 Train accuracy and macro_f1: 0.6168674698795181 0.6070941304656783\n",
      "epoch : 0 Validation accuracy, macro_f1: 0.558252427184466 0.5382135724104044\n",
      "train loss per epoch 1.0803689160978938\n",
      "Validation loss per epoch: 1.0206916216507698\n",
      "*************** Starting with epoch:  1 ***********************\n",
      "epoch : 1 Train accuracy and macro_f1: 0.6759036144578313 0.6681920510413196\n",
      "epoch : 1 Validation accuracy, macro_f1: 0.5922330097087378 0.5760117374930703\n",
      "train loss per epoch 0.9565686763051044\n",
      "Validation loss per epoch: 0.9245513527138719\n",
      "*************** Starting with epoch:  2 ***********************\n",
      "epoch : 2 Train accuracy and macro_f1: 0.7024096385542169 0.6969749495072196\n",
      "epoch : 2 Validation accuracy, macro_f1: 0.5922330097087378 0.576710285571045\n",
      "train loss per epoch 0.8853422805487391\n",
      "Validation loss per epoch: 0.8783109355898737\n",
      "*************** Starting with epoch:  3 ***********************\n",
      "epoch : 3 Train accuracy and macro_f1: 0.7265060240963855 0.721324740679769\n",
      "epoch : 3 Validation accuracy, macro_f1: 0.6407766990291263 0.6258796968230931\n",
      "train loss per epoch 0.835602098667478\n",
      "Validation loss per epoch: 0.8348645643123145\n",
      "*************** Starting with epoch:  4 ***********************\n",
      "epoch : 4 Train accuracy and macro_f1: 0.7373493975903614 0.7322384523667695\n",
      "epoch : 4 Validation accuracy, macro_f1: 0.6504854368932039 0.6377517868745939\n",
      "train loss per epoch 0.7975858098340322\n",
      "Validation loss per epoch: 0.8112508232153736\n",
      "*************** Starting with epoch:  5 ***********************\n",
      "epoch : 5 Train accuracy and macro_f1: 0.7493975903614458 0.7459089949177763\n",
      "epoch : 5 Validation accuracy, macro_f1: 0.6553398058252428 0.6424910393262097\n",
      "train loss per epoch 0.7665050681096962\n",
      "Validation loss per epoch: 0.7998183282833655\n",
      "*************** Starting with epoch:  6 ***********************\n",
      "epoch : 6 Train accuracy and macro_f1: 0.7650602409638554 0.7619712839804147\n",
      "epoch : 6 Validation accuracy, macro_f1: 0.6699029126213593 0.6568715957991033\n",
      "train loss per epoch 0.7401163940995983\n",
      "Validation loss per epoch: 0.793105315236212\n",
      "*************** Starting with epoch:  7 ***********************\n",
      "epoch : 7 Train accuracy and macro_f1: 0.7734939759036145 0.7707727625909445\n",
      "epoch : 7 Validation accuracy, macro_f1: 0.6747572815533981 0.6616472851766969\n",
      "train loss per epoch 0.7170856194323804\n",
      "Validation loss per epoch: 0.7883351647738114\n",
      "*************** Starting with epoch:  8 ***********************\n",
      "epoch : 8 Train accuracy and macro_f1: 0.7831325301204819 0.7811468340356633\n",
      "epoch : 8 Validation accuracy, macro_f1: 0.6747572815533981 0.6617260629253776\n",
      "train loss per epoch 0.6966791771821069\n",
      "Validation loss per epoch: 0.7907096784091691\n",
      "*************** Starting with epoch:  9 ***********************\n",
      "epoch : 9 Train accuracy and macro_f1: 0.7891566265060241 0.7873369890365606\n",
      "epoch : 9 Validation accuracy, macro_f1: 0.6699029126213593 0.6568491120273802\n",
      "train loss per epoch 0.6782580372224372\n",
      "Validation loss per epoch: 0.7958266040653859\n",
      "*************** Starting with epoch:  10 ***********************\n",
      "epoch : 10 Train accuracy and macro_f1: 0.7951807228915663 0.7934571122302693\n",
      "epoch : 10 Validation accuracy, macro_f1: 0.6699029126213593 0.6568715957991033\n",
      "train loss per epoch 0.6615153409434567\n",
      "Validation loss per epoch: 0.8013807882383032\n",
      "*************** Starting with epoch:  11 ***********************\n",
      "epoch : 11 Train accuracy and macro_f1: 0.7975903614457831 0.795922487989742\n",
      "epoch : 11 Validation accuracy, macro_f1: 0.6699029126213593 0.6568715957991033\n",
      "train loss per epoch 0.6461909484911157\n",
      "Validation loss per epoch: 0.8039941666195694\n",
      "*************** Starting with epoch:  12 ***********************\n",
      "epoch : 12 Train accuracy and macro_f1: 0.8060240963855422 0.8045115007837002\n",
      "epoch : 12 Validation accuracy, macro_f1: 0.6747572815533981 0.661692769350927\n",
      "train loss per epoch 0.63206445031745\n",
      "Validation loss per epoch: 0.8103378953285587\n",
      "*************** Starting with epoch:  13 ***********************\n",
      "epoch : 13 Train accuracy and macro_f1: 0.8072289156626506 0.8055829476475102\n",
      "epoch : 13 Validation accuracy, macro_f1: 0.6796116504854369 0.6675660426492289\n",
      "train loss per epoch 0.6189529276961099\n",
      "Validation loss per epoch: 0.8174901731963297\n",
      "*************** Starting with epoch:  14 ***********************\n",
      "epoch : 14 Train accuracy and macro_f1: 0.8048192771084337 0.8029754559166324\n",
      "epoch : 14 Validation accuracy, macro_f1: 0.6844660194174758 0.6733733473767236\n",
      "train loss per epoch 0.6066795147853683\n",
      "Validation loss per epoch: 0.8254982152031464\n",
      "*************** Starting with epoch:  15 ***********************\n",
      "epoch : 15 Train accuracy and macro_f1: 0.810843373493976 0.8085690314773252\n",
      "epoch : 15 Validation accuracy, macro_f1: 0.6844660194174758 0.6742265688042718\n",
      "train loss per epoch 0.5951167579785169\n",
      "Validation loss per epoch: 0.8392813066834385\n",
      "*************** Starting with epoch:  16 ***********************\n",
      "epoch : 16 Train accuracy and macro_f1: 0.8180722891566266 0.8159356934831604\n",
      "epoch : 16 Validation accuracy, macro_f1: 0.6844660194174758 0.6742265688042718\n",
      "train loss per epoch 0.5842727242168343\n",
      "Validation loss per epoch: 0.849577343000949\n",
      "*************** Starting with epoch:  17 ***********************\n",
      "epoch : 17 Train accuracy and macro_f1: 0.8240963855421687 0.8223733538674116\n",
      "epoch : 17 Validation accuracy, macro_f1: 0.6941747572815534 0.6844130667515408\n",
      "train loss per epoch 0.5740203969609466\n",
      "Validation loss per epoch: 0.8555820601657756\n",
      "*************** Starting with epoch:  18 ***********************\n",
      "epoch : 18 Train accuracy and macro_f1: 0.8289156626506025 0.8268640466906122\n",
      "epoch : 18 Validation accuracy, macro_f1: 0.6893203883495146 0.6804570983992875\n",
      "train loss per epoch 0.5642503486529286\n",
      "Validation loss per epoch: 0.8697542681277377\n",
      "*************** Starting with epoch:  19 ***********************\n",
      "epoch : 19 Train accuracy and macro_f1: 0.8337349397590361 0.8314643808577303\n",
      "epoch : 19 Validation accuracy, macro_f1: 0.6844660194174758 0.6756010396361273\n",
      "train loss per epoch 0.5549622313085809\n",
      "Validation loss per epoch: 0.8800561989395363\n",
      "*************** Starting with epoch:  20 ***********************\n",
      "epoch : 20 Train accuracy and macro_f1: 0.8349397590361446 0.8325962427705771\n",
      "epoch : 20 Validation accuracy, macro_f1: 0.6941747572815534 0.6852335551957788\n",
      "train loss per epoch 0.5460434235380219\n",
      "Validation loss per epoch: 0.9026512474689669\n",
      "*************** Starting with epoch:  21 ***********************\n",
      "epoch : 21 Train accuracy and macro_f1: 0.8409638554216867 0.8385874137723378\n",
      "epoch : 21 Validation accuracy, macro_f1: 0.6941747572815534 0.6853198653198653\n",
      "train loss per epoch 0.5375058320435611\n",
      "Validation loss per epoch: 0.9197756289278419\n",
      "*************** Starting with epoch:  22 ***********************\n",
      "epoch : 22 Train accuracy and macro_f1: 0.8421686746987952 0.8397843085677218\n",
      "epoch : 22 Validation accuracy, macro_f1: 0.6941747572815534 0.6862862978716109\n",
      "train loss per epoch 0.5292961635784431\n",
      "Validation loss per epoch: 0.9320829146116683\n",
      "*************** Starting with epoch:  23 ***********************\n",
      "epoch : 23 Train accuracy and macro_f1: 0.8409638554216867 0.8387954071551743\n",
      "epoch : 23 Validation accuracy, macro_f1: 0.7038834951456311 0.6961873896114001\n",
      "train loss per epoch 0.5214338304647002\n",
      "Validation loss per epoch: 0.9430075316753203\n",
      "*************** Starting with epoch:  24 ***********************\n",
      "epoch : 24 Train accuracy and macro_f1: 0.846987951807229 0.8447593800534977\n",
      "epoch : 24 Validation accuracy, macro_f1: 0.7038834951456311 0.6961873896114001\n",
      "train loss per epoch 0.5138665950930262\n",
      "Validation loss per epoch: 0.9605358552585528\n",
      "*************** Starting with epoch:  25 ***********************\n",
      "epoch : 25 Train accuracy and macro_f1: 0.8481927710843373 0.845984200095161\n",
      "epoch : 25 Validation accuracy, macro_f1: 0.6990291262135923 0.6912652844231791\n",
      "train loss per epoch 0.5065309161107997\n",
      "Validation loss per epoch: 0.9711324468399715\n",
      "*************** Starting with epoch:  26 ***********************\n",
      "epoch : 26 Train accuracy and macro_f1: 0.8481927710843373 0.8459075582503649\n",
      "epoch : 26 Validation accuracy, macro_f1: 0.6990291262135923 0.6912387884573316\n",
      "train loss per epoch 0.49946468744305617\n",
      "Validation loss per epoch: 0.9885604294758399\n",
      "*************** Starting with epoch:  27 ***********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 27 Train accuracy and macro_f1: 0.8506024096385543 0.8481508265217422\n",
      "epoch : 27 Validation accuracy, macro_f1: 0.6941747572815534 0.6863432025550343\n",
      "train loss per epoch 0.4926108660224485\n",
      "Validation loss per epoch: 1.002454172494342\n",
      "*************** Starting with epoch:  28 ***********************\n",
      "epoch : 28 Train accuracy and macro_f1: 0.8518072289156626 0.849225649535765\n",
      "epoch : 28 Validation accuracy, macro_f1: 0.6990291262135923 0.6902899139741244\n",
      "train loss per epoch 0.4859460501049037\n",
      "Validation loss per epoch: 1.0188604661272567\n",
      "*************** Starting with epoch:  29 ***********************\n",
      "epoch : 29 Train accuracy and macro_f1: 0.8530120481927711 0.8503537204861487\n",
      "epoch : 29 Validation accuracy, macro_f1: 0.6941747572815534 0.6859428730729205\n",
      "train loss per epoch 0.47946176159633214\n",
      "Validation loss per epoch: 1.0409411987633381\n"
     ]
    }
   ],
   "source": [
    "###########.........Start Training...........\n",
    "model = JointDLTN()\n",
    "##### Hyperparameter\n",
    "learning_rate=0.01\n",
    "epochs = 30\n",
    "#opt=\"ADAM\"\n",
    "#opt=\"SGD\" \n",
    "opt=\"ADA\"\n",
    "if(opt==\"SGD\"):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "elif(opt==\"ADA\"):\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=learning_rate, eps=1e-06, weight_decay=0.0001)\n",
    "elif(opt==\"ADAM\"):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "\n",
    "    \n",
    "loss_function = nn.NLLLoss()\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "check_val_acc = 0\n",
    "losses = []\n",
    "per_epoch_train_loss =[]\n",
    "per_epoch_val_loss =[]\n",
    "per_epoch_train_f1 =[]\n",
    "per_epoch_val_f1 = []\n",
    "for epoch in range(epochs): \n",
    "    print('*************** Starting with epoch: ', epoch, '***********************')\n",
    "    for i in range (0,len(train_data)):\n",
    "        #model_des.zero_grad()\n",
    "        #model_loc.zero_grad()\n",
    "        model.zero_grad()\n",
    "        #####Run forward pass.\n",
    "      \n",
    "        prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_twt[i], training_data_net[i])\n",
    "        \n",
    "        #print(\"prediction_joint :\", torch.argmax(prediction_joint, dim=1)) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        #Compute the loss, gradients, and update the parameters by\n",
    "        #calling optimizer.step()\n",
    "        loss = loss_function(prediction_joint, train_gt[i])\n",
    "        #if (i%200 == 0):\n",
    "            #print (\"loss per example\", loss.item())\n",
    "        losses.append(loss.item())\n",
    "        loss.backward(retain_graph=True)  #backpropagation\n",
    "        optimizer.step()\n",
    "    accuracy, macro_f1 = make_prediction_tr(model, training_data_des, training_data_loc, training_data_twt, training_data_net, train_gt)\n",
    "    print('epoch :', epoch, 'Train accuracy and macro_f1:', accuracy, macro_f1)\n",
    "    per_epoch_train_f1.append(macro_f1)\n",
    "    val_accuracy, val_macro_f1, val_loss = make_prediction_val(model, validation_data_des, validation_data_loc, validation_data_twt, validation_data_net, valid_gt)\n",
    "    per_epoch_val_f1.append(val_macro_f1)\n",
    "    print('epoch :', epoch, 'Validation accuracy, macro_f1:', val_accuracy, val_macro_f1)\n",
    "    per_epoch_train_loss.append(np.mean(losses))\n",
    "    print(\"train loss per epoch\", np.mean(losses))\n",
    "    per_epoch_val_loss.append(np.mean(val_loss))\n",
    "    print('Validation loss per epoch:', np.mean(val_loss))\n",
    "    torch.save(model.state_dict(),\"data/DLTN_utype_2layer/joint_DLTN_\"+str(epoch)+\".pt\")\n",
    "#     if (check_val_acc < val_macro_f1): #early stopping\n",
    "#         check_val_acc = val_macro_f1\n",
    "#         print (\"Model saved at epoch :\", epoch)\n",
    "#         torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "#         best_epoch = epoch\n",
    "        \n",
    "#print(\"Best model found at epoch : \", best_epoch)        \n",
    "#torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXzU9Z348dd7ct8JCWfCEe77MgIKKF6IV/FAC9quZWspHlW7PbTtbtVWt+7P6qqt1aKrbXe9D9RWRbSigIqQIAIBuY+EcOQghNzHvH9/fIcwxByTkMlkkvfz8ZjHzPec95ch857v5xRVxRhjjGmKK9ABGGOM6dwsURhjjGmWJQpjjDHNskRhjDGmWZYojDHGNCs00AG0p5SUFB00aFCgwzDGmKCRlZVVoKo9m9unSyWKQYMGkZmZGegwjDEmaIjIvpb2saInY4wxzbJEYYwxplmWKIwxxjTLEoUxxphmWaIwxhjTLL8mChGZIyLbRGSniNzdyPYEEfm7iHwlItkistBr214R2SQiG0TEmjIZY0yA+K15rIiEAE8AFwG5wDoReVtVt3jtdiuwRVWvEJGewDYReV5Vqz3bz1PVAn/FaIwxpmX+7EcxBdipqrsBROQlYC7gnSgUiBMRAWKBIqDWjzEZY0ynp6pU1bopLq/hWIXzKC6v5lhFDddMTsPlEgAeev9rNh0o4eFrJ9AzLsJv8fgzUaQCOV7LucDUBvv8EXgbyAPigG+rqtuzTYHlIqLAn1V1SWNvIiKLgEUAAwYMaL/ojTGmnagqewrK2F9UzuGSSo5V1FBSUes8V9Zw6bi+XDymDwDvbTrIHS9toLrO3ei5Zo/pQ0JUGAAbcor5dGchhWVVQZsopJF1DWdJuhjYAJwPDAE+EJFVqloCTFfVPBHp5Vn/taqu/MYJnQSyBCAjI8NmYTLGBMSx8hr2F5Wzr8hJCBXVdfxk9oj67XOf+JTjlY0XmAxMjqlPFJFhIVTXuQkPcZEQHUZCVBiJUWEkRocRHxWG92Rzt58/jJtmDCY1Mcqv1+bPRJEL9PdaTsO5c/C2EHhQnSvfKSJ7gJHAWlXNA1DVIyKyFKco6xuJwhhjfKWqbD9cysFjFRSX13C0vJqj5TUkRYexcHo6AJU1dVz4yCcUl9dQXl2LiCCACAjCb+aOYf4Up/TilXU53Pf3bNwKFTV1p7xXeKiLH184HJdLEBGmpvegvLqOfolRJEY5X/rxkaEkRIcxum9C/XEzhqXw9W/nEBHqwimVb9rUwcnt+w/UBH8minXAMBFJBw4A84HrG+yzH7gAWCUivYERwG4RiQFcqnrc83o28Bs/xmqM6eJeWrufpz7Zxd7C8m9sG9knrj5RRIS6OFxSSU2d55f7KdNFK26vxeo6N2XVToKICgthYHI0A3o4j4HJ0dS6lXBPfcIzN57pU5xhIS7CQlp/ff7kt0ShqrUichvwPhACPKuq2SKy2LP9KeC3wF9EZBNOUdVdqlogIoOBpZ5sGgq8oKrL/BWrMabrKSqrRoCkmHAAiitq2FtYTkpsBKP6xpEQFUZSdDhJ0WGkJUXXHycifPSTWcRHhRET7nxjuxUURRVCXSd/5V+X0Z+5E/sBEBsR2uIdQLAS1a5TrJ+RkaE2eqwxXYOqUl5dR1iIi/BQ37p8VdbU8eHWw7z55QE+3pbPrecN5ccXDQfgyPFKth06ztlDUghxdc0v9LYQkSxVzWhuny41zLgxpvPLKSpnY+4xjnqaex4tq6a4ooZhvWL54blD6vc57/cfU+sp54kMcxEX6ZTpx0WGcfclI5nmKZ9fs7uQzL1F7C8q571Nhzhe5VQYh7iE/NKq+vftFRdJr7jIDr7arsEShTGmw/zbyxt448sDjW6bMTSlPlHER4VR61aiPC2AKmvcVNZUkX/c+eKv9Ko4Xr2jgD+u2Fm/PCEtgSsnpXL5+H5+bTLanViiMMb4RXWtmxXbjjCpfyK94p1f8v17RBMZ5mL6kBR6xUeQEOXUESRGhzGgR0z9sfGRoWy7fw4RoSH1RVDHK2s5Xun0OxjaM65+32mDk3Grk1QuGdeXob1iO/xauzqrozDGtBtVZf3+o7yx/gDvbDpIcXkNd80Zyc2znDuFY+U1hIQIsRH2G7WzsDoKY0y7qqqtc4aUKK/x3B04rYI++vowa3YXsWzzIfYXnWx+OqpvPH0SThb/JESHdXjM5vRZojDGNGrnkVL++NEOvj50vH7MIe9OZe/cPoMx/ZyOYu9vPszLmc6IPb3jI7hyYipXTU5lZJ/4gMRu2pclCmMM1bVuMvcVUV3rZtaIXoDTE/nNDacOphDqEhKiwkiIDqPOq+fZBaN60TshkqnpPZg2ONman3YxliiM6ab2FpSxckc+K7fn8/muQsqq6xjTL74+UQxOieGBq8YyLjWB5NgIEjwd0BrrVDZ7TB9me8YqMl2PJQpjupm3Nhzg4eXbT6lLABjRO44ZQ1Nwu7V+fKIbpg4MUJSmM7FEYUwXVVPn5sv9xazekc/kgUn1dwoRoS72F5WTGB3GjKEpnDO8J+cM60mfBOuMZhpnicKYLkJV2ZVfxuod+azeWVBfnARw1aTU+kQxY1hPlt5yNuPTEq0uwfjEEoUxXcSi/83igy2HT1k3tFcsM4amMHt07/p1sRGhTBqQ1NHhmSBmicKYIFTnVlbuyGdUn/j6IqMzBiaRubeImcN6MmNYCjOHpdA3wb8T2pjuwRKFMUEkp6icVzNzeDUrl4PHKrnjgmH1o6PeeNYgvj8jnbAQ30ZaNcZXliiM6eSqautYnn2Yl9fl8Omugvp5dAYmR9Mr/mSv56jwTjbbjekyLFEY08n9/LWNvOXp+BYe6uLSsX247sz+TEtPxmWV0aYDWKIwppPJzjtGqMvFiD7OCKnzzxzA9sOlLJjSn7kTUm28JNPhLFEY0wm43crH24/wzKo9fLarkAtH9eaZG50BPacN7sG7t8/ostNsms7PEoUxAVRRXcfr63N59tM97M4vAyAmPISBydGn9JA2JpAsURgTIKt25POjF7+kuLwGgH4JkSycns63p/QnPtKKl0znYYnCmA5y6Fgl+4vKmZLeA4DhveMoq6plQloCN80czJyxfaxpq+mULFEY46GqVNa4Kal05l4oqahheJ+4+l/3xeXViDjDbPvqSEkl720+xD825rFu71FSE6NYfdd5iAi94yNZ/uNzGZQcbcVLplOzRGG6tZyicm58bi0lFTWUVNRSXec+ZfsLP5jK2UNSAPif1Xv4w0c76RkXwZCeMQzpGcuQnrEM7eU8+iU6vaCPllXzj00HeWdjHl/sKarv9xAR6mJcagIllbX1ySY9JQZjOju/JgoRmQM8BoQAz6jqgw22JwD/BwzwxPJ7VX3Ol2ONaYsteSVsPVjCNWekAU6/hBOVyADhIS7io8JIiAolISqMiNCTRUFVtW4iw1zkH68i/3gVa3YX1W8b0TuO9398DgBbD5XwH29urj/fuSN6cvn4vlwwqrfNFW2Ckqhqy3u15cQiIcB24CIgF1gHLFDVLV77/BJIUNW7RKQnsA3oA9S1dGxjMjIyNDMz0x+XY4LcziOl/PeH23ln40Eiw1ys/Nl59IqPpLbOzZ6CMhKiwoiPCqufA7opbreSd6yCXfll7DxSyq78UnYdKWVwz1h+d/U4wBmH6d9e2cC5w3ty4ejeVjFtOjURyVLVjOb28efPmynATlXd7QnmJWAu4P1lr0CcOAW0sUARUAtM9eFYY1qUU1TOY//cwRvrc3Grcwdx/ZSB9ZXGoSEuhvWO8/l8LpeQlhRNWlI05w7v2eg+IS7hsfmT2iV+YzoDfyaKVCDHazkXJwF4+yPwNpAHxAHfVlW3iPhyLAAisghYBDBgwID2idwEvZo6N/f9PZuX1+VQU6eEuoT5U/rzo/OH2oiqxrSSPxNFY804GpZzXQxsAM4HhgAfiMgqH491VqouAZaAU/TU5mhN0CuvrkUQosJDCAtxsa+wnFq3cvWkVO64cBgDk63i2Ji28GeiyAX6ey2n4dw5eFsIPKhORclOEdkDjPTxWNMNqSp7C8vZnV/KnoIydheUsSe/jD0FZRwqqeThayfUV1Tfc8VoVGlV0ZIx5pv8mSjWAcNEJB04AMwHrm+wz37gAmCViPQGRgC7gWIfjjXdQGVNHTuPlDI2NQEAVbjksZVU1ri/sW94iIuj5dX1y0N7WYIwpj34LVGoaq2I3Aa8j9PE9VlVzRaRxZ7tTwG/Bf4iIptwipvuUtUCgMaO9VespnNRVdbvP8prWQf4x8Y8XCKs/dUFRISG4HIJ0wYnU+dW0lNiGJwSQ3rPWAanxNAvMcrmgDbGD/zWPDYQrHlscMspKmfplwd4Y30uewvL69ePS03giesnMyA5OoDRGdM1Bbp5rDE+25VfygUPf1K/3CsugqsmpXL15LT6eRmMMYFhicJ0OLdb+WxXIev3H+X2C4YBMDglhvFpCQxKjuGaM9KYMTTFipGM6SQsUZgOs6egjNezcnljfS55xyoBmDuxHwOTYxAR3rxluk3taUwnZInC+FVFdR1vbjjAa1m5ZO07Wr++f48orpmcRozX2EeWJIzpnCxRGL+qrnNz79vZVNW6iQkP4dJxfZl3RhpnDuphicGYIGGJwrQbVWXZ5kP86eNdvH7z2YSHukiICuOOC4fRJz6SOWP7EB1u/+WMCTb2V2vaRe7Rcu55K5t/fn0EgNU78zl/ZG8Abpk1NJChGWNOkyUKc1pq69w89+leHvlgOxU1dcRFhnLXnJHMGt4r0KEZY9qJJQrTZhtzi7n79U1sOVgCwGXj+3LP5aPpFR8Z4MiMMe3JEoVps+y8ErYcLCE1MYr7rxzLeSPtLsKYrsgShfGZqrK/qLx+uO5vZ/SnutbNtRlpVkltTBfmankXY5zK6h/8LYuLH11JTpEzDpPLJdx49iBLEsZ0cfYXbppVWFrFEyt28X9r9lFd5yY2IpQdR47Tv4cN0GdMd2GJwjSqtKqWZ1bt5umVuymrrgOc4TZ+eekoeltltTHdiiUK06h/X7qJNzc4kwqeP7IXP509gtH94gMclTEmECxRGADq3MrR8mpSYiMAWDxrCHnFlfz04hFMSe8R4OiMMYFkiaKbU1WWbznM79/fRo+YcF5aNA0RYWSfeF5ZfFagwzPGdAKWKLqxwyWV3PL8+vpRXdOSoigoraZnXESAIzPGdCaWKLqpA8UVXP/0GvYVlpMSG86Pzh/GgikDCA+1FtPGmFNZouiGcorKWfD0GnKPVjA2NZ7//depJMWEBzosY0wnZYmiG3r7qzxyj1YwsX8if/3XKSREhQU6JGNMJ2aJohu6ZdYQYsJDmJfRn9gI+y9gjGmeFUh3E18fKuFIiTNPtYjwvenpliSMMT7xa6IQkTkisk1EdorI3Y1s/5mIbPA8NotInYj08GzbKyKbPNsy/RlnV7cxt5hv/3kNNzzzBUVl1YEOxxgTZPyWKEQkBHgCuAQYDSwQkdHe+6jqQ6o6UVUnAr8APlHVIq9dzvNsz/BXnF1d1r6j3PD0FxyrqGFgcgwxESGBDskYE2T8eUcxBdipqrtVtRp4CZjbzP4LgBf9GE+3s2Z3Id/9ny84XlXLZeP68uR3JhMRaonCGNM6/kwUqUCO13KuZ903iEg0MAd43Wu1AstFJEtEFjX1JiKySEQyRSQzPz+/HcLuGlbvKOB7z62lvLqOKyf247H5EwkLsSopY0zr+fObQxpZp03sewXwaYNip+mqOhmn6OpWETmnsQNVdYmqZqhqRs+ePU8v4i5i55FS/vWv66iscXNdRhoPXzeRUEsSxpg28mezl1ygv9dyGpDXxL7zaVDspKp5nucjIrIUpyhrpR/i7HKG9IzhX6YNpLK2jt98aywuV2M52xhjfOPPRLEOGCYi6cABnGRwfcOdRCQBOBf4jte6GMClqsc9r2cDv/FjrEGvsqaOgtIq0pKiERF+ddkowGkKa4wxp6NN5REisqSlfVS1FrgNeB/YCryiqtkislhEFnvtehWwXFXLvNb1BlaLyFfAWuAdVV3Wlli7gyPHK1nwtNP89ain+auIWJIwxrSLJu8oTvRnaGwTcKkvJ1fVd4F3G6x7qsHyX4C/NFi3G5jgy3t0d5sPHOMHf8vk4LFKUhOjKCyrsnGbjDHtqrmip3xgH6dWSqtnuZc/gzK++cfGPH766ldU1rjJGJjEU989o37iIWOMaS/NJYrdwAWqur/hBhHJaWR/00HcbuXRD7fz+Ec7Abj2jDTuv2qs9ZEwxvhFc4niUSAJ+EaiAP6ff8Ixvlizu5DHP9qJS+CXl47i+zPSrT7CGOM3TSYKVX2imW1/8E84xhdnD03hzguHMbF/IrNGWCmgMca/mmz1JCL/6fX6oo4JxzRl2eZDrN1zsj/inRcOtyRhjOkQzTWPneP1+r/8HYhpXGFpFbe+sJ7F/5fFT1/9iorqukCHZIzpZmxCgk5KVfnHxoPc83Y2RWXVRIeHcNPMdCJsTmtjTAdrLlH0EpF/w9Mc1vO6nqo+4tfIurEjxyv5jzc38372YQBmDE3hd1ePo3+P6ABHZozpjppLFE8DcY28Nn7kdisLlqxhV34ZsRGh/OqyUcw/s7+1ajLGBExzrZ7u68hAjMPlEn4yewSvZObwn1eNo19iVKBDMsZ0c1ZHEWCqysvrcjhWUcMPzx0CwKXj+nLJ2D52F2GM6RQsUQTYv7+5mee/2E+oS5gztg8Dk2MAG/XVGNN5WBOaAPpgy2Ge/2I/EaEuHr5uAgOsstoY0wm1eEfRsLWTxzEgS1U3tH9I3UNRWTW/eGMTAD+fM5K5ExudJdYYYwLOlzuKDGAxznzXqcAiYBbwtIj83H+hdV2qyn+8uZmC0iqmpvdg4dmDAh2SMcY0yZc6imRgsqqWAojIPcBrwDlAFjZAYKv9feNB3tl0kJjwEH5/7QSbqtQY06n5kigGANVeyzXAQFWtEJEq/4TVtY3qE8e41ASunzrAOtEZYzo9XxLFC8AaEXnLs3wF8KJnLustfousCxvWO443bjmbULuTMMYEgRYThar+VkTeBWbgDOexWFUzPZtv8GdwXc2+wjIG9IhGRAgLsQZnxpjg0OK3lYg8BkSo6mOq+qhXkjCtkFNUzqWPreKH/5tFZY2NAGuMCR6+/KxdD/y7iOwUkYdEJMPfQXU1brfy89c2UlZdR4hLbARYY0xQafEbS1X/qqqXAlOA7cB/icgOv0fWhfz18718vruQlNhw7r9yrPW6NsYEldb8tB0KjAQGAV/7coCIzBGRbZ67kbsb2f4zEdngeWwWkToR6eHLscFiV34pD77n/HM9cNU4kmMjAhyRMca0ji91FCfuIH4DZANnqOoVPhwXAjwBXAKMBhaIyGjvfVT1IVWdqKoTgV8An6hqkS/HBoPaOjc/ffUrqmrdXD05lYvH9Al0SMYY02q+NI/dA5ylqgWtPPcUYKeq7gYQkZeAuTTdpHYB8GIbj+2UXlyXw5f7i+kTH8k9V4wJdDjGGNMmvjSPfUpEkkRkChDptX5lC4emAjley7nA1MZ2FJFonDm6b2vDsYtwhhVhwIABLYTUsa49I439hWXMHNaThKiwQIdjjDFt4suggDcBdwBpwAZgGvA5cH5LhzayTpvY9wrgU1Utau2xqroEWAKQkZHR1PkDIjIshF9dFnQlZsYEH3cdlBwA9eErQATiU8EV4v+4ughfip7uAM4E1qjqeSIyEvBl9rtcoL/XchqQ18S+8zlZ7NTaYzudtXuKGN0vntgIm+7DGL/bvhyW3QVFu30/JqoHDJsNwy+GoRdAZIL/4usCfPkmq1TVShFBRCJU9WsRGeHDceuAYSKSDhzASQbXN9xJRBKAc4HvtPbYzqigtIrv/2UdEWEhvHv7DHrFR7Z8kDGm9Y7uhWW/gG3vOstRPSA8tuXjaiugLB82vuQ8XKEw8GwYPsd5JA/xa9jByJdEkSsiicCbwAcichQfft2raq2I3Aa8D4QAz6pqtogs9mx/yrPrVcByVS1r6djWXFigPLx8O8erapk8MMmShDH+UFMBnz4Gq/8baishPA5m3Q1TfwghPtQFqkLBdti+DLa/D/vXwJ6VzuP9X0LyUE/SuBj6TwWX55ze/Z+6WV8oUV/K9E7sLHIukAAsU9XqlvbvaBkZGZqZGbgRRrLzjnH5H1YTIsKyO2cytFdcwGIxpkva9h68dxcU73OWx10Hs38LcafR9Ly8CHZ95CSOHR9AZXHrzyEu6DvRSS7DL4Y+E8DVxhEYVJ1itIMbIGmQc14/1qeISJaqNjviRmsL0Ud4Ko9NA6rKb/6+BVX47tkDLUkY056KdsN7d8OO953lXqPh0odg0IzTP3d0Dxg3z3nU1ULu2pN3G/nbPDu18INa3ZC33nl8/DuI7e2pA5kDg2dBRDNFYu46OLQJ9n/uPPZ9DmVHTm6PTIBBMyH9XBh8LqQM7/A7mtbeUaxX1cl+jOe0BPKO4r1NB7n5+fUkRYfx8U/PIyHamsMac9qqy50ipk8fg7oqiIiH834JZ97kWzGTP3l/d9aUw97VJxNMyYGT20LCnYQ2zHO3EdcXDmTB/s+cpJCzFqqPn3ru6BRInewUkR3de+q2uL4nk0b6uZBwetMo+3JH0dpE8aWqTjqtqPwoUImiutbN+Q9/TO7RCn575Vi+O21gh8dgTMAV73eKcVDnF7bi9VpPfV1XDVUlUFnSyPOxk8vFOVDu6es7YQFceB/E9Q7cNfpCFQ5nn0waues45Y7EFQru2lOPSRzoVKgPOMt5Th568q7h6D7Y8wns/sR5Lss/9djkoU7COPs26DG41eH6I1GkquqBlvcMjEDeUazYdoRX1uXwhwWTCLW5JkxHc7thw/NO0Uffid/8svGnY7mw/D8g+w3/nL/3OKeYaeBZ/jm/v5UVwM4PnaSx859OAuw12rmeE4khvp9v51KFI1tOJo29n568G7l1HfQc3urw2iVReJqv3gvM9Kz6BPiNqh5rdUR+FujKbGMC4uBX8I8fO8UZ3mJ6woBpMOBs50up9zgIace+PTUV8OnjntZHFRAa6VV+Lk4Fb/1rz/KJ165Qp+w9Ih4i4xt/joiHqEToMaTtFcOdTV2t01KruTqLVp2vBvK+dFpunf2jNv0waK9E8TqwGfirZ9V3gQmqenWrI/KzQCSKvOIK+iVGdeh7GgM4xTMrHoC1S5winbh+kLHQKfbY99mpFaLgNCPtf6aniONsSMuA0DaMZqwKW95y7iKO7XfWjb7SaX2U2LmG0TEta69WT0NU9Rqv5ftEZMPphdY1bMgp5ponP+M7Uwdw39yxgQ7HdBeqkL3U6WxWeggkBKbdCuf9AiLiTu5TtNtJGPs/d56P7nGage76yNknPNZpkTNstvOI79vyex/aDMvuhr2rnOXeY2HOg5A+s/njTFDzJVFUiMgMVV0NICLTgQr/htX5qSr3/T2bOrcSFW5DdZgOUrgL3v0Z7Pqns5x2Jlz2CPQdf+p+Ik4P4+QhMPm7zrqSgydb2uz71Cnr/vofzgOgz3inVc6wi50WN95t98uLnLuXzGedu5eoHnD+v8PkG9u3OMt0Sr58wouBv3nqKgCOAjf6L6Tg8NaGPL7cX0xKbAS3nT800OGYrq62ClY/CqsedpqJRibChfc6X9S+lt/H94Wx1zgPcFoU7VjuPHZ/Aoc2Oo+VD0F0Mgy9CIbPhrJCJ0lUFjt3L1N+6PSEju7hr6s1nUyziUJEXDid7CaISDyAqpZ0SGSdWHl1bf2sdT+fM8IG/zMtU3W+7KtLoeq486it8u3Y4wfhw3uhaJezPGEBXPRbiO15ejEl9oczv+88aio8/QDedzq1Fe8/ORbSCennOsVMvW1E5O6m2W84VXV7xlx6xRLESU99vItDJZWMS01g3uS0QIdjOoPaKqcJ5NZ/OPUGVaWepFDqNIesLv1m2/nWShkBlz/SPr2RGwqLgmEXOQ99yOmRfOJuo6YCZtwJIy/vdmMcGYcvP4U/EJGfAi8D3gP3FTV9SNeVe7ScP690hjP+9RWjcbnsD6fbctc5lbqbXoOtb0NlCy3GQ8KdCuSIWKcFUlgkjU+90oC4YOSlToV1aHi7hN78+wn0Guk8pt/u//cznZ4vieJfPc+3eq1ToPVdALuA8FAXl43rS61bOXOQldF2O6pwYD1sfg02v+HcPZzQZxyMnee0BIqIPTUpRMS2rSmqMZ2AL1OhpndEIMGiV1wkj3x7IrV17kCHYjpS/jbnzmHTq04z0xOS0mHctc6Acj19mabFmODjy1SotwLPq2qxZzkJWKCqf/J3cJ2ZDdPRDZTkeZLDK87onifE9va0HprnNCO1cnvTxflS9PQDVX3ixIKqHhWRHwDdKlFU1tRx50sbmD40me9MG4jYl0PXVFHs9Dre9KrTCujEYG4RCTD6W86dw6CZNt+y6VZ8SRQuERH1jPUhIiFAB9SodS6Ze4+yLPsQ+4vK+e5ZgwIdjmlPNZXOSJ+bXnVa+dR55uQKiXA6oI2/zum5bHUMppvyJVG8D7wiIk/h/LxaDCzza1Sd0KodztC+M4enBDiSACkrcHrynhgmWt04w0bjeVavZ5wWM0mDAhZui2qrYd9q2PS602Kp6kTrb3H6C4y/DkZd4QxcZ0w350uiuAv4IXAzTlu+5cAz/gyqM1q1wxkTf+bQ0+zkFCzcbmdUyh3LYecHTkuflmb5aihlxMmpIftPDfxEM8cPnewbsOvjUyeL6TvBmVZz7DW+jXlkTDfiS6snN/Ck59EtFZRWseVgCRGhLjIGJQU6HP85MXfwjg+czmMnJowBpxim30SnL0DD4aMbDiPtroHcTCjY5jw+e9wp4x96gZM0hl4EMcn+vx53nZPgdrzv9Dg+tPHU7T1HwajLnQTRhnH8jekufGn1NAz4HTAaiDyxXlW7TT+KT3c6X5hT0nsQGdbFKjGPbHUGhdvxgTMTl3o1+00ccHJk0UEzITza9/PW1Tijlm73fEkX7nAmtsl+AxBnMLvhs53hrkNOVHk1uGNpxaRapzjmGcNo54dQXnhyfWgUpJ/jvO/QiyDJZiI0xhe+FD09B9wD/DdwHrAQn7qTdh31xU7Dus+DsMkAABbaSURBVFD9hKozD/GH95xc5wpzEsKJ5JAyrO1NP0PCnC/l9HPg4gecIa+3L3cqjfd96kxgn7u2fa6lOYkDPSOiznaGvgizuUOMaS1fEkWUqv7T0/JpH3CviKzCSR7dwtT0HhSWVnHu8F6BDqV91NXCez9zhowGmHgDjLjUmaz9xHwG7a3HYJi22HlUlcLuj52kcWTrqft9IzG1IVFFxMGQ85zhsk8n2RljAN8SRaVnFNkdngECDwA+fWOKyBzgMSAEeEZVH2xkn1nAo0AYUKCq53rW7wWOA3VAbUszMPnTtRn9uTajf6Devn1VHYdXFzoV1CERcPWfYcxVHRtDRKxTNzDq8o59X2NMm/iSKO4EooHbgd8C5+PDfBSe/hZPABcBucA6EXlbVbd47ZOI03FvjqruF5GGCeg8VS3AtI+SPHjhOqeXcVQPWPASDJga6KiMMZ2cL62e1nleluLUT/hqCrBTVXcDiMhLwFxgi9c+1wNvqOp+z3sd+cZZAuzVzBxSk6LIGNiD8NAgHrbj0GYnSZQccIqBbnjNmf3MGGNa0GSiEJG3mztQVb/VwrlTgRyv5Vyg4c/X4UCYiHwMxAGPqerfTrwFsFxEFPizqi5pIs5FwCKAAQPad2L3qto6fv1WNhU1dXzxywvoHR/Z8kGd0c5/wis3Ov0G+k+D+S90TPNUY0yX0NwdxVk4X/QvAl/Q+lrFxvZv2N4xFDgDuACIAj4XkTWquh2Yrqp5nuKoD0Tka1Vd+Y0TOglkCUBGRkYb21M2bv2+Yipq6hjROy54k8T6/4V/3OlMmjPmarjySc88CMYY45vmEkUfnPqFBThFRO8AL6pqto/nzgW8a4DTgLxG9ilQ1TKgTERWAhOA7aqaB05xlIgsxSnK+kai8KfVO51hO2YEY7NYVfjoflj1e2d5xo/h/F/7Pr+yMcZ4NPmtoap1qrpMVW8EpgE7gY9F5Ec+nnsdMExE0kUkHJgPNCzOeguYKSKhIhKNUzS1VURiRCQOQERigNnA5lZdWTtY7ek/EXSJorYK3viBkyQkBC5/FC6815KEMaZNmq3MFpEI4DKcu4pBwOPAG76cWFVrPc1p38dpHvusqmaLyGLP9qdUdauILAM2Am6cJrSbRWQwsNQzlHco8IKqduhAhEfLqtl44BjhIS6mpgfBTHalR5yeyDs+cIbhqCx2Zli79q8w7MJAR2eMCWLNVWb/FRgLvAfcp6qt/kWvqu8C7zZY91SD5YeAhxqs241TBBUwn+0qRBXOGJhEdLgvrYg7WF0tHMj0jMv0ARz86tTtvUbDVX+GvuMDE58xpsto7hvwu0AZTsuk270m6hFAVTXez7EFVGVNHamJUZ1rWPHSfCcpeN81nBAa6TX8xoVOE1hjjGkHTSYKVe3WBdrXnJHG1ZNTqXW3a0OqtnG74Ysn4cN7T06qA9BjCAy7yBngbtB0G8fIGOMXnbBMpfMQEcJCAjxO0PHD8OZi5w4CYMj5MHwODL3QOswZYzqEJYpG7CkoIy4ylJTYAE99uW0ZvHWrMy9EVA+Y+0cYeVlgYzLGdDvdunipKQ+8s5WM+z/kvU0HAxNATQW881N48dtOkhg8C27+zJKEMSYg7I6igZo6N2t2O5PdTOif2PEBHM6G174P+Vud+SEu+DWcdZv1gTDGBIwligY25BRTWlXLkJ4x9EvswMphVfjiz/DBr6GuCpKHwjX/40w/aowxAWSJooGTs9n17Lg3Lc2Ht25xpu8EmHwjzPkdhMd0XAzGGNMESxQNrNrhGd9paAf1n9j/Bbz8HSg7ApGJ8K0/wOiWBuY1xpiOY4nCy7GKGr7KKSbUJUwb0kHDcL/zEydJDJrp9KROSO2Y9zXGGB9ZovCSfeAYAJMHJBEb0QH/NAU74PAmiEiA77wOoQFujmuMMY2wROHl7KEpfPnr2RSUVnXMG2YvdZ5HXmZJwhjTaVmiaCAhKoyEqLCOebMTiWLMVR3zfsYY0wbWON+jutaNuyPHdTryNRzZ4lRgD57Vce9rjDGtZInC49WsHKb854c89+mejnnDE3cToy6H0PCOeU9jjGkDSxQeq7YXUFBaTURoiP/fTNWKnYwxQcMSBVDnVj7bdaKjXQf0nziyFQq2OQP9pZ/r//czxpjTYIkC2JhbTEllLQOTo+nfI9r/b1hf7HQFhHRQxbkxxrSRJQq8h+3ogLsJVcj2TDtuxU7GmCBgiQJY7UkUM4Z2wPhOhzdD4U6ITnF6YxtjTCfX7RNFaVUt6/cfJcQlnNURw3acKHYa/S0IsW4sxpjOr9t/U0WFhfDq4rPYfvi4/zvaqcJmK3YyxgSXbp8oQlzCpAFJTBqQ5P83O/gVHN0DMT1h4HT/v58xxrQDvxY9icgcEdkmIjtF5O4m9pklIhtEJFtEPmnNsUGnvthpLrg6oL+GMca0A7/dUYhICPAEcBGQC6wTkbdVdYvXPonAn4A5qrpfRHr5emzQOaWT3dWBjcUYY1rBn3cUU4CdqrpbVauBl4C5Dfa5HnhDVfcDqOqRVhwbXPLWQ/E+iO0DA6YFOhpjjPGZPxNFKpDjtZzrWedtOJAkIh+LSJaI/EsrjgVARBaJSKaIZObn57dT6H5gxU7GmCDlz8psaWRdw+FZQ4EzgAuAKOBzEVnj47HOStUlwBKAjIyMDhz+tRVUIftN5/VYK3YyxgQXfyaKXKC/13IakNfIPgWqWgaUichKYIKPxwaP3Ew4lgNx/SBtSqCjMcaYVvFn0dM6YJiIpItIODAfeLvBPm8BM0UkVESiganAVh+PDR71ldhXgqvb93E0xgQZv91RqGqtiNwGvA+EAM+qaraILPZsf0pVt4rIMmAj4AaeUdXNAI0d669Y/crthi2eYidr7WSMCUKi2jmL9dsiIyNDMzMzAx3GqfavgWcvhoT+cOcmkMaqX4wxJjBEJEtVM5rbx8pB/M27tZMlCWNMELJE4U9ut7V2MsYEPUsU/pSzBkoPQeIA6Dc50NEYY0ybWKLwJ++RYq3YyRgTpCxR+Iu7Dra85by2IcWNMUGs2w8z7jf7PoOyI5CUDn0nBjoaY4JOTU0Nubm5VFZWBjqULiEyMpK0tDTCwlo/744lCn/JtmInY05Hbm4ucXFxDBo0CLG/odOiqhQWFpKbm0t6enqrj7dE0Vo1lVBTDtVlpz7XVJy6zoqdjDktlZWVliTaiYiQnJxMWwdOtUTRGh/dDysf8n3/5KHQZ5z/4jGmi7Mk0X5O59/SEoWvyovgsz84ryMTITwGwqIhPNp5rn8d4zyHx8DYeVbsZIwJepYofJX1HNRWwtCL4DuvBToaY4yfFRcX88ILL3DLLbe06rhLL72UF154gcTERD9F1vGseawvaqth7dPO62k3BzYWY0yHKC4u5k9/+tM31tfV1TV73LvvvtulkgTYHYVvtrwFxw9CyggYcn6gozGmWxp09ztNbvvPq8Zx/dQBALzwxX5+uXRTk/vuffAyn97v7rvvZteuXUycOJGwsDBiY2Pp27cvGzZsYMuWLVx55ZXk5ORQWVnJHXfcwaJFi5w4Bw0iMzOT0tJSLrnkEmbMmMFnn31Gamoqb731FlFRUa246s7B7ihaogprnnBeT7vZ6hyM6SYefPBBhgwZwoYNG3jooYdYu3YtDzzwAFu2bAHg2WefJSsri8zMTB5//HEKCwu/cY4dO3Zw6623kp2dTWJiIq+//npHX0a7sDuKluSshbwvIaoHTJgf6GiM6bZ8vRO4fuqA+ruL9jRlypRT+iA8/vjjLF3qjA6dk5PDjh07SE5OPuWY9PR0Jk50OtyeccYZ7N27t93j6giWKFqyxlNGmbEQwoLvltEY0z5iYmLqX3/88cd8+OGHfP7550RHRzNr1qxGe5BHRETUvw4JCaGioqJDYm1vVvTUnOL9sPVtcIXCmTcFOhpjTAeKi4vj+PHjjW47duwYSUlJREdH8/XXX7NmzZoOjq5j2R1Fc9YuAXXD2Gsgvl+gozHGdKDk5GSmT5/O2LFjiYqKonfv3vXb5syZw1NPPcX48eMZMWIE06ZNC2Ck/mdToTalqhQeGQ1Vx+AHKyDV5pMwpiNt3bqVUaNGBTqMLqWxf1ObCvV0fPWikyT6T7MkYYzp1ixRNMbthjVPOq+tg50xppuzRNGYHcuhaBck9IeRlwc6GmOMCSi/JgoRmSMi20Rkp4jc3cj2WSJyTEQ2eB6/9tq2V0Q2eda3U8WDj040iZ2yCEKsvt8Y07357VtQREKAJ4CLgFxgnYi8rapbGuy6SlWb+tl+nqoW+CvGRh3Ohj2fOKPATv6XDn1rY4zpjPx5RzEF2Kmqu1W1GngJmOvH92sfJ+omJt0AUV1rYC9jjGkLfyaKVCDHaznXs66hs0TkKxF5T0TGeK1XYLmIZInIoqbeREQWiUimiGS2dfameqX5sPEV5/XUxad3LmNMtxIbGwtAXl4e8+bNa3SfWbNm0VIT/kcffZTy8vL65UsvvZTi4uL2C7QN/JkoGhs9r2GnjfXAQFWdAPwBeNNr23RVnQxcAtwqIuc09iaqukRVM1Q1o2fPnqcXcdZzUFcFw+dA8pDTO5cxplvq168fr73W9jlrGiaKzjBsuT9ranOB/l7LaUCe9w6qWuL1+l0R+ZOIpKhqgarmedYfEZGlOEVZK/0WbW0VrHvGeT2tdROVGGP87N4EP533WJOb7rrrLgYOHFg/cdG9996LiLBy5UqOHj1KTU0N999/P3PnnlqivnfvXi6//HI2b95MRUUFCxcuZMuWLYwaNeqUsZ5uvvlm1q1bR0VFBfPmzeO+++7j8ccfJy8vj/POO4+UlBRWrFhRP2x5SkoKjzzyCM8++ywAN910E3feeSd79+71+3Dm/ryjWAcME5F0EQkH5gNve+8gIn3EM5GriEzxxFMoIjEiEudZHwPMBjb7MVbIXgqlh6HXGEhv9ObFGNONzJ8/n5dffrl++ZVXXmHhwoUsXbqU9evXs2LFCn7yk5/Q3OgWTz75JNHR0WzcuJFf/epXZGVl1W974IEHyMzMZOPGjXzyySds3LiR22+/nX79+rFixQpWrFhxyrmysrJ47rnn+OKLL1izZg1PP/00X375JeD/4cz9dkehqrUichvwPhACPKuq2SKy2LP9KWAecLOI1AIVwHxVVRHpDSz15JBQ4AVVXeavWFGFz23OCWM6rWZ++fvLpEmTOHLkCHl5eeTn55OUlETfvn358Y9/zMqVK3G5XBw4cIDDhw/Tp0+fRs+xcuVKbr/9dgDGjx/P+PHj67e98sorLFmyhNraWg4ePMiWLVtO2d7Q6tWrueqqq+pHsb366qtZtWoV3/rWt/w+nLlfOwmo6rvAuw3WPeX1+o/AHxs5bjcwwZ+xnWLfZ3BoI0SnwLhrO+xtjTGd27x583jttdc4dOgQ8+fP5/nnnyc/P5+srCzCwsIYNGhQo8OLe5NGfnju2bOH3//+96xbt46kpCS+973vtXie5u5c/D2cufXMhpMd7M78PoRFBjYWY0ynMX/+fF566SVee+015s2bx7Fjx+jVqxdhYWGsWLGCffv2NXv8Oeecw/PPPw/A5s2b2bhxIwAlJSXExMSQkJDA4cOHee+99+qPaWp483POOYc333yT8vJyysrKWLp0KTNnzmzHq22adTsu2gNfvwOuMMj4fqCjMcZ0ImPGjOH48eOkpqbSt29fbrjhBq644goyMjKYOHEiI0eObPb4m2++mYULFzJ+/HgmTpzIlClTAJgwYQKTJk1izJgxDB48mOnTp9cfs2jRIi655BL69u17Sj3F5MmT+d73vld/jptuuolJkyZ1yKx5Nsz43tXw5i0w8Gy46qmW9zfGdAgbZrz9tXWYcbujGDQDbv8Sqkpa3tcYY7ohq6MAcIVAVFKgozDGmE7JEoUxptPqSkXjgXY6/5aWKIwxnVJkZCSFhYWWLNqBqlJYWEhkZNtadVodhTGmU0pLSyM3N5fTHuzTAE7iTUtLa9OxliiMMZ1SWFgY6enpgQ7DYEVPxhhjWmCJwhhjTLMsURhjjGlWl+qZLSL5QPODrzQtBejY+bn9q6tdD3S9a+pq1wNd75q62vXAN69poKo2O+tbl0oUp0NEMlvqxh5Mutr1QNe7pq52PdD1rqmrXQ+07Zqs6MkYY0yzLFEYY4xpliWKk5YEOoB21tWuB7reNXW164Gud01d7XqgDddkdRTGGGOaZXcUxhhjmmWJwhhjTLO6faIQkTkisk1EdorI3YGOpz2IyF4R2SQiG0SklVP+BZ6IPCsiR0Rks9e6HiLygYjs8DwH1QQiTVzTvSJywPM5bRCRSwMZY2uISH8RWSEiW0UkW0Tu8KwP2s+pmWsKys9JRCJFZK2IfOW5nvs861v9GXXrOgoRCQG2AxcBucA6YIGqbgloYKdJRPYCGaoalB2FROQcoBT4m6qO9az7f0CRqj7oSehJqnpXIONsjSau6V6gVFV/H8jY2kJE+gJ9VXW9iMQBWcCVwPcI0s+pmWu6jiD8nEREgBhVLRWRMGA1cAdwNa38jLr7HcUUYKeq7lbVauAlYG6AY+r2VHUlUNRg9Vzgr57Xf8X5Aw4aTVxT0FLVg6q63vP6OLAVSCWIP6dmrikoqaPUsxjmeSht+Iy6e6JIBXK8lnMJ4v8YXhRYLiJZIrIo0MG0k96qehCcP2igV4DjaS+3ichGT9FU0BTTeBORQcAk4Au6yOfU4JogSD8nEQkRkQ3AEeADVW3TZ9TdE4U0sq4rlMVNV9XJwCXArZ5iD9P5PAkMASYCB4GHAxtO64lILPA6cKeqlgQ6nvbQyDUF7eekqnWqOhFIA6aIyNi2nKe7J4pcoL/XchqQF6BY2o2q5nmejwBLcYrYgt1hTxnyibLkIwGO57Sp6mHPH7IbeJog+5w85d6vA8+r6hue1UH9OTV2TcH+OQGoajHwMTCHNnxG3T1RrAOGiUi6iIQD84G3AxzTaRGRGE9FHCISA8wGNjd/VFB4G7jR8/pG4K0AxtIuTvyxelxFEH1OnorS/wG2quojXpuC9nNq6pqC9XMSkZ4ikuh5HQVcCHxNGz6jbt3qCcDT1O1RIAR4VlUfCHBIp0VEBuPcRYAz1e0LwXZNIvIiMAtnOOTDwD3Am8ArwABgP3CtqgZN5XAT1zQLpzhDgb3AD0+UHXd2IjIDWAVsAtye1b/EKdMPys+pmWtaQBB+TiIyHqeyOgTnpuAVVf2NiCTTys+o2ycKY4wxzevuRU/GGGNaYInCGGNMsyxRGGOMaZYlCmOMMc2yRGGMMaZZliiMaQURqfMaRXRDe444LCKDvEeXNaazCA10AMYEmQrPkAjGdBt2R2FMO/DMAfJfnvH/14rIUM/6gSLyT8+Acv8UkQGe9b1FZKlnroCvRORsz6lCRORpz/wByz09ao0JKEsUxrROVIOip297bStR1SnAH3F6++N5/TdVHQ88DzzuWf848ImqTgAmA9me9cOAJ1R1DFAMXOPn6zGmRdYz25hWEJFSVY1tZP1e4HxV3e0ZWO6QqiaLSAHOZDg1nvUHVTVFRPKBNFWt8jrHIJyhoId5lu8CwlT1fv9fmTFNszsKY9qPNvG6qX0aU+X1ug6rRzSdgCUKY9rPt72eP/e8/gxnVGKAG3CmowT4J3Az1E8uE99RQRrTWvZrxZjWifLMGHbCMlU90UQ2QkS+wPkBtsCz7nbgWRH5GZAPLPSsvwNYIiLfx7lzuBlnUhxjOh2rozCmHXjqKDJUtSDQsRjT3qzoyRhjTLPsjsIYY0yz7I7CGGNMsyxRGGOMaZYlCmOMMc2yRGGMMaZZliiMMcY06/8DISBqBP68pOMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_plots(train_losses, val_losses, train_accs, test_accs):\n",
    "    \"\"\"Plot\n",
    "\n",
    "        Plot two figures: loss vs. epoch and accuracy vs. epoch\n",
    "    \"\"\"\n",
    "    n = len(train_losses)\n",
    "    xs = np.arange(n)\n",
    "\n",
    "    # plot losses\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_losses, '--', linewidth=2, label='train loss')\n",
    "    ax.plot(xs, val_losses, '-', linewidth=2, label='validation loss')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.savefig('loss_DLTN_utype_2layer.png')\n",
    "\n",
    "    # plot train and test accuracies\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_accs, '--', linewidth=2, label='train')\n",
    "    ax.plot(xs, test_accs, '-', linewidth=2, label='validation')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Macro-avg F1\")\n",
    "    ax.legend(loc='lower right')\n",
    "    plt.savefig('accuracy_DLTN_utype_2layer.png')\n",
    "    \n",
    "save_plots(per_epoch_train_loss, per_epoch_val_loss, per_epoch_train_f1, per_epoch_val_f1)\n",
    "# print(per_epoch_train_loss)\n",
    "# print(per_epoch_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "# def make_prediction(training_data_des, training_data_loc, training_data_twt, training_data_net, ground_truths):\n",
    "#     model = JointDLTN()\n",
    "#     #model.load_state_dict(torch.load(\"data/YUN_utype/joint_DLTN_14.pt\")) #Testing accuracy, macro_f1: 0.7633587786259542 0.6908145811582292\n",
    "#     #model.load_state_dict(torch.load(\"data/YUN_utype/joint_DLTN_19.pt\")) #Testing accuracy, macro_f1: 0.767175572519084 0.714798206278027\n",
    "#     #model.load_state_dict(torch.load(\"data/YUN_utype/joint_DLTN_11.pt\")) #best #Testing accuracy, macro_f1: 0.7862595419847328 0.7560951140518181\n",
    "#     #model.load_state_dict(torch.load(\"data/YUN_utype_overfit/joint_DLTN_16.pt\")) #Testing accuracy, macro_f1: 0.7442748091603053 0.6970324361628709\n",
    "#     model.load_state_dict(torch.load(\"data/YUN_utype_overfit/joint_DLTN_23.pt\")) #Testing accuracy, macro_f1: 0.7213740458015268 0.6876262717476371\n",
    "#     predictions =[]\n",
    "#     for i in range (0,len(training_data_des)):\n",
    "#         prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_twt[i], training_data_net[i])\n",
    "#         pred = torch.argmax(prediction_joint, dim=1)\n",
    "#         predictions.append(pred.item())\n",
    "#     #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "#     accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_des)\n",
    "#     macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    \n",
    "#     return accuracy, macro_f1\n",
    "\n",
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction(training_data_des, training_data_loc, training_data_twt, training_data_net, ground_truths):\n",
    "    for epoch in range(0,30):\n",
    "        model = JointDLTN()\n",
    "        model.load_state_dict(torch.load(\"data/DLTN_utype_2layer/joint_DLTN_\"+str(epoch)+\".pt\")) #best #Testing accuracy, macro_f1: 0.7862595419847328 0.7560951140518181\n",
    "        predictions =[]\n",
    "        for i in range (0,len(training_data_des)):\n",
    "            prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_twt[i], training_data_net[i])\n",
    "            pred = torch.argmax(prediction_joint, dim=1)\n",
    "            predictions.append(pred.item())\n",
    "        #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "        accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_des)\n",
    "        macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "        print('epoch :', epoch, 'Testing accuracy, macro_f1:', accuracy, macro_f1)\n",
    "        #return accuracy, macro_f1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "########.....Load Test data.......\n",
    "with open(\"data/test.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "test_data = data[:] \n",
    "#print(test_data, len(test_data)) #262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no location for user:  vaibhavatttc\n"
     ]
    }
   ],
   "source": [
    "#####prepare testing data for neural net #########\n",
    "testing_data_des, testing_data_loc, testing_data_twt =  nn_input(test_data,df)\n",
    "testing_data_net =  nn_input_network(test_data,df)\n",
    "test_gt = find_groundtruth(test_data, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########........Calculate Validation Accuracy.......\n",
    "# test_accuracy, test_macro_f1 = make_prediction(testing_data_des, testing_data_loc, testing_data_twt, testing_data_net, test_gt)\n",
    "# print('Testing accuracy, macro_f1:', test_accuracy, test_macro_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 Testing accuracy, macro_f1: 0.6183206106870229 0.5666650584896916\n",
      "epoch : 1 Testing accuracy, macro_f1: 0.7022900763358778 0.6625661375661376\n",
      "epoch : 2 Testing accuracy, macro_f1: 0.7137404580152672 0.6793524255480777\n",
      "epoch : 3 Testing accuracy, macro_f1: 0.7404580152671756 0.7094385929031599\n",
      "epoch : 4 Testing accuracy, macro_f1: 0.7557251908396947 0.7284603147031495\n",
      "epoch : 5 Testing accuracy, macro_f1: 0.7557251908396947 0.7255565610859729\n",
      "epoch : 6 Testing accuracy, macro_f1: 0.7519083969465649 0.7214422647581721\n",
      "epoch : 7 Testing accuracy, macro_f1: 0.7480916030534351 0.7178190590694422\n",
      "epoch : 8 Testing accuracy, macro_f1: 0.7557251908396947 0.7244198747416646\n",
      "epoch : 9 Testing accuracy, macro_f1: 0.767175572519084 0.7357656721872775\n",
      "epoch : 10 Testing accuracy, macro_f1: 0.7633587786259542 0.7329534373951776\n",
      "epoch : 11 Testing accuracy, macro_f1: 0.7633587786259542 0.7322398446101209\n",
      "epoch : 12 Testing accuracy, macro_f1: 0.7633587786259542 0.7311609155871449\n",
      "epoch : 13 Testing accuracy, macro_f1: 0.767175572519084 0.7341064458389942\n",
      "epoch : 14 Testing accuracy, macro_f1: 0.7633587786259542 0.7295670446382415\n",
      "epoch : 15 Testing accuracy, macro_f1: 0.7709923664122137 0.7369867291178767\n",
      "epoch : 16 Testing accuracy, macro_f1: 0.7709923664122137 0.7363456121202209\n",
      "epoch : 17 Testing accuracy, macro_f1: 0.7748091603053435 0.7419874108232204\n",
      "epoch : 18 Testing accuracy, macro_f1: 0.767175572519084 0.7346432281135771\n",
      "epoch : 19 Testing accuracy, macro_f1: 0.767175572519084 0.7346432281135771\n",
      "epoch : 20 Testing accuracy, macro_f1: 0.7557251908396947 0.7223360811877558\n",
      "epoch : 21 Testing accuracy, macro_f1: 0.7557251908396947 0.7214060019860775\n",
      "epoch : 22 Testing accuracy, macro_f1: 0.7557251908396947 0.7243970874436507\n",
      "epoch : 23 Testing accuracy, macro_f1: 0.7595419847328244 0.7272975389814302\n",
      "epoch : 24 Testing accuracy, macro_f1: 0.7595419847328244 0.7272975389814302\n",
      "epoch : 25 Testing accuracy, macro_f1: 0.7519083969465649 0.7190065681444993\n",
      "epoch : 26 Testing accuracy, macro_f1: 0.7595419847328244 0.7262799641475448\n",
      "epoch : 27 Testing accuracy, macro_f1: 0.767175572519084 0.7335711869204693\n",
      "epoch : 28 Testing accuracy, macro_f1: 0.767175572519084 0.7335711869204693\n",
      "epoch : 29 Testing accuracy, macro_f1: 0.7709923664122137 0.7382457580733442\n"
     ]
    }
   ],
   "source": [
    "make_prediction(testing_data_des, testing_data_loc, testing_data_twt, testing_data_net, test_gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
