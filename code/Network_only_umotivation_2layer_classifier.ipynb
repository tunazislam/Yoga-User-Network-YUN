{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11e031a10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "import spacy  # For preprocessing\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p  #pip install tweet-preprocessor\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation as punc\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "#from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.models as gsm\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import regex\n",
    "import emoji\n",
    "# Internal dependencies\n",
    "import word_emoji2vec as we2v\n",
    "#from word_emoji2vec import Word_Emoji2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed #python -m spacy download en\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## load embeddings #######\n",
    "#loc_emb = torch.load('data/locationEmbeddings.pt') \n",
    "#des_emb = torch.load('data/descriptionEmbeddings.pt') \n",
    "#twt_emb = torch.load('data/tweetsEmbeddings.pt') \n",
    "\n",
    "#load network embedding\n",
    "net_emb = gsm.KeyedVectors.load_word2vec_format('data/userNetworkEmd.emd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user = net_emb ['000mrs000']\n",
    "#print(user)\n",
    "#print(type(net_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load 1300 user location, description, yoga tweets, utype, umotivation\n",
    "df = pd.read_csv(\"data/yoga_user_name_loc_des_mergetweets_yoga_1300_lb.csv\") \n",
    "#print (df) #[1308 rows x 7 columns] name, location, description, text, utype, umotivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load train users and split into train and validation #######\n",
    "with open(\"data/train.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "random.seed(1)\n",
    "random.shuffle(data)\n",
    "\n",
    "train_data = data[:830] #80% train  \n",
    "#print(train_data, len(train_data)) #830\n",
    "valid_data = data[830:] #20% validation\n",
    "#print(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create Model \n",
    "class NetworkMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkMLP, self).__init__() \n",
    "        self.fc1 = nn.Linear(300, 150)       \n",
    "    def forward(self, X):\n",
    "        #print(X.size()) # torch.Size([300])\n",
    "        #print('resize', X.view(1,len(X)).size()) #resize torch.Size([1, 300])\n",
    "        z1 = self.fc1(X.view(1,len(X)))\n",
    "        #print('z1', z1, z1.size()) # torch.Size([1, 150])\n",
    "        h1 = F.relu(z1) \n",
    "        #logits = self.fc2(h1) #without attention\n",
    "        #print(\"logits\", logits, logits.size()) #torch.Size([1, 3])\n",
    "        #return logits \n",
    "        return h1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.model_des = BiLSTMDesAtt()\n",
    "        #self.model_loc = LSTMLoc()\n",
    "        self.model_net = NetworkMLP()\n",
    "        self.fc1 = nn.Linear(150, 200) \n",
    "        self.fc2 = nn.Linear(200, 3) \n",
    "\n",
    "    def forward(self, x_n): \n",
    "        #prediction_des = self.model_des(x_d)\n",
    "        #print(prediction_des, prediction_des.size()) #torch.Size([1, 3])\n",
    "        #prediction_loc = self.model_loc(x_l)\n",
    "        #print(prediction_loc, prediction_loc.size()) #torch.Size([1, 3])\n",
    "        prediction_net = self.model_net(x_n)\n",
    "        #print(prediction_net, prediction_net.size()) #torch.Size([1, 3])\n",
    "        #concat_pred = torch.cat((prediction_des, prediction_loc, prediction_net), 1) #concat with dim= 1\n",
    "        #print(concat_pred, concat_pred.size()) #torch.Size([1, 6])\n",
    "        out = self.fc1(prediction_net)\n",
    "        out = self.fc2(F.relu(out))\n",
    "        out = F.log_softmax(out, dim = 1)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare data for neural net #########\n",
    "def nn_input_network(train_data,df):\n",
    "    training_data =[]\n",
    "    for i in range (0, len(train_data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (train_data[i] == df.name[j]):\n",
    "                #print(train_data[i]) #print username\n",
    "                utype =  [int(df.utype[j])]\n",
    "                umotivation = [int(float(df.umotivation[j]))]\n",
    "                #print (\"net_emb[train_data[i]] : \", net_emb[train_data[i]], type(net_emb[train_data[i]]), torch.Tensor(net_emb[train_data[i]]), type(torch.Tensor(net_emb[train_data[i]])))\n",
    "                #count = 0\n",
    "                if(train_data[i] not in net_emb ):\n",
    "                    net_emb[train_data[i]] = np.zeros(300) #For users not appearing in the mention network, we set their network embedding vectors as 0.\n",
    "                    #count = count + 1\n",
    "                #print(count)\n",
    "                #print(net_emb[train_data[i]]) #ok\n",
    "                ####.....convert ndarray to torch.tensor........\n",
    "                net_emb_tensor = torch.Tensor(net_emb[train_data[i]])\n",
    "                #print(net_emb_tensor) #ok\n",
    "                training_data.append(net_emb_tensor)\n",
    "                break\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Ground Truth #########\n",
    "def find_groundtruth(data, df):\n",
    "    ground_truths = []\n",
    "    for i in range (0, len(data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (data[i] == df.name[j]):\n",
    "                #print(data[i]) #print username\n",
    "                utype =  [int(df.utype[j])]\n",
    "                umotivation = [int(float(df.umotivation[j]))]\n",
    "                #target_type = torch.tensor(utype, dtype=torch.long) #for user type\n",
    "                target_type = torch.tensor(umotivation, dtype=torch.long) #for user motivation\n",
    "                ground_truths.append(target_type)\n",
    "    return ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_tr(model, training_data_net, ground_truths):\n",
    "    predictions =[]\n",
    "    for i in range (0,len(training_data_net)):\n",
    "        prediction_joint = model(training_data_net[i])\n",
    "        \n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_net)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    return accuracy, macro_f1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_val(model, training_data_net, ground_truths):\n",
    "    predictions =[]\n",
    "    val_losses = []\n",
    "    loss_function = nn.NLLLoss()\n",
    "    for i in range (0,len(training_data_net)):\n",
    "        prediction_joint = model( training_data_net[i])\n",
    "        val_loss = loss_function(prediction_joint, ground_truths[i])\n",
    "        val_losses.append(val_loss.item())\n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_net)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    \n",
    "    #print(type(predictions), type(ground_truths))\n",
    "    #print(\"predictions\", predictions)\n",
    "    #print(\"ground_truths\", ground_truths)\n",
    "    \n",
    "    return accuracy, macro_f1, val_losses\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########......prepare training and validation data\n",
    "# ground truth training\n",
    "train_gt = find_groundtruth(train_data, df)\n",
    "#####prepare training data for neural net #########\n",
    "training_data_net =  nn_input_network(train_data,df)\n",
    "#print(training_data_net, len(training_data_net)) #ok\n",
    "#training_data_des, training_data_loc =  nn_input(train_data,df)\n",
    "\n",
    "# ground truth validation\n",
    "valid_gt = find_groundtruth(valid_data, df)\n",
    "#####prepare validation data for neural net #########\n",
    "validation_data_net =  nn_input_network(valid_data,df)\n",
    "#validation_data_des, validation_data_loc =  nn_input(valid_data,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Starting with epoch:  0 ***********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tunaz/miniconda2/envs/py3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 Train accuracy and macro_f1: 0.6975903614457831 0.4624112749112748\n",
      "epoch : 0 Validation accuracy, macro_f1: 0.7378640776699029 0.4809363835119715\n",
      "train loss per epoch 1.0020748778998134\n",
      "Validation loss per epoch: 0.9115864313343196\n",
      "*************** Starting with epoch:  1 ***********************\n",
      "epoch : 1 Train accuracy and macro_f1: 0.755421686746988 0.5136709496997599\n",
      "epoch : 1 Validation accuracy, macro_f1: 0.8009708737864077 0.534611395496671\n",
      "train loss per epoch 0.9428080602223614\n",
      "Validation loss per epoch: 0.7731293778396348\n",
      "*************** Starting with epoch:  2 ***********************\n",
      "epoch : 2 Train accuracy and macro_f1: 0.7590361445783133 0.517356787707841\n",
      "epoch : 2 Validation accuracy, macro_f1: 0.8106796116504854 0.5416001330671989\n",
      "train loss per epoch 0.892293600552532\n",
      "Validation loss per epoch: 0.6697730063234718\n",
      "*************** Starting with epoch:  3 ***********************\n",
      "epoch : 3 Train accuracy and macro_f1: 0.7566265060240964 0.5160242092445858\n",
      "epoch : 3 Validation accuracy, macro_f1: 0.8203883495145631 0.5488704357482638\n",
      "train loss per epoch 0.8506581841463066\n",
      "Validation loss per epoch: 0.5985187934440317\n",
      "*************** Starting with epoch:  4 ***********************\n",
      "epoch : 4 Train accuracy and macro_f1: 0.7578313253012048 0.5171695327345102\n",
      "epoch : 4 Validation accuracy, macro_f1: 0.8252427184466019 0.5524778687846447\n",
      "train loss per epoch 0.817812542958432\n",
      "Validation loss per epoch: 0.5586121912720134\n",
      "*************** Starting with epoch:  5 ***********************\n",
      "epoch : 5 Train accuracy and macro_f1: 0.7590361445783133 0.5180754749579137\n",
      "epoch : 5 Validation accuracy, macro_f1: 0.8349514563106796 0.5596404420254\n",
      "train loss per epoch 0.7927400752363435\n",
      "Validation loss per epoch: 0.5396299023651382\n",
      "*************** Starting with epoch:  6 ***********************\n",
      "epoch : 6 Train accuracy and macro_f1: 0.7602409638554217 0.5189802236684148\n",
      "epoch : 6 Validation accuracy, macro_f1: 0.8300970873786407 0.556494244355516\n",
      "train loss per epoch 0.7735521350485528\n",
      "Validation loss per epoch: 0.5310909059441206\n",
      "*************** Starting with epoch:  7 ***********************\n",
      "epoch : 7 Train accuracy and macro_f1: 0.7650602409638554 0.5223731597902318\n",
      "epoch : 7 Validation accuracy, macro_f1: 0.8300970873786407 0.556494244355516\n",
      "train loss per epoch 0.7585055534649326\n",
      "Validation loss per epoch: 0.5273948948360184\n",
      "*************** Starting with epoch:  8 ***********************\n",
      "epoch : 8 Train accuracy and macro_f1: 0.7650602409638554 0.5225874827305589\n",
      "epoch : 8 Validation accuracy, macro_f1: 0.8300970873786407 0.556494244355516\n",
      "train loss per epoch 0.7463517015637803\n",
      "Validation loss per epoch: 0.5258989065017515\n",
      "*************** Starting with epoch:  9 ***********************\n",
      "epoch : 9 Train accuracy and macro_f1: 0.7662650602409639 0.5234864130577583\n",
      "epoch : 9 Validation accuracy, macro_f1: 0.8300970873786407 0.556494244355516\n",
      "train loss per epoch 0.7362484991694072\n",
      "Validation loss per epoch: 0.525479315843397\n",
      "*************** Starting with epoch:  10 ***********************\n",
      "epoch : 10 Train accuracy and macro_f1: 0.7686746987951807 0.5251795914720984\n",
      "epoch : 10 Validation accuracy, macro_f1: 0.8252427184466019 0.5533520793251443\n",
      "train loss per epoch 0.7276413727498655\n",
      "Validation loss per epoch: 0.525594810258995\n",
      "*************** Starting with epoch:  11 ***********************\n",
      "epoch : 11 Train accuracy and macro_f1: 0.7710843373493976 0.5270708908821297\n",
      "epoch : 11 Validation accuracy, macro_f1: 0.8300970873786407 0.556896551724138\n",
      "train loss per epoch 0.7201596715723175\n",
      "Validation loss per epoch: 0.5260084161480654\n",
      "*************** Starting with epoch:  12 ***********************\n",
      "epoch : 12 Train accuracy and macro_f1: 0.7746987951807229 0.5297477152219994\n",
      "epoch : 12 Validation accuracy, macro_f1: 0.8300970873786407 0.556896551724138\n",
      "train loss per epoch 0.713539810894373\n",
      "Validation loss per epoch: 0.52658694027697\n",
      "*************** Starting with epoch:  13 ***********************\n",
      "epoch : 13 Train accuracy and macro_f1: 0.7759036144578313 0.5306378443633345\n",
      "epoch : 13 Validation accuracy, macro_f1: 0.8300970873786407 0.556896551724138\n",
      "train loss per epoch 0.7075980218675584\n",
      "Validation loss per epoch: 0.5272301221356809\n",
      "*************** Starting with epoch:  14 ***********************\n",
      "epoch : 14 Train accuracy and macro_f1: 0.7771084337349398 0.5315269165941229\n",
      "epoch : 14 Validation accuracy, macro_f1: 0.8300970873786407 0.5572750347989847\n",
      "train loss per epoch 0.7022036234777137\n",
      "Validation loss per epoch: 0.5280931923285271\n",
      "*************** Starting with epoch:  15 ***********************\n",
      "epoch : 15 Train accuracy and macro_f1: 0.7746987951807229 0.5299290245587589\n",
      "epoch : 15 Validation accuracy, macro_f1: 0.8300970873786407 0.5575396825396824\n",
      "train loss per epoch 0.6972537078389741\n",
      "Validation loss per epoch: 0.5289954820882927\n",
      "*************** Starting with epoch:  16 ***********************\n",
      "epoch : 16 Train accuracy and macro_f1: 0.7746987951807229 0.5299290245587589\n",
      "epoch : 16 Validation accuracy, macro_f1: 0.8203883495145631 0.5508658008658008\n",
      "train loss per epoch 0.6926716493787197\n",
      "Validation loss per epoch: 0.5299076066144461\n",
      "*************** Starting with epoch:  17 ***********************\n",
      "epoch : 17 Train accuracy and macro_f1: 0.7746987951807229 0.5299290245587589\n",
      "epoch : 17 Validation accuracy, macro_f1: 0.8203883495145631 0.5508658008658008\n",
      "train loss per epoch 0.6883955460695058\n",
      "Validation loss per epoch: 0.5308253090937161\n",
      "*************** Starting with epoch:  18 ***********************\n",
      "epoch : 18 Train accuracy and macro_f1: 0.7759036144578313 0.5307279067575633\n",
      "epoch : 18 Validation accuracy, macro_f1: 0.8155339805825242 0.5477114550069597\n",
      "train loss per epoch 0.6843773665273953\n",
      "Validation loss per epoch: 0.5318306486294108\n",
      "*************** Starting with epoch:  19 ***********************\n",
      "epoch : 19 Train accuracy and macro_f1: 0.7783132530120482 0.5324149414093179\n",
      "epoch : 19 Validation accuracy, macro_f1: 0.8155339805825242 0.5477114550069597\n",
      "train loss per epoch 0.6805788269172232\n",
      "Validation loss per epoch: 0.5328628428063347\n",
      "*************** Starting with epoch:  20 ***********************\n",
      "epoch : 20 Train accuracy and macro_f1: 0.7771084337349398 0.5316154764147981\n",
      "epoch : 20 Validation accuracy, macro_f1: 0.8155339805825242 0.5477114550069597\n",
      "train loss per epoch 0.6769706560938917\n",
      "Validation loss per epoch: 0.53400083869985\n",
      "*************** Starting with epoch:  21 ***********************\n",
      "epoch : 21 Train accuracy and macro_f1: 0.7783132530120482 0.5324149414093179\n",
      "epoch : 21 Validation accuracy, macro_f1: 0.8155339805825242 0.547979797979798\n",
      "train loss per epoch 0.6735264105593779\n",
      "Validation loss per epoch: 0.5351907370738613\n",
      "*************** Starting with epoch:  22 ***********************\n",
      "epoch : 22 Train accuracy and macro_f1: 0.7807228915662651 0.5341878866079175\n",
      "epoch : 22 Validation accuracy, macro_f1: 0.8155339805825242 0.547979797979798\n",
      "train loss per epoch 0.6702231995000335\n",
      "Validation loss per epoch: 0.5364594011052141\n",
      "*************** Starting with epoch:  23 ***********************\n",
      "epoch : 23 Train accuracy and macro_f1: 0.7819277108433735 0.5350728258174663\n",
      "epoch : 23 Validation accuracy, macro_f1: 0.8155339805825242 0.547979797979798\n",
      "train loss per epoch 0.6670437658886355\n",
      "Validation loss per epoch: 0.5378140319608947\n",
      "*************** Starting with epoch:  24 ***********************\n",
      "epoch : 24 Train accuracy and macro_f1: 0.7819277108433735 0.5350728258174663\n",
      "epoch : 24 Validation accuracy, macro_f1: 0.8155339805825242 0.547979797979798\n",
      "train loss per epoch 0.663972734457039\n",
      "Validation loss per epoch: 0.5392843343100502\n",
      "*************** Starting with epoch:  25 ***********************\n",
      "epoch : 25 Train accuracy and macro_f1: 0.7843373493975904 0.5368396842820553\n",
      "epoch : 25 Validation accuracy, macro_f1: 0.8155339805825242 0.547979797979798\n",
      "train loss per epoch 0.6609969699280587\n",
      "Validation loss per epoch: 0.540851093322328\n",
      "*************** Starting with epoch:  26 ***********************\n",
      "epoch : 26 Train accuracy and macro_f1: 0.7867469879518072 0.5386726445214319\n",
      "epoch : 26 Validation accuracy, macro_f1: 0.8106796116504854 0.5444663382594417\n",
      "train loss per epoch 0.6581053030033401\n",
      "Validation loss per epoch: 0.5424117885747002\n",
      "*************** Starting with epoch:  27 ***********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 27 Train accuracy and macro_f1: 0.791566265060241 0.5420398906846838\n",
      "epoch : 27 Validation accuracy, macro_f1: 0.8106796116504854 0.5444663382594417\n",
      "train loss per epoch 0.6552885296986969\n",
      "Validation loss per epoch: 0.5440545722986888\n",
      "*************** Starting with epoch:  28 ***********************\n",
      "epoch : 28 Train accuracy and macro_f1: 0.791566265060241 0.5420398906846838\n",
      "epoch : 28 Validation accuracy, macro_f1: 0.8106796116504854 0.5444663382594417\n",
      "train loss per epoch 0.6525368527005112\n",
      "Validation loss per epoch: 0.5457562232769809\n",
      "*************** Starting with epoch:  29 ***********************\n",
      "epoch : 29 Train accuracy and macro_f1: 0.7927710843373494 0.542918394403543\n",
      "epoch : 29 Validation accuracy, macro_f1: 0.8106796116504854 0.5444663382594417\n",
      "train loss per epoch 0.6498451328217744\n",
      "Validation loss per epoch: 0.5476069163928912\n"
     ]
    }
   ],
   "source": [
    "###########.........Start Training...........\n",
    "model = Net()\n",
    "##### Hyperparameter\n",
    "#learning_rate=0.005\n",
    "learning_rate=0.01\n",
    "epochs = 30\n",
    "#opt=\"ADAM\"\n",
    "#opt=\"SGD\" \n",
    "opt=\"ADA\"\n",
    "if(opt==\"SGD\"):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "elif(opt==\"ADA\"):\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=learning_rate, eps=1e-06, weight_decay=0.0001)\n",
    "elif(opt==\"ADAM\"):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "\n",
    "    \n",
    "loss_function = nn.NLLLoss()\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "check_val_acc = 0\n",
    "losses = []\n",
    "per_epoch_train_loss =[]\n",
    "per_epoch_val_loss =[]\n",
    "per_epoch_train_f1 =[]\n",
    "per_epoch_val_f1 = []\n",
    "for epoch in range(epochs): \n",
    "    print('*************** Starting with epoch: ', epoch, '***********************')\n",
    "    for i in range (0,len(train_data)):\n",
    "        #model_des.zero_grad()\n",
    "        #model_loc.zero_grad()\n",
    "        model.zero_grad()\n",
    "        #####Run forward pass.\n",
    "      \n",
    "        prediction_joint = model(training_data_net[i])\n",
    "        \n",
    "        #print(\"prediction_joint :\", torch.argmax(prediction_joint, dim=1)) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        #Compute the loss, gradients, and update the parameters by\n",
    "        #calling optimizer.step()\n",
    "        loss = loss_function(prediction_joint, train_gt[i])\n",
    "        #if (i%200 == 0):\n",
    "            #print (\"loss per example\", loss.item())\n",
    "        losses.append(loss.item())\n",
    "        loss.backward(retain_graph=True)  #backpropagation\n",
    "        optimizer.step()\n",
    "    accuracy, macro_f1 = make_prediction_tr(model, training_data_net, train_gt)\n",
    "    print('epoch :', epoch, 'Train accuracy and macro_f1:', accuracy, macro_f1)\n",
    "    per_epoch_train_f1.append(macro_f1)\n",
    "    val_accuracy, val_macro_f1, val_loss = make_prediction_val(model, validation_data_net, valid_gt)\n",
    "    per_epoch_val_f1.append(val_macro_f1)\n",
    "    print('epoch :', epoch, 'Validation accuracy, macro_f1:', val_accuracy, val_macro_f1)\n",
    "    per_epoch_train_loss.append(np.mean(losses))\n",
    "    print(\"train loss per epoch\", np.mean(losses))\n",
    "    per_epoch_val_loss.append(np.mean(val_loss))\n",
    "    print('Validation loss per epoch:', np.mean(val_loss))\n",
    "    \n",
    "    torch.save(model.state_dict(),\"data/Net_umotivation_2layer/Net_\"+str(epoch)+\".pt\")\n",
    "#     if (check_val_acc < val_macro_f1): #early stopping\n",
    "#         check_val_acc = val_macro_f1\n",
    "#         print (\"Model saved at epoch :\", epoch)\n",
    "#         torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "#         best_epoch = epoch\n",
    "        \n",
    "#print(\"Best model found at epoch : \", best_epoch)        \n",
    "#torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU9dX48c/JvhJCQkjYF5F9NaKIte4CLrhQS237q1oflNalfWqrtU+faqutdrFqa6G0YutT16K44tqiaN1IEBCiyA5hyQZkX2fO7487GYaQDBPIZGYy5/165ZV779x751xH5uS7i6pijDHGdCQm1AEYY4wJb5YojDHG+GWJwhhjjF+WKIwxxvhlicIYY4xfcaEOoCtlZ2fr0KFDQx2GMcZEjMLCwnJV7evvnB6VKIYOHUpBQUGowzDGmIghIjuOdo5VPRljjPHLEoUxxhi/LFEYY4zxyxKFMcYYv4KaKERkpohsFJHNInJ7O6+fKSKVIrLG8/O/Pq/1FpGlIvK5iHwmItODGasxxpj2Ba3Xk4jEAg8D5wHFwCoReVFVi9qc+q6qXtTOLR4EXlPVuSKSAKQEK1ZjjDEdC2aJYhqwWVW3qmoT8BQwJ5ALRaQXcAbwCICqNqnqwaBFaowxpkPBTBQDgF0++8WeY21NF5G1IvKqiIzzHBsOlAGPisgnIvJXEUkNYqw9S9ELsPRa2Ls21JEYY3qAYCYKaedY28UvVgNDVHUS8Afgec/xOGAqsFBVpwC1wBFtHAAiMl9ECkSkoKysrGsij2T7PoVnr4P1z8LiM2H5j6ChMtRRGWMiWDATRTEwyGd/ILDH9wRVrVLVGs/2ciBeRLI91xar6keeU5fiJI4jqOpiVc1X1fy+ff2OQu/5mupg6bfB1QS5EwCBj/8MfzwZ1v0TbJEqY8wxCGaiWAWMFJFhnsboecCLvieISK6IiGd7mieeClXdB+wSkVGeU88B2jaCm7ZevwPKN0L2KLj2Dbj+HRh0CtSUwHPXwWOXQNkXoY7SGBNhgtbrSVVbRORG4HUgFliiqhtE5AbP64uAucACEWkB6oF5emht1puAxz1JZitwTbBi7RE+ewkKH4XYBJj7CCSkOKWKa16DNY/Dm/8L21bCwtNgxs3wpVudc0zXU4XmOmisgaYaaKx2fppqPMeqnd/JmTD56xBjw5lMeJOetGZ2fn6+RuWkgJW7YdEMqD8AM++FUxcceU7dfnjrTlj9d2c/YzDM/jWMmtWtoQadqxnKN4G6u/i+jc5/37oDUL/fs73f2a7z7Lceb6wO/P3P+V/40g+6NlZjOkFEClU13+85liginNsFj82B7e/CCefB1/8J0l4/Ao9dq+CV7zuN3gAnzoJxl9J+34NukJoNw8/qmr+qiwtg2fVQsfn473W84pIhMQ0S0jy/033200FinBKgxMA3l8HwM0MdsYlSgSSKHjXNeFR67/dOkkjNgUsX+k8SAINOhv96GwoegX/fDV+86vyE0qBT4ML7IXf8sV3f0gTv3Afv3e/8JZ+WCylZXRtjbJxTVZTcB1L6tNn27LceT+zlnH80qX1h5a+dDgjXr4SM9nqPGxN6VqKIZMUF8Mj5oC74xrNwwrmdu756H7z/B6gpDU58R6Ww9R2oLQWJhVNugLN+7PzFHaiSIlg231NCEjjtJjjrJxCfFLSou4zbBf+4AraugIHT4OpXIC4h1FGZKGNVTz1ZQxUsOh0O7oDpN8IF94Q6omNTfxBW/BJW/cUpDaTnwQW/hHGX+S8duV3wwcPw71843YF7D4HLFsGQ07ov9q5QWwF/PgOqip1EOeu+UEdkokwgicK6W0Sq5bc6SSJ3otMgGqmSezuN6v+1AgacBNV7Yek18H+XQnkHbQ37t8HfLoI3f+okiZOuhgX/ibwkAZCaBVf+HWLi4aNF8OnSUEdkzBEsUUSitU/DuqchPgXmLoG4xFBHdPz6T4ZvvwUXPQBJvWHr27BwutOO0lTnnKMKhX+DhTNg5/uQ1g+u+idc/GDnqqvCzcB8mPkrZ/vFm6H089DGY0wbligizf6t8IqnO+Ws+yB7ZGjj6UoxMZB/DdxUCFO+4ZQWVv4G/nSKM7L8iSvhpVuguRbGXgrf+RBOPD/UUXeNk6+DCVc6z/bMN50utsaECUsUkcTV7Mzj1FQNY+fAlG+GOqLgSM2GOQ/Dta9Dzjg4uNMZWb7pDUjKgCsega/8zell1FOIwMUPQN8xUP4FvHiTTbliwoYlikjy9q9gdyH0GuhUtxytK2ykG3yq0230gl861VEjL3BKERPm9sxnT0iFr/6fM+ZiwzKnzcKYMGC9niJBSxO8/Ut47wHnC/LqVyKz4fZ4qPbM5NCeohfgmf8HMXHOZz341FBHZHow6/XUE5R+Bn892xlYJwLn3xN9SQKiJ0mAU604/UZwt8A/rw7hOBdjHJYowpXbDR8uhD9/2RlM1nsIXPMqTP9OqCMz3eHcO2HwaZ7uwteCqyXUEZkoZlN4hKOqPfD8d5wRu+D0AJp5b2R3ATWdExsPX3kUFn3JmaLlN8OdqqijScuFs/8HRs8OfowmaliiCDfrn4OXvw8NB535ii5+CMZcFOqoTCik5zq9u566yvn/IRB1FfDU12DUbOePi8whQQ3RRAdLFOGioRKW/9AZSAcw8ny45I+Q3i+0cZnQGjoDfrDRWcviaFSdJXD/fTdsXA5bVsCXf+S0d9gcUuY4WK+ncLD9PVh2A1TucqanvuAeyL82uhpwTdep3uesdrj+WWc/+0S48Hcw7IzQxmXCkvV6igQfLnTmLarcBf2nwg3vwcnftiRhjl16rjO1yzefh6wTnAF8f78YnptvPajMMbESRSjt+hiWzHRmTf3yj+CMHzqNmMZ0lZZG+M9D8O5voaUBEjPgnJ86JdaY2NDE5Gp2YokEccmBrS0SwWya8XDmO034jFvgvJ+HOiLTk+3fBq/+yJkGBaD/FKcdrCt51wpvs0Z4Y/WhdcIbq51lZSNFch+nU8DEK3tsKd8SRThbtgDWPgF5k5xZU62x0QSbKnz+Mrx6G1TtDl0cEgtxSeH/xatuJ/EBjLkYLvw9pPUNbUxBYEuhhqv1zzlJIi4ZLv+rJQnTPUScL7zhZ8GaJ6B+f9e/R3yyM94nId357btOeGK6sx2fHP5JApzEuuZxePV2+Owl2PGBM3HjmItDHVm3sxJFd6sshoWnOd1hL7zfabg2xoSvgzvhhe/CtpXO/sSvOlP8J2eGNq4uYr2ewo3bBc9d7ySJE2c5DYrGmPDWezB88wWY9RunFmDd0/Cn02DzW6GOrNtYouhO7z8EO96D1ByY88fIKH4bY5xFtU6Z7yy5O3AaVO+Bf1wBL30vKhaZskTRXfZ84oyYBbh0obM4jzEmsmSNgGtfcyZtjE2AwkedpXm3/yfUkQWVNWZ3h6ZaZ2U6dwuccgOMPDfUERljjlVMLJz+fad78bLrndmd/3YhpIa4R9S1rzmJLAgsUXSH138CFZshZyyce1eoozHGdIV+4+C6fzuDGd/9HdSGeNS72xW0W1uiCLbPX3GKp7EJcPlfID4p1BEZY7pKXAKcdQecdrNTcxBKKVlBu7UlimCq3gcv3Ohsn3sX5I4PbTzGmOBITHN+ukGLy832ijqaWtyM7d+rW97TEkWwuN3w/AJnUNOIs522CWOM6YS9lfWs313FFyXVfFFSzcZ91Wwtq6XJ5Wb68CyenN8966lbogiWjxbBln87c8VcutDpXmeMiXp7DtZz5m/e7vD1xf/vJM4clQPAQ//azJMf7zzinAG9k8nL6L5qbEsUwbDvU3jrTmf7kj840z4bY6KSy62s2XWQk4YcGsnd5HJ3eL7vXBknDcmk+EAdI3PSGZWbxon90hnZL520xO796g7qFB4iMhN4EIgF/qqq97Z5/UzgBWCb59Bzqvpzn9djgQJgt6oedT3QsJjCo7EGFn/Z6eV00tVw8YOhjccYEzKbS6v50dJ1rCuu5IUbZzCufwaq6jdRxMfEEBPTfYNxQzopoOdL/mHgPKAYWCUiL6pqUZtT3/WTBG4BPgO6p8WmKyy/9VBX2Jn3Hv18Y0yP0+xys3jlVh58axNNLjc56YlU1jcDICIkxoVoLZBjFMzyyzRgs6puBRCRp4A5QNtE0S4RGQhcCNwD/HewguxSa56EtU8688HMfdSZJdMYE1XW767kR0vXUbS3CoCv5g/ijgvHkJEcuYuSBTNRDAB2+ewXA6e0c950EVkL7AFuVdUNnuMPAD8C0v29iYjMB+YDDB48+HhjPnblm+CVHzjbs38DOaNDF4sxJiSWfVLMrf9ch8utDMxM5t7LJ3L6yMifrieYiaK9Sra2DSKrgSGqWiMis4HngZEichFQqqqFnnaMDqnqYmAxOG0Uxx/2MWiuh39eDc21MOErMOUbIQnDGBNa04ZlkZIQyxVTB/LDC0aR2s2NzsESzKcoBgb57A/EKTV4qWqVz/ZyEfmTiGQDM4BLPMkjCeglIv9Q1fD8Bn79J1CyHvoMh4t+b7PCGhMFymsaeWXdXt76rIS/fiufxLhYBvRO5p0fnkWf1J61GFkwE8UqnNLBMGA3MA+4yvcEEckFSlRVRWQazmy2Far6Y+DHnnPOxKmSCs8kUfQCFDziTNEx91FnFS9jTI9U29jCG0X7eP6TPby3uRyX26nEeGdjGeePc7rB97QkAUFMFKraIiI3Aq/jdI9doqobROQGz+uLgLnAAhFpAeqBeRpJS+4d2A4v3ORsn/cL6D85pOEYY4KjvsnFbc+u482iEuqbncn34mKEs0fnMGdy/x7RDuFPUCvQVHU5sLzNsUU+238E/niUe7wNvB2E8I6PqxmWfhsaK2HUhXDK9aGOyBjTRdxupWhvFeMHZACQFB9D0d4q6ptdnDQkk0sn92f2hDyy0hJDHGn36BktLaHwr5/D7gLoNdBWqzOmB1BVPt1dycvr9vLy2j3sqWxg5Q/PYnBWCiLCry6fQG6vJAb1SQl1qN3OEsWx2PSms6ypxMLcJZDSJ9QRGWOOgaqysaSal9fu5aV1e9hRUed9rX9GEsUH6hic5SSGk4dG779zSxSdVbXXWdUK4OyfwOD2hoYYYyJBfbOLOX/8D40tzpQa2WmJXDQxj4sm5jF1cGa3TqURzixRdIbbBc/9F9RVwPCzYMb3Qx2RMVGpodnF5tIaNu6r5ovSar7YV830EVnMP8NZCrR1dHR7YmOEZxecRkJcDCkJcVw+dSAAF0/K45RhWcRacjiCJYrO+OBh2P4upObA5Ytt6nBjgqzF5SYu9tC/szuWfcoHWyrYUVGLu03/yGHZhxYOqmtyeafQaM97m8s4e3Q/AH51+YSuDboHskTRGV+85vyedS+k5YQ2FmN6qIZmF29vLOWltXtZsbGUgv85l5QE56uq+EA928priY0RTuibyqh+6ZzYz5mCe+LA3t57jOvfi5dvOr3d+8eIMLxvarc8S09hiaIzqvc5v/vZkqbGdKVml5v3Npfz0po9vFFUQk1ji/e1beW1jOvvdFP90QWj+PGs0Qzvm+p3BtbUxDhv11Zz/CxRdEZNqfPbShPGdJnS6gbO//1KDtY1e49NGJDBxZPyuHBifwb0PjQLs335h4YlikA11UJTNcQmQlLvo59vTIRzu5XVOw+w60AdZ4zse9yDy5pdbnZU1LGlrIZt5bXc8GWn4TknPYmc9ET6piVyyaT+XDSpP8OyrWoonFiiCFRrtVN6PxtcZ3osl1v5eNt+Xl2/l9fW76O0uhGAl2863Zso/vafbWwsqWZE3zRG9E1jeN9UBmamHNFbaFt5LU99vJMtZbVsLathx/4679xIALPG5zIky0kI/7z+NDJSIne9hp7OEkWgvNVO/UIbhwk7lXXNfFFazcZ91Wwrr2VodioXjOtHTnpSqEML2MG6Jn79+kbe2LCP8pom7/EBvZMZ27/XYY2///q8lHc3lR92fUJcDAMzk7ls8gBuOmckAPtrm/jzyq3ec0RgUJ9kRvRNY0xeL+J9ejNZkghvligCVeMpUViiiFout3r/aq6sa+bmpz5h475q9lU1HHFucnwsc09y+uc3NLtIjItBwqgk2tjiYuO+am9PodTEOF5Zt5fK+maGZKUwa3wesyfkMmFAxhFx33zOSM4ZncPW8lq2lNWwpbSWfVUNbC2rZW3xQe95I/ul8d/nneiUPHJSGZqVSlJ8ZC0BahyWKAJVXeL8Ts8NbRwm6JpdbraX1/L5vmq+KHFKCl+UVNMnNYHnvjMDgLSkOD7cWkFji5uk+BhG5jjdNIdlp7CuuJKzRx/q8PCLl4t4d1M5543tx3lj+5E/JPOwsQHB1NDsYmuZ5wu9rOawbVVY/dPzSE2MIz42hvuumMDgPqmMyUv3m9ROHtrniOksahpb2FlRR3baoSm2eyXFc7OndGEimyWKQNV4EoWVKHoMt1spPlBPRnK8t+pj4dtbuP/NjTS7jpztfn9tE6qKiBAbIzx69cn0753MoD5H1s/7Wr3zIDv31/HIe9t45L1tZKbEc/bofpw6vA9TBmdyQo4zUGzX/jpW7zzQ4X0unJDnTTDvbipjf23TEedU1TczNDuVL43sC8AHWyq45m+r2r3f6Nx09hysZ2Q/Zw2VmePzOnzvo0lLjGNs/17HfL0Jb5YoAmWJoseoa2rh0f9s56/vbuVAXTO//cokbzVRVmoCzS5lcJ8U70Au53c6w7PTDvtL+7QTAluD4OWbTmf1zgO8WVTCGxv2sb2ijmdXF/Ps6mJ+etFYb6JYtX0///3M2g7vc8G4XFqHDjz41iYKdrSfVC6fOsCbKE7ISWNE31SGexqeD22n0jul5y2wY4LDEkWgLFFEvIZmF49/tJOFb2/2Ntj2TU+kscXlPeeiSXlcODGvS9c6jo0Rb3XNj2eNZnNpDW8UlfBFSfVhjcQDM1O4ZFL/Du8T45OkZpyQTX+f8QWtkuNjmT4iy7s/qE8K//rBmV3zICZqWaIIlLeNwhJFJHpp7R5+ufwz9lY6Dc+TBvXmh+ePYsYJWYeVElqniggWEWFkv3RvdY+vacP6MG1YYFNZf/+8E7s6NGM6ZIkiUN5eT9aYHYmqGprZW9nA6Nx0bj1/FOeMyQmrXkjGhDNLFIFwtUBtOSCQ2jfU0ZijUFVeW7+P8tomvnnqEACuzB9EVmoi54/tZ2sMGNNJligCUVsGqJMkYu0/WbhqaHbxZlEJf165hfW7q0hJiGXW+Fyy0xKJj41h5ngrDRpzLOxbLxBW7RS2VJVV2w/w3OpiXvl0L9UNzqyjOemJ3HT2CfRKshG/xhwvSxSBsFljw9b2ijqu/PMH3v2JAzO4YupArswfRHKCjQI2piscU6IQkcWqOr+rgwlb3gkBrUQRSgfrmnh53V7W7DrIb78yCYBh2anMGp/L0OxULp8yoN3eRMaY49NhohCRjvrpCTA7OOGEKStRhExNYwsrPi/llXV7+ffnpTS53AB8+/RhjMlzRgIv/MZJoQzRmB7PX4miDNiBkxhaqWc/ur4xrY2i25VUNfDT59fzzhdlNLY4yUEEvjQym8unDmBIVkqIIzQmevhLFFuBc1R1Z9sXRGRX8EIKQ75rUZigOFjXRNHeKk4b4UyL0Tslnve3VNDkcnPy0Exmjs/jwgl55GZEztTdxvQU/hLFA0AmcESiAH4dnHDClK1F0eVcbmXX/jo+3FrB8vX7eH9zOfGxMaz+6XkkJ8SSGBfLn74+lVG56fTrZcnBmFDqMFGo6sN+XvtDcMIJU7YWxTFTVc9U3E4PpKI9Vdz+3Dq+KKmmodntPS82Rpg6pDflNY0M6uNUK51xog1uNCYc+GvM/qWq3uHZPk9V3+y+sMKIqpUoPNxupb7Z5fw0ucjNSPKuUrZ210F2HaijrslFXWML23zWczh7dD9+d6XTSyk9KY51xZUA5PZKYlz/Xpw/rh/njc2lT6rNZmpMOPJX9TQTuMOzfR8QnYmioRJaGiAhDRLTQh1NSJRUNfCzFzbwRtE+fJY8ZsWtZzIs25n99C/vbuXldXvbvX7XgTrv9oDeyTw9/1RG5abbNNfGRAgbcHc0UTy9uKqytLCYX7xcRJVnxHNyfCzJCbEkx8fich+qOpo6OBO3KknxsaQkxDIoM4UTc9MZnZtOrk8bQ0yMcMrwrCPeyxgTvvwlihwR+W883WE9216qen9QIwsXUZwoaptc/O6NL6hqaOGsUX355eUTyMs4cg0EgGtPH8a1pw/r5giNMd3BX6L4C5DeznbARGQm8CAQC/xVVe9t8/qZwAvANs+h51T15yIyCHgMyAXcwGJVfbCz798lomwdCrdbaXErCXExpCXGcd/cieyvbeTSyQNsWm5jopS/Xk93Hc+NRSQWeBg4DygGVonIi6pa1ObUd1X1ojbHWoAfqOpqEUkHCkXkzXauDb4oGmy3s6KO255dx8SBGfx49hgAvmw9j4yJejFBvPc0YLOqblXVJuApYE4gF6rqXlVd7dmuBj4DBgQtUn+8VU89dzC6y60seW8bFzywkg+2VvDcJ7upaWwJdVjGmDARzMbsAYDvCO5i4JR2zpsuImuBPcCtqrrB90URGQpMAT5q701EZD4wH2Dw4MHHHfQRvFVPPbNEsbm0htueXUfhjgMAXDKpPz+7eCxpXbhmtDEmsgXz26C9Cm1ts78aGKKqNSIyG3geGOm9gUga8CzwPVWtau9NVHUxsBggPz+/7f2PXw9pzG5scbG9vI5RuYeamq5Y+L43QeSkJ3L3peM5f1zPTIjGmGN31ETRtreTRyVQqKpr/FxaDAzy2R+IU2rw8v3yV9XlIvInEclW1XIRicdJEo+r6nNHizNoIixRuN3KrgN1fL6vmo2tPyXVbCuvxeVW1v7sfDKSncV8MlPiSYqPYc6kAdwxewwZKbbIjzHmSIGUKPI9Py959i8EVgE3iMg/VbWjeZ9WASNFZBiwG5gHXOV7gojkAiWqqiIyDafNpEKc7jWPAJ+FvBtuGK9FUV7TyMZ91aQlxjFpUG8AVm4q4+pHVx1xbozA8L6plFU3ehPF774ymbSkOGJtDWljjB+BJIosYKqq1gCIyM+ApcAZQCEdTBCoqi0iciPwOk732CWqukFEbvC8vgiYCywQkRagHpjnSRqnA98EPhWR1lLLHaq6/Fgf9Ji0NELDQYiJg+SOluc40payGh54axOxAqeNyGb6iCzv/EXHalt5LYU7DlC0p4qNJVVs3FdNeU0T4LQrPPS1KQCMyk0nJz2RUZ7BbqNyezE6N50TctK88y21shKEMSYQgSSKwUCTz34zTrtCvYg0+rvQ88W+vM2xRT7bfwT+2M5179F+G0f3aq12Ss2BmMA7iO2sqOOltU4t2/NrnN+D+6Rw2ogspo/I4oJxuUd8afuqbmhm7a5K8odmes+766UNvL2x7LDzUhNiOdGTBFrlZSTz8U/ODThWY4w5mkASxRPAhyLygmf/YuBJEUkFun9cQ3fqxGC7phY3CXFOMjlrdA53Xzqe2sYWVu88wAdbKti5v46d++tYWljMeXceut/qnQdIjo/l092VfLLzAKt3HOSL0mpU4Z83TOfkoU5J5qxROSTFxTJhYAaj+qUzKjedAb2TibFqI2NMkB01UajqL0RkOXA6zl/5N6hqgeflrwczuJALsCH7P5vL+dHSdTw4bzL5ni/2b5w6xPu6y60U7ani/S3llNc0kpLg/Gd3u5VrHl1FZX3zYfeLjxXG9c+gueXQXErfOm0o3zptaBc8lDHGdE4gvZ4eBJ4O2RQaoXSUdSiaWtz87o2NLH53K6rw2Ac7vInCV2yMMGFgBhMGZhx2/EBdE6Nz09lTWc/4/hlMHZzJ1CG9Gdc/w2/VlDHGdKdAqp5WA/8jIicCy3CSRsFRrukZWtehaKfH0+bSGr739Ces311FjMAt547kxrNO6NTts9ISefr66V0RqTHGBE0gVU9/B/4uIn2AK4D7RGSwqo48yqWRr7VrrM/0HarKkx/v4ucvb6Ch2c3AzGQenDeZk4YE3ivKGGMiSWdGZp8AjAaG0tMbsVt52ygOlSgO1DXz69c/p6HZzWVTBnDXnHH0SrJupsaYniuQNor7gMuBLcAzwC9U9WCwAwsL7TRm90lN4LdzJ1Hb1MKcyaGZp9AYY7pTICWKbcB0VS0PdjBhp4PuseeOjYzpPIwxpisE0kaxSEQyPVNsJPkcXxnUyELN7YZaT2O2p0Tx1Mc76ZUcz7lj+nnHTBhjTE8XSNXTdcAtOJP6rQFOBT4Azg5uaCFWvx/cLZDUG+ISaXG5uWPZp7gVNt0zK9TRGWNMtwnkz+JbgJOBHap6Fs7aEGX+L+kB2kwGWFHbhFshOy2B+FgrTRhjokcg33gNqtoAICKJqvo5MCq4YYWBNg3ZJVUNAOSkJ3V0hTHG9EiBNGYXi0hvnEWF3hSRA7RZV6JHapMoSquc+Q/79UoMVUTGGBMSgTRmX+bZvFNEVgAZwGtBjSoceKuePCWKaitRGGOiU2cr20ep6ouq2nT0UyNczeE9nkqsRGGMiVKdTRQ3BCWKcOSdENBpzK5tbEEEcnpZicIYE106M4UHhMNiQt3FOyGgU6L46UVjuX3WaFxuDWFQxhjT/TqbKC4KShThqPrIKcbjY2Ow2b+NMdHmqFVPIpIhIr8XkQLgBRH5nYhkHO26iBfgokXGGNPTBdJGsQSoAq70/FQBjwYzqJBrrIGmGohLgqQMml1uvvTrfzN34fuoWtWTMSa6BFL1NEJVr/DZv0tE1gQroLDgLU3kgAjlNQ3s2l9PQ7MbkehppjHGGAisRFEvIqe37ojIDKA+eCGFgTbrUFjXWGNMNAukRHED8JhPu8QB4FvBCykM+JYogFKbvsMYE8X8JgoRicEZZDdJRHoBqGpVt0QWSt51KDwlimorURhjopffqidVdQM3eraroiJJwBFVT1aiMMZEs0DaKN4UkVtFZJCI9Gn9CXpkoXRE1VNricIShTEm+gTSRnGt5/d3fY4pMLzrwwkTbdai+PKovqQkxjJ+QK8QBmWMMaERyOyxw7ojkLDSZkLA2RPymD0hL4QBGWNM6AQyMvu7nvUoWvczReQ7wQ0rxGqOnL7DGGOiVSBtFP46Zd0AABSCSURBVP+lqgdbd1T1APBfwQspxFwtUFsOCKT2pdnl5tVP9/LJzgOhjswYY0IikEQRIz7DkUUkFkgIXkghVlsGKKRmQ2wcZdWNLHh8NTf8ozDUkRljTEgEkiheB54RkXNE5GzgSQJc4U5EZorIRhHZLCK3t/P6mSJSKSJrPD//G+i1QdNmHYrWtbKtx5MxJloF0uvpNuB6YAHOehRvAH892kWeksfDwHlAMbBKRF5U1aI2p76rqhcd47Vdr806FK3Td+Sk22A7Y0x0CqTXkxtY6PnpjGnAZlXdCiAiTwFzgEC+7I/n2uPTZh2K0ta1sq1EYYyJUoH0ehopIktFpEhEtrb+BHDvAcAun/1iz7G2povIWhF5VUTGdfJaRGS+iBSISEFZWVkAYR1Fm3UovIPtbFS2MSZKBdJG8ShOaaIFOAt4DPi/AK5rbz7utos5rAaGqOok4A/A85241jmoulhV81U1v2/fvgGEdRQ1beZ58rZRWNWTMSY6BZIoklX1X4Co6g5VvRM4O4DrioFBPvsDgT2+J3jmj6rxbC8H4kUkO5Brg8Zb9eRM33FoQkArURhjolMgjdkNnllkN4nIjcBuICeA61YBI0VkmOeaecBVvieISC5QoqoqItNwElcFcPBo1waNd1S2U6L46//Lp6ymkcyU+G55e2OMCTeBJIrvASnAzcAvcEoTR12PQlVbPInldSAWWKKqG0TkBs/ri4C5wAIRacFZDGmeOmuNtnttp5/uWLR2j/X0ekqIi2FA7+RueWtjjAlH0pPWgM7Pz9eCgoJjv4Eq3N0PXI1wxx5ISO264IwxJgyJSKGq5vs7p8MShYi86O9CVb3kWAMLWw2VTpJISIeEVPZW1nPjE58wJi+duy+dEOrojDEmJPxVPU3H6aL6JPAR7fdE6lnarEOx52ADhTsO0OJyhzAoY4wJLX+JIhdnZPTXcBqSXwGe7La2glBosw6Fd2U76/FkjIliHXaPVVWXqr6mqt8CTgU2A2+LyE3dFl13a7MORamtlW2MMf57PYlIInAhTqliKPAQ8FzwwwqRNutQeAfb2ahsY0wU89eY/XdgPPAqcJeqru+2qELFOyr78AkBbbCdMSaa+StRfBOoBU4EbvZdkgJQVe15C0hXtzZme9ooPBMC9rWqJ2NMFOswUahqINN79Cw1h0/fcdqIbNKT4hiaZeMpjDHRK5CR2dHDuxaFU6JYcOaIEAZjjDHhIfpKDf60WYvCGGOMJYpDmhug4SDExEFyH2obW1i984C355MxxkQrSxStan3GUMTE8NneKi7/0/tc/3+FoY3LGGNCzBJFq+rDp+841DXWejwZY6KbJYpWNe13jbUxFMaYaGeJolWbdShssJ0xxjgsUbTyVj155nlqnRAw3aqejDHRzRJFq5rDE0VJtc0ca4wxYInikLaJwhqzjTEGsJHZh3gnBHQasx+7dhp7Kxts+g5jTNSzRNGqTRtF/97J9O+dHMKAjDEmPFjVE4Db7TPgLie0sRhjTJixRAFQvx/cLZCcCXGJFO2p4ruPr2bJe9tCHZkxxoScJQrwmQzQaZ/YWl7DK5/uZdX2/SEMyhhjwoMlCjhiHQobbGeMMYdYooAj1qHwDrazrrHGGGOJAvCpemotUbSOyrYShTHGWKKAQyUKTxuFDbYzxphDLFGAz4SANnOsMca0ZQPu4Ii1KCYPyiQjOZ5+VvVkjDGWKIAj1qL43ZWTQhiMMcaEF6t6Ap95nvqFNg5jjAlDligaa6CpBuKSILEXNY0t7K2sp9nlDnVkxhgTFoKaKERkpohsFJHNInK7n/NOFhGXiMz1OfZ9EdkgIutF5EkRCU6Dge/04iL8+/NSpv/q33zvqTVBeTtjjIk0QUsUIhILPAzMAsYCXxORsR2cdx/wus+xAcDNQL6qjgdigXlBCbSmg5XtrGusMcYAwW3MngZsVtWtACLyFDAHKGpz3k3As8DJ7cSWLCLNQAqwJyhR5k6Aa98AcXJm62A76xprjDGOYFY9DQB2+ewXe455eUoOlwGLfI+r6m7gt8BOYC9QqapvtPcmIjJfRApEpKCsrKzzUSamw+BTYJCTp1oH29la2cYY4whmopB2jmmb/QeA21TVddiFIpk4pY9hQH8gVUS+0d6bqOpiVc1X1fy+ffsed9BWojDGmMMFs+qpGBjksz+QI6uP8oGnRAQgG5gtIi1APLBNVcsAROQ54DTgH0GMF4Cyapu+wxhjfAUzUawCRorIMGA3TmP0Vb4nqOqw1m0R+Rvwsqo+LyKnAKeKSApQD5wDFAQxVi/vhIBWojDGGCCIiUJVW0TkRpzeTLHAElXdICI3eF5f5Ofaj0RkKbAaaAE+ARYHK1af9+Wxb0+jtKqR9EQbtG6MMQCi2rbZIHLl5+drQUG3FDyMMaZHEJFCVc33d46NzDbGGOOXJQofq7bv5+cvFfFWUUmoQzHGmLBhFfE+Ptl5gCX/2QbAuWNtgkBjQqm5uZni4mIaGhpCHUqPkJSUxMCBA4mPj+/0tZYofNjKdsaEj+LiYtLT0xk6dCieLvTmGKkqFRUVFBcXM2zYsKNf0IZVPfmwwXbGhI+GhgaysrIsSXQBESErK+uYS2eWKHyUegbb2YSAxoQHSxJd53j+W1qi8OGdOdaWQDXGGC9LFB6qam0UxhivgwcP8qc//anT182ePZuDBw8GIaLQsUTh0djiZlRuOsP7ppJmo7KNiXodJQqXy9XO2YcsX76c3r17ByuskLBvRI+k+Fie/+6MUIdhjOnA0Ntf6fC1X142gatOGQzAEx/t5I5ln3Z47vZ7Lwzo/W6//Xa2bNnC5MmTiY+PJy0tjby8PNasWUNRURGXXnopu3btoqGhgVtuuYX58+c7cQ4dSkFBATU1NcyaNYvTTz+d999/nwEDBvDCCy+QnJzciacOD1aiMMaYdtx7772MGDGCNWvW8Jvf/IaPP/6Ye+65h6IiZ+21JUuWUFhYSEFBAQ899BAVFRVH3GPTpk1897vfZcOGDfTu3Ztnn322ux+jS1iJwqOh2UVcjBAXa7nTmHAUaEngqlMGe0sXXWnatGmHjUF46KGHWLZsGQC7du1i06ZNZGVlHXbNsGHDmDx5MgAnnXQS27dv7/K4uoN9K3r87f3tjPyfV7n/jY2hDsUYE4ZSU1O922+//TZvvfUWH3zwAWvXrmXKlCntjlFITDzUMSY2NpaWlpZuibWrWaLwKKlqQBXSkzo/vN0Y0/Okp6dTXV3d7muVlZVkZmaSkpLC559/zocfftjN0XUvq3ryKK2ywXbGmEOysrKYMWMG48ePJzk5mX79Ds3/NnPmTBYtWsTEiRMZNWoUp556aggjDT5LFB6l1TbYzhhzuCeeeKLd44mJibz66qvtvtbaDpGdnc369eu9x2+99dYuj6+7WNWThw22M8aY9lmioHVUtq2VbYwx7bFEAVTVt9DY4iY1IdZGZRtjTBv2rQgkxMXw8FVTqWuKzK5rxhgTTJYogOSEWC6cmBfqMIwxJixZ1ZMxxhi/LFEA/9lczuKVW1i/uzLUoRhjIlRaWhoAe/bsYe7cue2ec+aZZ1JQUOD3Pg888AB1dXXe/XCYttwSBfBmUQm/XP45H249clIvY4zpjP79+7N06dJjvr5togiHacutjQKfwXbWNdaY8HRnRpDu23Etwm233caQIUP4zne+45x6552ICCtXruTAgQM0Nzdz9913M2fOnMOu2759OxdddBHr16+nvr6ea665hqKiIsaMGUN9fb33vAULFrBq1Srq6+uZO3cud911Fw899BB79uzhrLPOIjs7mxUrVninLc/Ozub+++9nyZIlAFx33XV873vfY/v27UGfztxKFPgMtku3wXbGGMe8efN4+umnvfvPPPMM11xzDcuWLWP16tWsWLGCH/zgB6hqh/dYuHAhKSkprFu3jp/85CcUFhZ6X7vnnnsoKChg3bp1vPPOO6xbt46bb76Z/v37s2LFClasWHHYvQoLC3n00Uf56KOP+PDDD/nLX/7CJ598AgR/OnMrUYB3sF0/K1EYE578/OUfLFOmTKG0tJQ9e/ZQVlZGZmYmeXl5fP/732flypXExMSwe/duSkpKyM3NbfceK1eu5OabbwZg4sSJTJw40fvaM888w+LFi2lpaWHv3r0UFRUd9npb7733Hpdddpl3FtvLL7+cd999l0suuSTo05lHfaJQVZsQ0BjTrrlz57J06VL27dvHvHnzePzxxykrK6OwsJD4+HiGDh3a7vTivkTkiGPbtm3jt7/9LatWrSIzM5Orr776qPfxV3JpO525bxVXV4j6qqeDdc00udykJ8aRkhD1edMY42PevHk89dRTLF26lLlz51JZWUlOTg7x8fGsWLGCHTt2+L3+jDPO4PHHHwdg/fr1rFu3DoCqqipSU1PJyMigpKTksAkGO5re/IwzzuD555+nrq6O2tpali1bxpe+9KUufNqORf03Y1VDM3kZSWQk2zoUxpjDjRs3jurqagYMGEBeXh5f//rXufjii8nPz2fy5MmMHj3a7/ULFizgmmuuYeLEiUyePJlp06YBMGnSJKZMmcK4ceMYPnw4M2bM8F4zf/58Zs2aRV5e3mHtFFOnTuXqq6/23uO6665jypQp3bJqnvgrzkSa/Px8PVof5Y6oartFRGNMaHz22WeMGTMm1GH0KO39NxWRQlXN93dd1Fc9tbIkYYwx7QtqohCRmSKyUUQ2i8jtfs47WURcIjLX51hvEVkqIp+LyGciMj2YsRpjjGlf0BKFiMQCDwOzgLHA10RkbAfn3Qe83ualB4HXVHU0MAn4LFixGmPCU0+qGg+14/lvGcwSxTRgs6puVdUm4ClgTjvn3QQ8C5S2HhCRXsAZwCMAqtqkqqGd7MQY062SkpKoqKiwZNEFVJWKigqSko5trFgwez0NAHb57BcDp/ieICIDgMuAs4GTfV4aDpQBj4rIJKAQuEVVa9u+iYjMB+YDDB48uCvjN8aE0MCBAykuLqasrCzUofQISUlJDBw48JiuDWaiaK91uO2fBg8At6mqq01jchwwFbhJVT8SkQeB24GfHnFD1cXAYnB6PXVF4MaY0IuPj2fYsGGhDsMQ3ERRDAzy2R8I7GlzTj7wlCdJZAOzRaQF+BAoVtWPPOctxUkUxhhjulkwE8UqYKSIDAN2A/OAq3xPUFXvnwsi8jfgZVV93rO/S0RGqepG4BygKIixGmOM6UDQEoWqtojIjTi9mWKBJaq6QURu8Ly+6Ci3uAl4XEQSgK3ANcGK1RhjTMd61MhsESkD/E++0rFsoLwLwwm1nvY80POeqac9D/S8Z+ppzwNHPtMQVe3r74IelSiOh4gUHG0YeyTpac8DPe+ZetrzQM97pp72PHBsz2RTeBhjjPHLEoUxxhi/LFEcsjjUAXSxnvY80POeqac9D/S8Z+ppzwPH8EzWRmGMMcYvK1EYY4zxyxKFMcYYv6I+UQS6ZkYkEZHtIvKpiKwRkWNb8i+ERGSJiJSKyHqfY31E5E0R2eT5nRnKGDurg2e6U0R2ez6nNSIyO5QxdoaIDBKRFZ61YjaIyC2e4xH7Ofl5poj8nEQkSUQ+FpG1nue5y3O8059RVLdReNbC+AI4D2duqlXA11Q1oqcLEZHtQL6qRuRAIRE5A6gBHlPV8Z5jvwb2q+q9noSeqaq3hTLOzujgme4EalT1t6GM7ViISB6Qp6qrRSQdZ4bnS4GridDPyc8zXUkEfk7iTKKXqqo1IhIPvAfcAlxOJz+jaC9RBLpmhulGqroS2N/m8Bzg757tv+P8A44YHTxTxFLVvaq62rNdjbOw2AAi+HPy80wRSR01nt14z49yDJ9RtCeK9tbMiNj/MXwo8IaIFHrW6+gJ+qnqXnD+QQM5IY6nq9woIus8VVMRU03jS0SGAlOAj+ghn1ObZ4II/ZxEJFZE1uAsDPemZ0buTn9G0Z4oAlkzIxLNUNWpOMvQftdT7WHCz0JgBDAZ2Av8LrThdJ6IpOGsUPk9Va0KdTxdoZ1nitjPSVVdqjoZZ5mHaSIy/ljuE+2JIpA1MyKOqu7x/C4FluFUsUW6Ek8dcmtdculRzg97qlri+YfsBv5ChH1OnnrvZ4HHVfU5z+GI/pzae6ZI/5wAPEtJvw3M5Bg+o2hPFN41MzzTmc8DXgxxTMdFRFI9DXGISCpwPrDe/1UR4UXgW57tbwEvhDCWLtH6j9XjMiLoc/I0lD4CfKaq9/u8FLGfU0fPFKmfk4j0FZHenu1k4Fzgc47hM4rqXk8Anq5uD3BozYx7QhzScRGR4TilCHDWG3ki0p5JRJ4EzsSZDrkE+BnwPPAMMBjYCXxFVSOmcbiDZzoTpzpDge3A9a11x+FORE4H3gU+Bdyew3fg1OlH5Ofk55m+RgR+TiIyEaexOhanUPCMqv5cRLLo5GcU9YnCGGOMf9Fe9WSMMeYoLFEYY4zxyxKFMcYYvyxRGGOM8csShTHGGL8sURjTCSLi8plFdE1XzjgsIkN9Z5c1JlzEhToAYyJMvWdKBGOihpUojOkCnjVA7vPM//+xiJzgOT5ERP7lmVDuXyIy2HO8n4gs86wVsFZETvPcKlZE/uJZP+ANz4haY0LKEoUxnZPcpurpqz6vVanqNOCPOKP98Ww/pqoTgceBhzzHHwLeUdVJwFRgg+f4SOBhVR0HHASuCPLzGHNUNjLbmE4QkRpVTWvn+HbgbFXd6plYbp+qZolIOc5iOM2e43tVNVtEyoCBqtroc4+hOFNBj/Ts3wbEq+rdwX8yYzpmJQpjuo52sN3ROe1p9Nl2Ye2IJgxYojCm63zV5/cHnu33cWYlBvg6znKUAP8CFoB3cZle3RWkMZ1lf60Y0znJnhXDWr2mqq1dZBNF5COcP8C+5jl2M7BERH4IlAHXeI7fAiwWkW/jlBwW4CyKY0zYsTYKY7qAp40iX1XLQx2LMV3Nqp6MMcb4ZSUKY4wxflmJwhhjjF+WKIwxxvhlicIYY4xfliiMMcb4ZYnCGGOMX/8fJUyBoYrtWIoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_plots(train_losses, val_losses, train_accs, test_accs):\n",
    "    \"\"\"Plot\n",
    "\n",
    "        Plot two figures: loss vs. epoch and accuracy vs. epoch\n",
    "    \"\"\"\n",
    "    n = len(train_losses)\n",
    "    xs = np.arange(n)\n",
    "\n",
    "    # plot losses\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_losses, '--', linewidth=2, label='train loss')\n",
    "    ax.plot(xs, val_losses, '-', linewidth=2, label='validation loss')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.savefig('loss_Net_umotivation.png')\n",
    "\n",
    "    # plot train and test accuracies\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_accs, '--', linewidth=2, label='train')\n",
    "    ax.plot(xs, test_accs, '-', linewidth=2, label='validation')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Macro-avg F1\")\n",
    "    ax.legend(loc='lower right')\n",
    "    plt.savefig('accuracy_Net_umotivation.png')\n",
    "    \n",
    "save_plots(per_epoch_train_loss, per_epoch_val_loss, per_epoch_train_f1, per_epoch_val_f1)\n",
    "# print(per_epoch_train_loss)\n",
    "# print(per_epoch_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction(training_data_net, ground_truths):\n",
    "    for epoch in range(0,30):\n",
    "        model = Net()\n",
    "        model.load_state_dict(torch.load(\"data/Net_umotivation_2layer/Net_\"+str(epoch)+\".pt\")) \n",
    "        predictions =[]\n",
    "        for i in range (0,len(training_data_net)):\n",
    "            prediction_joint = model(training_data_net[i])\n",
    "            pred = torch.argmax(prediction_joint, dim=1)\n",
    "            predictions.append(pred.item())\n",
    "        #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "        accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_net)\n",
    "        macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "        print('epoch :', epoch, 'Testing accuracy, macro_f1:', accuracy, macro_f1)\n",
    "        #return accuracy, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "########.....Load Test data.......\n",
    "with open(\"data/test.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "test_data = data[:] \n",
    "#print(test_data, len(test_data)) #262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare testing data for neural net #########\n",
    "testing_data_net =  nn_input_network(test_data,df)\n",
    "test_gt = find_groundtruth(test_data, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 Testing accuracy, macro_f1: 0.732824427480916 0.5009413281753706\n",
      "epoch : 1 Testing accuracy, macro_f1: 0.7748091603053435 0.5307692307692308\n",
      "epoch : 2 Testing accuracy, macro_f1: 0.7748091603053435 0.5307871333672416\n",
      "epoch : 3 Testing accuracy, macro_f1: 0.7786259541984732 0.5333867850828501\n",
      "epoch : 4 Testing accuracy, macro_f1: 0.7824427480916031 0.535925108205057\n",
      "epoch : 5 Testing accuracy, macro_f1: 0.7786259541984732 0.5332633053221288\n",
      "epoch : 6 Testing accuracy, macro_f1: 0.7786259541984732 0.5332633053221288\n",
      "epoch : 7 Testing accuracy, macro_f1: 0.7786259541984732 0.5332633053221288\n",
      "epoch : 8 Testing accuracy, macro_f1: 0.7824427480916031 0.5358495231912953\n",
      "epoch : 9 Testing accuracy, macro_f1: 0.7824427480916031 0.5358495231912953\n",
      "epoch : 10 Testing accuracy, macro_f1: 0.7786259541984732 0.5331766258402408\n",
      "epoch : 11 Testing accuracy, macro_f1: 0.7786259541984732 0.5331766258402408\n",
      "epoch : 12 Testing accuracy, macro_f1: 0.7786259541984732 0.5331766258402408\n",
      "epoch : 13 Testing accuracy, macro_f1: 0.7824427480916031 0.5357575757575758\n",
      "epoch : 14 Testing accuracy, macro_f1: 0.7824427480916031 0.5357575757575758\n",
      "epoch : 15 Testing accuracy, macro_f1: 0.7824427480916031 0.5357575757575758\n",
      "epoch : 16 Testing accuracy, macro_f1: 0.7786259541984732 0.5330732069862504\n",
      "epoch : 17 Testing accuracy, macro_f1: 0.7748091603053435 0.5303812047122501\n",
      "epoch : 18 Testing accuracy, macro_f1: 0.7748091603053435 0.5303812047122501\n",
      "epoch : 19 Testing accuracy, macro_f1: 0.7748091603053435 0.5303812047122501\n",
      "epoch : 20 Testing accuracy, macro_f1: 0.7824427480916031 0.5353510295212106\n",
      "epoch : 21 Testing accuracy, macro_f1: 0.7862595419847328 0.5380559127789571\n",
      "epoch : 22 Testing accuracy, macro_f1: 0.7862595419847328 0.5380559127789571\n",
      "epoch : 23 Testing accuracy, macro_f1: 0.7900763358778626 0.5406226742743736\n",
      "epoch : 24 Testing accuracy, macro_f1: 0.7900763358778626 0.5406226742743736\n",
      "epoch : 25 Testing accuracy, macro_f1: 0.7938931297709924 0.5431891883504787\n",
      "epoch : 26 Testing accuracy, macro_f1: 0.7938931297709924 0.5431891883504787\n",
      "epoch : 27 Testing accuracy, macro_f1: 0.7938931297709924 0.5431891883504787\n",
      "epoch : 28 Testing accuracy, macro_f1: 0.7900763358778626 0.5404761904761904\n",
      "epoch : 29 Testing accuracy, macro_f1: 0.7900763358778626 0.5404761904761904\n"
     ]
    }
   ],
   "source": [
    "make_prediction(testing_data_net, test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
