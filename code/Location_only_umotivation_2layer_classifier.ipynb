{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12b84a530>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "import spacy  # For preprocessing\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p  #pip install tweet-preprocessor\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation as punc\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "#from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.models as gsm\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import regex\n",
    "import emoji\n",
    "# Internal dependencies\n",
    "import word_emoji2vec as we2v\n",
    "#from word_emoji2vec import Word_Emoji2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed #python -m spacy download en\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## load embeddings #######\n",
    "loc_emb = torch.load('data/locationEmbeddings.pt') \n",
    "#des_emb = torch.load('data/descriptionEmbeddings.pt') \n",
    "#twt_emb = torch.load('data/tweetsEmbeddings.pt') \n",
    "\n",
    "#load network embedding\n",
    "#net_emb = gsm.KeyedVectors.load_word2vec_format('data/userNetworkEmd.emd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user = net_emb ['000mrs000']\n",
    "#print(user)\n",
    "#print(type(net_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load 1300 user location, description, yoga tweets, utype, umotivation\n",
    "df = pd.read_csv(\"data/yoga_user_name_loc_des_mergetweets_yoga_1300_lb.csv\") \n",
    "#print (df) #[1308 rows x 7 columns] name, location, description, text, utype, umotivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load train users and split into train and validation #######\n",
    "with open(\"data/train.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "random.seed(1)\n",
    "random.shuffle(data)\n",
    "\n",
    "train_data = data[:830] #80% train  \n",
    "#print(train_data, len(train_data)) #830\n",
    "valid_data = data[830:] #20% validation\n",
    "#print(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create LSTM Model for Location #############\n",
    "class LSTMLoc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMLoc, self).__init__()\n",
    "        self.lstm = nn.LSTM(300, 150, num_layers=1) \n",
    "        self.hidden = self.init_hidden() # <- change here \n",
    "\n",
    "    def init_hidden(self):\n",
    "        #(2*self.num_layers, batch_size, self.hidden_dim // 2)# <- change here: first dim of hidden needs to be doubled\n",
    "        return (torch.zeros(1, 1, 150), torch.zeros(1, 1, 150)) \n",
    "    def forward(self, x):\n",
    "        #x=embeds.permute(1,0,2)\n",
    "        #print('resize', x.view(len(x),1,-1), x.view(len(x),1,-1).size()) #torch.Size([13, 1, 300])\n",
    "        #lstm_out, self.hidden = self.lstm(x.view(len(x),1, -1), self.hidden)\n",
    "        lstm_out, _ = self.lstm(x.view(len(x),1, -1))\n",
    "        #lstm_out, _ = self.lstm(x.view(len(x),1,-1)) \n",
    "        #print('lstm_out', lstm_out, lstm_out.size()) # torch.Size([13, 1, 150])\n",
    "        #print('self.hidden[0]', self.hidden[0], self.hidden[0].size()) # torch.Size([1, 1, 150])\n",
    "        #print(\"lstm_out[-1]\", lstm_out[-1], lstm_out[-1].size())  # torch.Size([1, 150])\n",
    "        #x = self.fc2(lstm_out[-1])  \n",
    "        #out = F.log_softmax(x, dim = 1)\n",
    "        #return out\n",
    "        #return x\n",
    "        return lstm_out[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loc, self).__init__()\n",
    "        #self.model_des = BiLSTMDesAtt()\n",
    "        self.model_loc = LSTMLoc()\n",
    "        #self.model_net = NetworkMLP()\n",
    "        self.fc1 = nn.Linear(150, 200) \n",
    "        self.fc2 = nn.Linear(200, 3) #if we use two-layer classifier\n",
    "    def forward(self, x_l): \n",
    "        #prediction_des = self.model_des(x_d)\n",
    "        #print(prediction_des, prediction_des.size()) #torch.Size([1, 3])\n",
    "        prediction_loc = self.model_loc(x_l)\n",
    "        #print(prediction_loc, prediction_loc.size()) #torch.Size([1, 3])\n",
    "        #prediction_net = self.model_net(x_n)\n",
    "        #print(prediction_net, prediction_net.size()) #torch.Size([1, 3])\n",
    "        #concat_pred = torch.cat((prediction_des, prediction_loc, prediction_net), 1) #concat with dim= 1\n",
    "        #concat_pred = torch.cat((prediction_des, prediction_loc), 1) #concat with dim= 1\n",
    "        #print(concat_pred, concat_pred.size()) #torch.Size([1, 6])\n",
    "        out = self.fc1(prediction_loc)\n",
    "        out = self.fc2(F.relu(out))\n",
    "        out = F.log_softmax(out, dim = 1)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare data for neural net input #########\n",
    "def nn_input(train_data,df):\n",
    "    #ground_truths = []\n",
    "    #training_data_des =[]\n",
    "    training_data_loc=[]\n",
    "    for i in range (0, len(train_data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (train_data[i] == df.name[j]):\n",
    "                if (not loc_emb[train_data[i]]):\n",
    "                    print ('no location for user: ', train_data[i])\n",
    "                    training_data_loc.append(torch.zeros(1, 300))\n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "                    sent_tensor_loc = torch.stack(loc_emb[train_data[i]],dim = 1)\n",
    "                    training_data_loc.append(sent_tensor_loc[-1])\n",
    "                    break\n",
    "    return training_data_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Ground Truth #########\n",
    "def find_groundtruth(data, df):\n",
    "    ground_truths = []\n",
    "    for i in range (0, len(data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (data[i] == df.name[j]):\n",
    "                #print(data[i]) #print username\n",
    "                utype =  [int(df.utype[j])]\n",
    "                umotivation = [int(float(df.umotivation[j]))]\n",
    "                #target_type = torch.tensor(utype, dtype=torch.long) #for user type\n",
    "                target_type = torch.tensor(umotivation, dtype=torch.long) #for user motivation\n",
    "                ground_truths.append(target_type)\n",
    "    return ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_tr(model, training_data_loc, ground_truths):\n",
    "    predictions =[]\n",
    "    for i in range (0,len(training_data_loc)):\n",
    "        prediction_joint = model(training_data_loc[i])\n",
    "        \n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_loc)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    return accuracy, macro_f1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_val(model, training_data_loc, ground_truths):\n",
    "    predictions =[]\n",
    "    val_losses = []\n",
    "    loss_function = nn.NLLLoss()\n",
    "    for i in range (0,len(training_data_loc)):\n",
    "        prediction_joint = model(training_data_loc[i])\n",
    "        val_loss = loss_function(prediction_joint, ground_truths[i])\n",
    "        val_losses.append(val_loss.item())\n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_loc)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    \n",
    "    #print(type(predictions), type(ground_truths))\n",
    "    #print(\"predictions\", predictions)\n",
    "    #print(\"ground_truths\", ground_truths)\n",
    "    \n",
    "    return accuracy, macro_f1, val_losses\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no location for user:  Christoph_Tran\n",
      "no location for user:  yogitimesonline\n",
      "no location for user:  cipherEquality\n",
      "no location for user:  thewaywecame\n"
     ]
    }
   ],
   "source": [
    "##########......prepare training and validation data\n",
    "# ground truth training\n",
    "train_gt = find_groundtruth(train_data, df)\n",
    "#####prepare training data for neural net #########\n",
    "#training_data_net =  nn_input_network(train_data,df)\n",
    "#print(training_data_net, len(training_data_net)) #ok\n",
    "training_data_loc =  nn_input(train_data,df)\n",
    "\n",
    "# ground truth validation\n",
    "valid_gt = find_groundtruth(valid_data, df)\n",
    "#####prepare validation data for neural net #########\n",
    "#validation_data_net =  nn_input_network(valid_data,df)\n",
    "validation_data_loc =  nn_input(valid_data,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Starting with epoch:  0 ***********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tunaz/miniconda2/envs/py3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 Train accuracy and macro_f1: 0.45542168674698796 0.24854168836773263\n",
      "epoch : 0 Validation accuracy, macro_f1: 0.45145631067961167 0.24324632394847825\n",
      "train loss per epoch 0.8477357610162483\n",
      "Validation loss per epoch: 0.8236211144808426\n",
      "*************** Starting with epoch:  1 ***********************\n",
      "epoch : 1 Train accuracy and macro_f1: 0.5759036144578313 0.3839556004036327\n",
      "epoch : 1 Validation accuracy, macro_f1: 0.5436893203883495 0.3550303826019627\n",
      "train loss per epoch 0.8278808295008648\n",
      "Validation loss per epoch: 0.7938745137557243\n",
      "*************** Starting with epoch:  2 ***********************\n",
      "epoch : 2 Train accuracy and macro_f1: 0.6144578313253012 0.4156875658728357\n",
      "epoch : 2 Validation accuracy, macro_f1: 0.5679611650485437 0.37587168758716877\n",
      "train loss per epoch 0.8164376656453772\n",
      "Validation loss per epoch: 0.7893102542289252\n",
      "*************** Starting with epoch:  3 ***********************\n",
      "epoch : 3 Train accuracy and macro_f1: 0.6204819277108434 0.42075588520926366\n",
      "epoch : 3 Validation accuracy, macro_f1: 0.5970873786407767 0.39917027417027423\n",
      "train loss per epoch 0.8078298786497978\n",
      "Validation loss per epoch: 0.7815231689550344\n",
      "*************** Starting with epoch:  4 ***********************\n",
      "epoch : 4 Train accuracy and macro_f1: 0.6662650602409639 0.4562827045535341\n",
      "epoch : 4 Validation accuracy, macro_f1: 0.5922330097087378 0.3961516416932776\n",
      "train loss per epoch 0.800256649341928\n",
      "Validation loss per epoch: 0.7605300641175613\n",
      "*************** Starting with epoch:  5 ***********************\n",
      "epoch : 5 Train accuracy and macro_f1: 0.6843373493975904 0.4692845474387302\n",
      "epoch : 5 Validation accuracy, macro_f1: 0.6067961165048543 0.4074725274725275\n",
      "train loss per epoch 0.793050687571606\n",
      "Validation loss per epoch: 0.7617709231608122\n",
      "*************** Starting with epoch:  6 ***********************\n",
      "epoch : 6 Train accuracy and macro_f1: 0.7120481927710843 0.48917027999991775\n",
      "epoch : 6 Validation accuracy, macro_f1: 0.6504854368932039 0.43877616747181963\n",
      "train loss per epoch 0.7860071377274092\n",
      "Validation loss per epoch: 0.7655308596717502\n",
      "*************** Starting with epoch:  7 ***********************\n",
      "epoch : 7 Train accuracy and macro_f1: 0.7180722891566265 0.4932647049142556\n",
      "epoch : 7 Validation accuracy, macro_f1: 0.6553398058252428 0.4419694626981059\n",
      "train loss per epoch 0.7789400681135166\n",
      "Validation loss per epoch: 0.7984079527623446\n",
      "*************** Starting with epoch:  8 ***********************\n",
      "epoch : 8 Train accuracy and macro_f1: 0.7156626506024096 0.49160762483130904\n",
      "epoch : 8 Validation accuracy, macro_f1: 0.6650485436893204 0.44852467465532797\n",
      "train loss per epoch 0.7715112121389254\n",
      "Validation loss per epoch: 0.8449310932344604\n",
      "*************** Starting with epoch:  9 ***********************\n",
      "epoch : 9 Train accuracy and macro_f1: 0.7156626506024096 0.4915042208624582\n",
      "epoch : 9 Validation accuracy, macro_f1: 0.6553398058252428 0.44212593987988863\n",
      "train loss per epoch 0.7634368186327348\n",
      "Validation loss per epoch: 0.8941763407975725\n",
      "*************** Starting with epoch:  10 ***********************\n",
      "epoch : 10 Train accuracy and macro_f1: 0.7301204819277108 0.5015588428482881\n",
      "epoch : 10 Validation accuracy, macro_f1: 0.6650485436893204 0.44852467465532797\n",
      "train loss per epoch 0.7548817153175454\n",
      "Validation loss per epoch: 0.9922757817124858\n",
      "*************** Starting with epoch:  11 ***********************\n",
      "epoch : 11 Train accuracy and macro_f1: 0.7265060240963855 0.4990608373814481\n",
      "epoch : 11 Validation accuracy, macro_f1: 0.6504854368932039 0.4385964912280702\n",
      "train loss per epoch 0.7471062446693819\n",
      "Validation loss per epoch: 1.0183314047392131\n",
      "*************** Starting with epoch:  12 ***********************\n",
      "epoch : 12 Train accuracy and macro_f1: 0.7156626506024096 0.4916355404640633\n",
      "epoch : 12 Validation accuracy, macro_f1: 0.6262135922330098 0.4226515334460275\n",
      "train loss per epoch 0.7397206447155416\n",
      "Validation loss per epoch: 1.0049260284715487\n",
      "*************** Starting with epoch:  13 ***********************\n",
      "epoch : 13 Train accuracy and macro_f1: 0.7168674698795181 0.4924763666255652\n",
      "epoch : 13 Validation accuracy, macro_f1: 0.6601941747572816 0.4446703128277108\n",
      "train loss per epoch 0.7317090667207147\n",
      "Validation loss per epoch: 1.0588992128094423\n",
      "*************** Starting with epoch:  14 ***********************\n",
      "epoch : 14 Train accuracy and macro_f1: 0.727710843373494 0.49990019960079835\n",
      "epoch : 14 Validation accuracy, macro_f1: 0.6067961165048543 0.40947873402234464\n",
      "train loss per epoch 0.7240745902731716\n",
      "Validation loss per epoch: 1.1025097199435372\n",
      "*************** Starting with epoch:  15 ***********************\n",
      "epoch : 15 Train accuracy and macro_f1: 0.7228915662650602 0.5212267681233199\n",
      "epoch : 15 Validation accuracy, macro_f1: 0.6796116504854369 0.4574780058651026\n",
      "train loss per epoch 0.7166724915739643\n",
      "Validation loss per epoch: 1.3402329506804642\n",
      "*************** Starting with epoch:  16 ***********************\n",
      "epoch : 16 Train accuracy and macro_f1: 0.7337349397590361 0.5719149770159997\n",
      "epoch : 16 Validation accuracy, macro_f1: 0.6844660194174758 0.4589865380355868\n",
      "train loss per epoch 0.7091411842850401\n",
      "Validation loss per epoch: 1.4466691575582744\n",
      "*************** Starting with epoch:  17 ***********************\n",
      "epoch : 17 Train accuracy and macro_f1: 0.7325301204819277 0.5911641237214491\n",
      "epoch : 17 Validation accuracy, macro_f1: 0.6650485436893204 0.44681320296993315\n",
      "train loss per epoch 0.7012632635742466\n",
      "Validation loss per epoch: 1.5344094066943936\n",
      "*************** Starting with epoch:  18 ***********************\n",
      "epoch : 18 Train accuracy and macro_f1: 0.7120481927710843 0.5257113072782543\n",
      "epoch : 18 Validation accuracy, macro_f1: 0.6747572815533981 0.4533644723398044\n",
      "train loss per epoch 0.6950415363890806\n",
      "Validation loss per epoch: 1.3348903407170936\n",
      "*************** Starting with epoch:  19 ***********************\n",
      "epoch : 19 Train accuracy and macro_f1: 0.7253012048192771 0.5669786527132002\n",
      "epoch : 19 Validation accuracy, macro_f1: 0.6844660194174758 0.4610622352557836\n",
      "train loss per epoch 0.6890231331536569\n",
      "Validation loss per epoch: 1.6721534066408583\n",
      "*************** Starting with epoch:  20 ***********************\n",
      "epoch : 20 Train accuracy and macro_f1: 0.7433734939759036 0.5688277414830399\n",
      "epoch : 20 Validation accuracy, macro_f1: 0.6601941747572816 0.44329854716595046\n",
      "train loss per epoch 0.6829123727562643\n",
      "Validation loss per epoch: 1.7756080262869307\n",
      "*************** Starting with epoch:  21 ***********************\n",
      "epoch : 21 Train accuracy and macro_f1: 0.7325301204819277 0.5705571762663645\n",
      "epoch : 21 Validation accuracy, macro_f1: 0.6747572815533981 0.45193343122858537\n",
      "train loss per epoch 0.6766618262474534\n",
      "Validation loss per epoch: 1.8859157232404913\n",
      "*************** Starting with epoch:  22 ***********************\n",
      "epoch : 22 Train accuracy and macro_f1: 0.736144578313253 0.5730802804843839\n",
      "epoch : 22 Validation accuracy, macro_f1: 0.6747572815533981 0.4513681042801303\n",
      "train loss per epoch 0.6712010280351604\n",
      "Validation loss per epoch: 1.864893039453377\n",
      "*************** Starting with epoch:  23 ***********************\n",
      "epoch : 23 Train accuracy and macro_f1: 0.7313253012048193 0.5889271890669758\n",
      "epoch : 23 Validation accuracy, macro_f1: 0.6990291262135923 0.46878208575759056\n",
      "train loss per epoch 0.6659826469379496\n",
      "Validation loss per epoch: 1.9360274435247031\n",
      "*************** Starting with epoch:  24 ***********************\n",
      "epoch : 24 Train accuracy and macro_f1: 0.7349397590361446 0.5624800096664369\n",
      "epoch : 24 Validation accuracy, macro_f1: 0.6699029126213593 0.4493884985688264\n",
      "train loss per epoch 0.6612128017437027\n",
      "Validation loss per epoch: 1.9820353382999458\n",
      "*************** Starting with epoch:  25 ***********************\n",
      "epoch : 25 Train accuracy and macro_f1: 0.7530120481927711 0.6234544982900981\n",
      "epoch : 25 Validation accuracy, macro_f1: 0.6262135922330098 0.42368932038834956\n",
      "train loss per epoch 0.6556665094750583\n",
      "Validation loss per epoch: 1.8104271229031017\n",
      "*************** Starting with epoch:  26 ***********************\n",
      "epoch : 26 Train accuracy and macro_f1: 0.7783132530120482 0.6531830489674165\n",
      "epoch : 26 Validation accuracy, macro_f1: 0.6747572815533981 0.45469942120494605\n",
      "train loss per epoch 0.6506036607695711\n",
      "Validation loss per epoch: 2.472850362652714\n",
      "*************** Starting with epoch:  27 ***********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 27 Train accuracy and macro_f1: 0.7710843373493976 0.5964529180696813\n",
      "epoch : 27 Validation accuracy, macro_f1: 0.6893203883495146 0.461066077130926\n",
      "train loss per epoch 0.6456787625247558\n",
      "Validation loss per epoch: 2.682815645504924\n",
      "*************** Starting with epoch:  28 ***********************\n",
      "epoch : 28 Train accuracy and macro_f1: 0.7843373493975904 0.6159670674185712\n",
      "epoch : 28 Validation accuracy, macro_f1: 0.6553398058252428 0.4380550512732446\n",
      "train loss per epoch 0.6415939687716797\n",
      "Validation loss per epoch: 2.7444810395680586\n",
      "*************** Starting with epoch:  29 ***********************\n",
      "epoch : 29 Train accuracy and macro_f1: 0.7795180722891566 0.661135324945065\n",
      "epoch : 29 Validation accuracy, macro_f1: 0.6796116504854369 0.45343619095018867\n",
      "train loss per epoch 0.6373099918681455\n",
      "Validation loss per epoch: 2.920828936458791\n"
     ]
    }
   ],
   "source": [
    "###########.........Start Training...........\n",
    "model = Loc()\n",
    "##### Hyperparameter\n",
    "#learning_rate=0.05\n",
    "learning_rate=0.01\n",
    "epochs = 30\n",
    "#opt=\"ADAM\"\n",
    "opt=\"SGD\" \n",
    "#opt=\"ADA\"\n",
    "if(opt==\"SGD\"):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "elif(opt==\"ADA\"):\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=learning_rate, eps=1e-06, weight_decay=0.0001)\n",
    "elif(opt==\"ADAM\"):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "\n",
    "    \n",
    "loss_function = nn.NLLLoss()\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "check_val_acc = 0\n",
    "losses = []\n",
    "per_epoch_train_loss =[]\n",
    "per_epoch_val_loss =[]\n",
    "per_epoch_train_f1 =[]\n",
    "per_epoch_val_f1 = []\n",
    "for epoch in range(epochs): \n",
    "    print('*************** Starting with epoch: ', epoch, '***********************')\n",
    "    for i in range (0,len(train_data)):\n",
    "        #model_des.zero_grad()\n",
    "        #model_loc.zero_grad()\n",
    "        model.zero_grad()\n",
    "        #####Run forward pass.\n",
    "      \n",
    "        prediction_joint = model(training_data_loc[i])\n",
    "        \n",
    "        #print(\"prediction_joint :\", torch.argmax(prediction_joint, dim=1)) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        #Compute the loss, gradients, and update the parameters by\n",
    "        #calling optimizer.step()\n",
    "        loss = loss_function(prediction_joint, train_gt[i])\n",
    "        #if (i%200 == 0):\n",
    "            #print (\"loss per example\", loss.item())\n",
    "        losses.append(loss.item())\n",
    "        loss.backward(retain_graph=True)  #backpropagation\n",
    "        optimizer.step()\n",
    "    accuracy, macro_f1 = make_prediction_tr(model, training_data_loc, train_gt)\n",
    "    print('epoch :', epoch, 'Train accuracy and macro_f1:', accuracy, macro_f1)\n",
    "    per_epoch_train_f1.append(macro_f1)\n",
    "    val_accuracy, val_macro_f1, val_loss = make_prediction_val(model, validation_data_loc, valid_gt)\n",
    "    per_epoch_val_f1.append(val_macro_f1)\n",
    "    print('epoch :', epoch, 'Validation accuracy, macro_f1:', val_accuracy, val_macro_f1)\n",
    "    per_epoch_train_loss.append(np.mean(losses))\n",
    "    print(\"train loss per epoch\", np.mean(losses))\n",
    "    per_epoch_val_loss.append(np.mean(val_loss))\n",
    "    print('Validation loss per epoch:', np.mean(val_loss))\n",
    "    \n",
    "    torch.save(model.state_dict(),\"data/Loc_umotivation_2layer/loc_\"+str(epoch)+\".pt\")\n",
    "#     if (check_val_acc < val_macro_f1): #early stopping\n",
    "#         check_val_acc = val_macro_f1\n",
    "#         print (\"Model saved at epoch :\", epoch)\n",
    "#         torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "#         best_epoch = epoch\n",
    "        \n",
    "#print(\"Best model found at epoch : \", best_epoch)        \n",
    "#torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_plots(train_losses, val_losses, train_accs, test_accs):\n",
    "    \"\"\"Plot\n",
    "\n",
    "        Plot two figures: loss vs. epoch and accuracy vs. epoch\n",
    "    \"\"\"\n",
    "    n = len(train_losses)\n",
    "    xs = np.arange(n)\n",
    "\n",
    "    # plot losses\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_losses, '--', linewidth=2, label='train loss')\n",
    "    ax.plot(xs, val_losses, '-', linewidth=2, label='validation loss')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.savefig('loss_Loc_umotivation.png')\n",
    "\n",
    "    # plot train and test accuracies\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_accs, '--', linewidth=2, label='train')\n",
    "    ax.plot(xs, test_accs, '-', linewidth=2, label='validation')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Macro-avg F1\")\n",
    "    ax.legend(loc='lower right')\n",
    "    plt.savefig('accuracy_Loc_umotivation.png')\n",
    "    \n",
    "save_plots(per_epoch_train_loss, per_epoch_val_loss, per_epoch_train_f1, per_epoch_val_f1)\n",
    "# print(per_epoch_train_loss)\n",
    "# print(per_epoch_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction(training_data_loc, ground_truths):\n",
    "    for epoch in range(0,30):\n",
    "        model = Loc()\n",
    "        model.load_state_dict(torch.load(\"data/Loc_umotivation_2layer/loc_\"+str(epoch)+\".pt\")) \n",
    "        predictions =[]\n",
    "        for i in range (0,len(training_data_loc)):\n",
    "            prediction_joint = model(training_data_loc[i])\n",
    "            pred = torch.argmax(prediction_joint, dim=1)\n",
    "            predictions.append(pred.item())\n",
    "        #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "        accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_loc)\n",
    "        macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "        print('epoch :', epoch, 'Testing accuracy, macro_f1:', accuracy, macro_f1)\n",
    "        #return accuracy, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########.....Load Test data.......\n",
    "with open(\"data/test.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "test_data = data[:] \n",
    "#print(test_data, len(test_data)) #262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no location for user:  vaibhavatttc\n"
     ]
    }
   ],
   "source": [
    "#####prepare testing data for neural net #########\n",
    "testing_data_loc =  nn_input(test_data,df)\n",
    "#testing_data_net =  nn_input_network(test_data,df)\n",
    "test_gt = find_groundtruth(test_data, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 Testing accuracy, macro_f1: 0.5458015267175572 0.27109974424552435\n",
      "epoch : 1 Testing accuracy, macro_f1: 0.5916030534351145 0.3679756425009589\n",
      "epoch : 2 Testing accuracy, macro_f1: 0.6221374045801527 0.3958422023556123\n",
      "epoch : 3 Testing accuracy, macro_f1: 0.6526717557251909 0.42418546365914783\n",
      "epoch : 4 Testing accuracy, macro_f1: 0.683206106870229 0.45477181196838284\n",
      "epoch : 5 Testing accuracy, macro_f1: 0.6908396946564885 0.4618078498744549\n",
      "epoch : 6 Testing accuracy, macro_f1: 0.7061068702290076 0.47896697345901745\n",
      "epoch : 7 Testing accuracy, macro_f1: 0.6946564885496184 0.47031853925096634\n",
      "epoch : 8 Testing accuracy, macro_f1: 0.6870229007633588 0.4654262527702046\n",
      "epoch : 9 Testing accuracy, macro_f1: 0.6793893129770993 0.4591101967339591\n",
      "epoch : 10 Testing accuracy, macro_f1: 0.6870229007633588 0.4656787600068131\n",
      "epoch : 11 Testing accuracy, macro_f1: 0.6793893129770993 0.4591101967339591\n",
      "epoch : 12 Testing accuracy, macro_f1: 0.6755725190839694 0.456945694569457\n",
      "epoch : 13 Testing accuracy, macro_f1: 0.6755725190839694 0.45725709716113555\n",
      "epoch : 14 Testing accuracy, macro_f1: 0.6946564885496184 0.4694623655913978\n",
      "epoch : 15 Testing accuracy, macro_f1: 0.6908396946564885 0.4704243857574563\n",
      "epoch : 16 Testing accuracy, macro_f1: 0.6984732824427481 0.47689810189810194\n",
      "epoch : 17 Testing accuracy, macro_f1: 0.6908396946564885 0.4700210240116343\n",
      "epoch : 18 Testing accuracy, macro_f1: 0.6526717557251909 0.44117647058823534\n",
      "epoch : 19 Testing accuracy, macro_f1: 0.6564885496183206 0.4439618463634815\n",
      "epoch : 20 Testing accuracy, macro_f1: 0.648854961832061 0.4419584544726752\n",
      "epoch : 21 Testing accuracy, macro_f1: 0.6603053435114504 0.45158580800187126\n",
      "epoch : 22 Testing accuracy, macro_f1: 0.6412213740458015 0.43768938789831263\n",
      "epoch : 23 Testing accuracy, macro_f1: 0.6603053435114504 0.451336407497545\n",
      "epoch : 24 Testing accuracy, macro_f1: 0.6564885496183206 0.44766278111385843\n",
      "epoch : 25 Testing accuracy, macro_f1: 0.6412213740458015 0.4275530188573667\n",
      "epoch : 26 Testing accuracy, macro_f1: 0.6564885496183206 0.4502025949394371\n",
      "epoch : 27 Testing accuracy, macro_f1: 0.683206106870229 0.4681494208985617\n",
      "epoch : 28 Testing accuracy, macro_f1: 0.6793893129770993 0.46499832327297114\n",
      "epoch : 29 Testing accuracy, macro_f1: 0.6870229007633588 0.47180506478209655\n"
     ]
    }
   ],
   "source": [
    "make_prediction(testing_data_loc, test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
