{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x133cafad0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "import spacy  # For preprocessing\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p  #pip install tweet-preprocessor\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation as punc\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "#from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.models as gsm\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import regex\n",
    "import emoji\n",
    "# Internal dependencies\n",
    "import word_emoji2vec as we2v\n",
    "#from word_emoji2vec import Word_Emoji2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed #python -m spacy download en\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## load embeddings #######\n",
    "loc_emb = torch.load('data/locationEmbeddings.pt') \n",
    "des_emb = torch.load('data/descriptionEmbeddings.pt') \n",
    "twt_emb = torch.load('data/tweetsEmbeddings.pt') \n",
    "\n",
    "#load network embedding\n",
    "#net_emb = gsm.KeyedVectors.load_word2vec_format('data/userNetworkEmd.emd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user = net_emb ['000mrs000']\n",
    "#print(user)\n",
    "#print(type(net_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load 1300 user location, description, yoga tweets, utype, umotivation\n",
    "df = pd.read_csv(\"data/yoga_user_name_loc_des_mergetweets_yoga_1300_lb.csv\") \n",
    "#print (df) #[1308 rows x 7 columns] name, location, description, text, utype, umotivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load train users and split into train and validation #######\n",
    "with open(\"data/train.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "random.seed(1)\n",
    "random.shuffle(data)\n",
    "\n",
    "train_data = data[:830] #80% train  \n",
    "#print(train_data, len(train_data)) #830\n",
    "valid_data = data[830:] #20% validation\n",
    "#print(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create BiLSTMAttention Model for Description\n",
    "class BiLSTMDesAtt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiLSTMDesAtt, self).__init__() \n",
    "        self.lstm = nn.LSTM(300, 150//2 , num_layers=1, bidirectional=True ) #BiLSTM with attention \n",
    "        #self.lstm = nn.LSTM(300, 150 , num_layers=1, bidirectional=False) #LSTM with attention\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        self.hidden = self.init_hidden() # <- change here \n",
    "        self.attn_fc = torch.nn.Linear(300, 1) #attention layer\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        #(2*self.num_layers, batch_size, self.hidden_dim // 2)\n",
    "        return (torch.zeros(2 * 1, 1, 150//2), torch.zeros(2 * 1, 1, 150//2)) # <- change here: first dim of hidden needs to be doubled\n",
    "        #return (torch.zeros(1 * 1, 1, 150), torch.zeros(1 * 1, 1, 150))#LSTM with attention\n",
    "    def attention(self, rnn_out, state):\n",
    "        #print(\"rnn_out\", rnn_out.size()) #torch.Size([13, 1, 150])\n",
    "        #rnn_out = rnn_out.squeeze(0).unsqueeze(1) \n",
    "        #rnn_out = rnn_out.permute(2,0,1) \n",
    "        rnn_out = rnn_out.permute(1,0,2) \n",
    "        #print(\"permute rnn_out\", rnn_out.size()) #torch.Size([150, 13, 1])\n",
    "        #print(\"state\", state.size()) #torch.Size([2, 1, 75])\n",
    "        merged_state = torch.cat([s for s in state],1)\n",
    "        #print(\"merged_state\", merged_state.size()) #torch.Size([1, 150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).size()) #torch.Size([150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).size()) #torch.Size([150, 1])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).unsqueeze(2).size()) # torch.Size([150, 1, 1])\n",
    "        #merged_state = merged_state.squeeze(0).unsqueeze(2)\n",
    "        merged_state = merged_state.squeeze(0).unsqueeze(1).unsqueeze(2)\n",
    "        #print(\"merged_state2 :\", merged_state.size()) #torch.Size([150, 1, 1])\n",
    "        merged_state = merged_state.permute(1,0,2)\n",
    "        # (batch, seq_len, cell_size) * (batch, cell_size, 1) = (batch, seq_len, 1)\n",
    "        weights = torch.bmm(rnn_out, merged_state)\n",
    "        #print(\"weights\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        #weights = torch.nn.functional.softmax(weights.squeeze(2)).unsqueeze(2)\n",
    "        weights = F.log_softmax(weights.squeeze(2),dim = 1).unsqueeze(2)\n",
    "         #F.log_softmax(x, dim = 1)\n",
    "        #print(\"weights2 :\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        # (batch, cell_size, seq_len) * (batch, seq_len, 1) = (batch, cell_size, 1)\n",
    "        return torch.bmm(torch.transpose(rnn_out, 1, 2), weights).squeeze(2)\n",
    "    # end method attention\n",
    "\n",
    "    def forward(self, X):\n",
    "        #print(X.size()) # torch.Size([13, 300])\n",
    "        #print('resize', x.view(len(x),1,-1), x.view(len(x),1,-1).size()) #torch.Size([13, 1, 300])\n",
    "        lstm_out, hidden = self.lstm(X.view(len(X),1, -1))\n",
    "        #print('lstm_out', lstm_out, lstm_out.size()) # torch.Size([13, 1, 150])\n",
    "        #print('hidden[0] = h_n', hidden[0], hidden[0].size()) # torch.Size([2, 1, 75])\n",
    "        #print('hidden[1] = c_n', hidden[1], hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        h_n, c_n = hidden\n",
    "        #print('h_n', h_n, h_n.size()) # torch.Size([2, 1, 75])\n",
    "        #print('c_n', c_n, hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        attn_out = self.attention(lstm_out, h_n)\n",
    "        #print(\"attn_out\", attn_out.size()) #torch.Size([150, 1])\n",
    "        #logits = self.fc2(attn_out)\n",
    "        #logits = self.fc2(attn_out.permute(1,0))\n",
    "        #print(\"logits\", logits, logits.size())\n",
    "        #return logits \n",
    "        return attn_out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create BiLSTMAttention Model for Description\n",
    "class BiLSTMTwtAtt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiLSTMTwtAtt, self).__init__() \n",
    "        self.lstm = nn.LSTM(300, 150//2 , num_layers=1, bidirectional=True ) #BiLSTM with attention \n",
    "        #self.lstm = nn.LSTM(300, 150 , num_layers=1, bidirectional=False) #LSTM with attention\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        self.hidden = self.init_hidden() # <- change here \n",
    "        self.attn_fc = torch.nn.Linear(300, 1) #attention layer\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        #(2*self.num_layers, batch_size, self.hidden_dim // 2)\n",
    "        return (torch.zeros(2 * 1, 1, 150//2), torch.zeros(2 * 1, 1, 150//2)) # <- change here: first dim of hidden needs to be doubled\n",
    "        #return (torch.zeros(1 * 1, 1, 150), torch.zeros(1 * 1, 1, 150))#LSTM with attention\n",
    "    def attention(self, rnn_out, state):\n",
    "        #print(\"rnn_out\", rnn_out.size()) #torch.Size([13, 1, 150])\n",
    "        #rnn_out = rnn_out.squeeze(0).unsqueeze(1) \n",
    "        #rnn_out = rnn_out.permute(2,0,1) \n",
    "        rnn_out = rnn_out.permute(1,0,2) \n",
    "        #print(\"permute rnn_out\", rnn_out.size()) #torch.Size([150, 13, 1])\n",
    "        #print(\"state\", state.size()) #torch.Size([2, 1, 75])\n",
    "        merged_state = torch.cat([s for s in state],1)\n",
    "        #print(\"merged_state\", merged_state.size()) #torch.Size([1, 150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).size()) #torch.Size([150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).size()) #torch.Size([150, 1])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).unsqueeze(2).size()) # torch.Size([150, 1, 1])\n",
    "        #merged_state = merged_state.squeeze(0).unsqueeze(2)\n",
    "        merged_state = merged_state.squeeze(0).unsqueeze(1).unsqueeze(2)\n",
    "        #print(\"merged_state2 :\", merged_state.size()) #torch.Size([150, 1, 1])\n",
    "        merged_state = merged_state.permute(1,0,2)\n",
    "        # (batch, seq_len, cell_size) * (batch, cell_size, 1) = (batch, seq_len, 1)\n",
    "        weights = torch.bmm(rnn_out, merged_state)\n",
    "        #print(\"weights\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        #weights = torch.nn.functional.softmax(weights.squeeze(2)).unsqueeze(2)\n",
    "        weights = F.log_softmax(weights.squeeze(2),dim = 1).unsqueeze(2)\n",
    "         #F.log_softmax(x, dim = 1)\n",
    "        #print(\"weights2 :\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        # (batch, cell_size, seq_len) * (batch, seq_len, 1) = (batch, cell_size, 1)\n",
    "        return torch.bmm(torch.transpose(rnn_out, 1, 2), weights).squeeze(2)\n",
    "    # end method attention\n",
    "\n",
    "    def forward(self, X):\n",
    "        #print(X.size()) # torch.Size([13, 300])\n",
    "        #print('resize', x.view(len(x),1,-1), x.view(len(x),1,-1).size()) #torch.Size([13, 1, 300])\n",
    "        lstm_out, hidden = self.lstm(X.view(len(X),1, -1))\n",
    "        #print('lstm_out', lstm_out, lstm_out.size()) # torch.Size([13, 1, 150])\n",
    "        #print('hidden[0] = h_n', hidden[0], hidden[0].size()) # torch.Size([2, 1, 75])\n",
    "        #print('hidden[1] = c_n', hidden[1], hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        h_n, c_n = hidden\n",
    "        #print('h_n', h_n, h_n.size()) # torch.Size([2, 1, 75])\n",
    "        #print('c_n', c_n, hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        attn_out = self.attention(lstm_out, h_n)\n",
    "        #print(\"attn_out\", attn_out.size()) #torch.Size([150, 1])\n",
    "        #logits = self.fc2(attn_out)\n",
    "        #logits = self.fc2(attn_out.permute(1,0))\n",
    "        #print(\"logits\", logits, logits.size())\n",
    "        #return logits \n",
    "        return attn_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create LSTM Model for Location #############\n",
    "class LSTMLoc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMLoc, self).__init__()\n",
    "        self.lstm = nn.LSTM(300, 150, num_layers=1)\n",
    "        self.fc2 = nn.Linear(150, 50) \n",
    "        self.hidden = self.init_hidden() # <- change here \n",
    "\n",
    "    def init_hidden(self):\n",
    "        #(2*self.num_layers, batch_size, self.hidden_dim // 2)# <- change here: first dim of hidden needs to be doubled\n",
    "        return (torch.zeros(1, 1, 150), torch.zeros(1, 1, 150)) \n",
    "    def forward(self, x):\n",
    "        #x=embeds.permute(1,0,2)\n",
    "        #print('resize', x.view(len(x),1,-1), x.view(len(x),1,-1).size()) #torch.Size([13, 1, 300])\n",
    "        #lstm_out, self.hidden = self.lstm(x.view(len(x),1, -1), self.hidden)\n",
    "        lstm_out, _ = self.lstm(x.view(len(x),1, -1))\n",
    "        #lstm_out, _ = self.lstm(x.view(len(x),1,-1)) \n",
    "        #print('lstm_out', lstm_out, lstm_out.size()) # torch.Size([13, 1, 150])\n",
    "        #print('self.hidden[0]', self.hidden[0], self.hidden[0].size()) # torch.Size([1, 1, 150])\n",
    "        #print(\"lstm_out[-1]\", lstm_out[-1], lstm_out[-1].size())  # torch.Size([1, 150])\n",
    "        #x = self.fc2(lstm_out[-1])  \n",
    "        #out = F.log_softmax(x, dim = 1)\n",
    "        #return out\n",
    "        #return x\n",
    "        return lstm_out[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create Model \n",
    "class NetworkMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkMLP, self).__init__() \n",
    "        self.fc1 = nn.Linear(300, 150)\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #print(X.size()) # torch.Size([300])\n",
    "        #print('resize', X.view(1,len(X)).size()) #resize torch.Size([1, 300])\n",
    "        z1 = self.fc1(X.view(1,len(X)))\n",
    "        #print('z1', z1, z1.size()) # torch.Size([1, 150])\n",
    "        h1 = F.relu(z1)\n",
    "        return h1\n",
    "        #logits = self.fc2(h1) #without attention\n",
    "        #print(\"logits\", logits, logits.size()) #torch.Size([1, 3])\n",
    "        #return logits \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointDLT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JointDLT, self).__init__()\n",
    "        self.model_des = BiLSTMDesAtt()\n",
    "        self.model_loc = LSTMLoc()\n",
    "        #self.model_twt = BiLSTMDesAtt()\n",
    "        self.model_twt = BiLSTMTwtAtt()\n",
    "        #self.model_net = NetworkMLP()\n",
    "\n",
    "        self.fc1 = nn.Linear(450, 200) \n",
    "        self.fc2 = nn.Linear(200, 3)\n",
    "#        self.fc1 = nn.Linear(450, 3)\n",
    "    def forward(self, x_d, x_l, x_t): \n",
    "        prediction_des = self.model_des(x_d)\n",
    "        #print(prediction_des, prediction_des.size())\n",
    "        prediction_loc = self.model_loc(x_l)\n",
    "        #print(prediction_loc, prediction_loc.size())\n",
    "        prediction_twt = self.model_twt(x_t)\n",
    "        #prediction_net = self.model_net(x_n)\n",
    "        concat_pred = torch.cat((prediction_des, prediction_loc, prediction_twt), 1) #concat with dim= 1\n",
    "        #print(concat_pred, concat_pred.size()) \n",
    "#         out = F.log_softmax(self.fc(concat_pred), dim = 1)\n",
    "#         return out\n",
    "        out = self.fc1(concat_pred)\n",
    "        out = self.fc2(F.relu(out))\n",
    "        out = F.log_softmax(out, dim = 1)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare data for neural net input #########\n",
    "def nn_input(train_data,df):\n",
    "    #ground_truths = []\n",
    "    training_data_des =[]\n",
    "    training_data_loc=[]\n",
    "    training_data_twt =[]\n",
    "    for i in range (0, len(train_data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (train_data[i] == df.name[j]):\n",
    "                if (not des_emb[train_data[i]]) and (not loc_emb[train_data[i]]) and (twt_emb[train_data[i]]):\n",
    "                    print ('no description and location for user: ', train_data[i])\n",
    "                    training_data_des.append(torch.zeros(1, 300))\n",
    "                    training_data_loc.append(torch.zeros(1, 300))\n",
    "                    sent_tensor_twt = torch.stack(twt_emb[train_data[i]],dim = 1)\n",
    "                    training_data_twt.append(sent_tensor_twt[-1])\n",
    "                    break\n",
    "                \n",
    "                elif (des_emb[train_data[i]]) and (not loc_emb[train_data[i]]) and (twt_emb[train_data[i]]): \n",
    "                    print ('no location for user: ', train_data[i])\n",
    "                    sent_tensor_des = torch.stack(des_emb[train_data[i]],dim = 1)\n",
    "                    training_data_des.append(sent_tensor_des[-1])\n",
    "                    training_data_loc.append(torch.zeros(1, 300))\n",
    "                    sent_tensor_twt = torch.stack(twt_emb[train_data[i]],dim = 1)\n",
    "                    training_data_twt.append(sent_tensor_twt[-1])\n",
    "                    break\n",
    "                    \n",
    "                elif (not des_emb[train_data[i]]) and (loc_emb[train_data[i]]) and (twt_emb[train_data[i]]): \n",
    "                    print ('no description for user: ', train_data[i])\n",
    "                    training_data_des.append(torch.zeros(1, 300))\n",
    "                    sent_tensor_loc = torch.stack(loc_emb[train_data[i]],dim = 1)\n",
    "                    training_data_loc.append(sent_tensor_loc[-1])\n",
    "                    sent_tensor_twt = torch.stack(twt_emb[train_data[i]],dim = 1)\n",
    "                    training_data_twt.append(sent_tensor_twt[-1])\n",
    "                    break    \n",
    "               \n",
    "                elif (des_emb[train_data[i]]) and (loc_emb[train_data[i]]) and (twt_emb[train_data[i]]): \n",
    "                    sent_tensor_des = torch.stack(des_emb[train_data[i]],dim = 1)\n",
    "                    training_data_des.append(sent_tensor_des[-1])\n",
    "                    sent_tensor_loc = torch.stack(loc_emb[train_data[i]],dim = 1)\n",
    "                    training_data_loc.append(sent_tensor_loc[-1])\n",
    "                    sent_tensor_twt = torch.stack(twt_emb[train_data[i]],dim = 1)\n",
    "                    training_data_twt.append(sent_tensor_twt[-1])\n",
    "                    break\n",
    "    return training_data_des, training_data_loc, training_data_twt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare data for neural net #########\n",
    "def nn_input_network(train_data,df):\n",
    "    training_data =[]\n",
    "    for i in range (0, len(train_data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (train_data[i] == df.name[j]):\n",
    "                #print(train_data[i]) #print username\n",
    "                utype =  [int(df.utype[j])]\n",
    "                umotivation = [int(float(df.umotivation[j]))]\n",
    "                #print (\"net_emb[train_data[i]] : \", net_emb[train_data[i]], type(net_emb[train_data[i]]), torch.Tensor(net_emb[train_data[i]]), type(torch.Tensor(net_emb[train_data[i]])))\n",
    "                #count = 0\n",
    "                if(train_data[i] not in net_emb ):\n",
    "                    net_emb[train_data[i]] = np.zeros(300) #For users not appearing in the mention network, we set their network embedding vectors as 0.\n",
    "                    #count = count + 1\n",
    "                #print(count)\n",
    "                #print(net_emb[train_data[i]]) #ok\n",
    "                ####.....convert ndarray to torch.tensor........\n",
    "                net_emb_tensor = torch.Tensor(net_emb[train_data[i]])\n",
    "                #print(net_emb_tensor) #ok\n",
    "                training_data.append(net_emb_tensor)\n",
    "                break\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Ground Truth #########\n",
    "def find_groundtruth(data, df):\n",
    "    ground_truths = []\n",
    "    for i in range (0, len(data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (data[i] == df.name[j]):\n",
    "                #print(data[i]) #print username\n",
    "                utype =  [int(df.utype[j])]\n",
    "                umotivation = [int(float(df.umotivation[j]))]\n",
    "                target_type = torch.tensor(utype, dtype=torch.long) #for user type\n",
    "                #target_type = torch.tensor(umotivation, dtype=torch.long) #for user motivation\n",
    "                ground_truths.append(target_type)\n",
    "    return ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_tr(model, training_data_des, training_data_loc, training_data_twt, ground_truths):\n",
    "    predictions =[]\n",
    "    for i in range (0,len(training_data_des)):\n",
    "        prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_twt[i])\n",
    "        \n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_des)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    \n",
    "    return accuracy, macro_f1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_val(model, training_data_des, training_data_loc, training_data_twt, ground_truths):\n",
    "    predictions =[]\n",
    "    val_losses = []\n",
    "    loss_function = nn.NLLLoss()\n",
    "    for i in range (0,len(training_data_des)):\n",
    "        prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_twt[i])\n",
    "        val_loss = loss_function(prediction_joint, ground_truths[i])\n",
    "        val_losses.append(val_loss.item())\n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_des)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    \n",
    "    return accuracy, macro_f1, val_losses\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no description for user:  bchi49\n",
      "no location for user:  Christoph_Tran\n",
      "no description for user:  viecestlavie\n",
      "no description for user:  crystalization_\n",
      "no location for user:  yogitimesonline\n",
      "no description for user:  mimmosamami\n",
      "no description for user:  wenmarbyoga\n",
      "no location for user:  cipherEquality\n",
      "no description for user:  YogaLifeLine\n",
      "no location for user:  thewaywecame\n"
     ]
    }
   ],
   "source": [
    "##########......prepare training and validation data\n",
    "# ground truth training\n",
    "train_gt = find_groundtruth(train_data, df)\n",
    "#####prepare training data for neural net #########\n",
    "#training_data_net =  nn_input_network(train_data,df)\n",
    "#print(training_data_net, len(training_data_net)) #ok\n",
    "training_data_des, training_data_loc, training_data_twt =  nn_input(train_data,df)\n",
    "\n",
    "# ground truth validation\n",
    "valid_gt = find_groundtruth(valid_data, df)\n",
    "#####prepare validation data for neural net #########\n",
    "#validation_data_net =  nn_input_network(valid_data,df)\n",
    "validation_data_des, validation_data_loc, validation_data_twt =  nn_input(valid_data,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Starting with epoch:  0 ***********************\n",
      "epoch : 0 Train accuracy and macro_f1: 0.5614457831325301 0.5462910195949137\n",
      "epoch : 0 Validation accuracy, macro_f1: 0.49514563106796117 0.4850887021475257\n",
      "train loss per epoch 1.1205432154597288\n",
      "Validation loss per epoch: 1.0694371429317207\n",
      "*************** Starting with epoch:  1 ***********************\n",
      "epoch : 1 Train accuracy and macro_f1: 0.6313253012048192 0.61850346567567\n",
      "epoch : 1 Validation accuracy, macro_f1: 0.5728155339805825 0.5597830319669906\n",
      "train loss per epoch 0.9878388140552554\n",
      "Validation loss per epoch: 0.9733917009338592\n",
      "*************** Starting with epoch:  2 ***********************\n",
      "epoch : 2 Train accuracy and macro_f1: 0.6614457831325301 0.6509768855928953\n",
      "epoch : 2 Validation accuracy, macro_f1: 0.6116504854368932 0.5960093504758723\n",
      "train loss per epoch 0.9135930748933171\n",
      "Validation loss per epoch: 0.9098314770940438\n",
      "*************** Starting with epoch:  3 ***********************\n",
      "epoch : 3 Train accuracy and macro_f1: 0.6734939759036145 0.6650730007762969\n",
      "epoch : 3 Validation accuracy, macro_f1: 0.616504854368932 0.5995427260675931\n",
      "train loss per epoch 0.8626103721906891\n",
      "Validation loss per epoch: 0.8866731898443213\n",
      "*************** Starting with epoch:  4 ***********************\n",
      "epoch : 4 Train accuracy and macro_f1: 0.7036144578313253 0.6972740752451306\n",
      "epoch : 4 Validation accuracy, macro_f1: 0.6213592233009708 0.6056090665133218\n",
      "train loss per epoch 0.8228767013262553\n",
      "Validation loss per epoch: 0.86348132076628\n",
      "*************** Starting with epoch:  5 ***********************\n",
      "epoch : 5 Train accuracy and macro_f1: 0.7228915662650602 0.7175707693982855\n",
      "epoch : 5 Validation accuracy, macro_f1: 0.6359223300970874 0.6231591421464839\n",
      "train loss per epoch 0.7904703535760442\n",
      "Validation loss per epoch: 0.8523760413732923\n",
      "*************** Starting with epoch:  6 ***********************\n",
      "epoch : 6 Train accuracy and macro_f1: 0.7349397590361446 0.7304547118427314\n",
      "epoch : 6 Validation accuracy, macro_f1: 0.6407766990291263 0.6294238486019308\n",
      "train loss per epoch 0.7630242731460657\n",
      "Validation loss per epoch: 0.8413722414197853\n",
      "*************** Starting with epoch:  7 ***********************\n",
      "epoch : 7 Train accuracy and macro_f1: 0.7542168674698795 0.7505020560102761\n",
      "epoch : 7 Validation accuracy, macro_f1: 0.6456310679611651 0.6359890109890111\n",
      "train loss per epoch 0.7390334270462529\n",
      "Validation loss per epoch: 0.8364146297562469\n",
      "*************** Starting with epoch:  8 ***********************\n",
      "epoch : 8 Train accuracy and macro_f1: 0.7650602409638554 0.7619613461425354\n",
      "epoch : 8 Validation accuracy, macro_f1: 0.6553398058252428 0.6461112707688049\n",
      "train loss per epoch 0.7180902466467186\n",
      "Validation loss per epoch: 0.827780351440594\n",
      "*************** Starting with epoch:  9 ***********************\n",
      "epoch : 9 Train accuracy and macro_f1: 0.7734939759036145 0.7709520191571562\n",
      "epoch : 9 Validation accuracy, macro_f1: 0.6650485436893204 0.654263882112358\n",
      "train loss per epoch 0.6993570796685316\n",
      "Validation loss per epoch: 0.8215686202736445\n",
      "*************** Starting with epoch:  10 ***********************\n",
      "epoch : 10 Train accuracy and macro_f1: 0.7831325301204819 0.7800533570465044\n",
      "epoch : 10 Validation accuracy, macro_f1: 0.6699029126213593 0.6609599083345629\n",
      "train loss per epoch 0.6824736483556271\n",
      "Validation loss per epoch: 0.819119075692973\n",
      "*************** Starting with epoch:  11 ***********************\n",
      "epoch : 11 Train accuracy and macro_f1: 0.7879518072289157 0.7848330556646008\n",
      "epoch : 11 Validation accuracy, macro_f1: 0.6893203883495146 0.6803862634176377\n",
      "train loss per epoch 0.6671431985580882\n",
      "Validation loss per epoch: 0.8225776149158918\n",
      "*************** Starting with epoch:  12 ***********************\n",
      "epoch : 12 Train accuracy and macro_f1: 0.7987951807228916 0.796317477860129\n",
      "epoch : 12 Validation accuracy, macro_f1: 0.6990291262135923 0.6904270947478995\n",
      "train loss per epoch 0.6530186380632567\n",
      "Validation loss per epoch: 0.8179049156154099\n",
      "*************** Starting with epoch:  13 ***********************\n",
      "epoch : 13 Train accuracy and macro_f1: 0.808433734939759 0.8058304280097915\n",
      "epoch : 13 Validation accuracy, macro_f1: 0.7087378640776699 0.700266153599487\n",
      "train loss per epoch 0.6399818511343146\n",
      "Validation loss per epoch: 0.816310103711428\n",
      "*************** Starting with epoch:  14 ***********************\n",
      "epoch : 14 Train accuracy and macro_f1: 0.8132530120481928 0.8109569805953322\n",
      "epoch : 14 Validation accuracy, macro_f1: 0.7087378640776699 0.7012600908538525\n",
      "train loss per epoch 0.6279215656050358\n",
      "Validation loss per epoch: 0.8161049066744384\n",
      "*************** Starting with epoch:  15 ***********************\n",
      "epoch : 15 Train accuracy and macro_f1: 0.8132530120481928 0.8112340216322517\n",
      "epoch : 15 Validation accuracy, macro_f1: 0.7184466019417476 0.7101910006577334\n",
      "train loss per epoch 0.6166572032821034\n",
      "Validation loss per epoch: 0.8206647463793894\n",
      "*************** Starting with epoch:  16 ***********************\n",
      "epoch : 16 Train accuracy and macro_f1: 0.8216867469879519 0.819995831232346\n",
      "epoch : 16 Validation accuracy, macro_f1: 0.7184466019417476 0.7114587544129138\n",
      "train loss per epoch 0.6060705657698898\n",
      "Validation loss per epoch: 0.8174983107832993\n",
      "*************** Starting with epoch:  17 ***********************\n",
      "epoch : 17 Train accuracy and macro_f1: 0.827710843373494 0.8260274538171687\n",
      "epoch : 17 Validation accuracy, macro_f1: 0.7184466019417476 0.7093739593739595\n",
      "train loss per epoch 0.596095508434922\n",
      "Validation loss per epoch: 0.8235273398820636\n",
      "*************** Starting with epoch:  18 ***********************\n",
      "epoch : 18 Train accuracy and macro_f1: 0.8301204819277108 0.8281691354527249\n",
      "epoch : 18 Validation accuracy, macro_f1: 0.7184466019417476 0.7097041794385248\n",
      "train loss per epoch 0.586669633436928\n",
      "Validation loss per epoch: 0.8263591521971144\n",
      "*************** Starting with epoch:  19 ***********************\n",
      "epoch : 19 Train accuracy and macro_f1: 0.8373493975903614 0.835406484470477\n",
      "epoch : 19 Validation accuracy, macro_f1: 0.7233009708737864 0.7145977634270038\n",
      "train loss per epoch 0.5776845868869618\n",
      "Validation loss per epoch: 0.8343426902389642\n",
      "*************** Starting with epoch:  20 ***********************\n",
      "epoch : 20 Train accuracy and macro_f1: 0.8373493975903614 0.8352964902388503\n",
      "epoch : 20 Validation accuracy, macro_f1: 0.7233009708737864 0.7163742690058479\n",
      "train loss per epoch 0.569157381041234\n",
      "Validation loss per epoch: 0.8411182101309589\n",
      "*************** Starting with epoch:  21 ***********************\n",
      "epoch : 21 Train accuracy and macro_f1: 0.8421686746987952 0.8401123201123202\n",
      "epoch : 21 Validation accuracy, macro_f1: 0.7281553398058253 0.721293912537822\n",
      "train loss per epoch 0.5610247069055537\n",
      "Validation loss per epoch: 0.845659408573676\n",
      "*************** Starting with epoch:  22 ***********************\n",
      "epoch : 22 Train accuracy and macro_f1: 0.8421686746987952 0.8399987218673793\n",
      "epoch : 22 Validation accuracy, macro_f1: 0.7184466019417476 0.7107560075647147\n",
      "train loss per epoch 0.553254411749214\n",
      "Validation loss per epoch: 0.8500079223727898\n",
      "*************** Starting with epoch:  23 ***********************\n",
      "epoch : 23 Train accuracy and macro_f1: 0.8457831325301205 0.843559392173673\n",
      "epoch : 23 Validation accuracy, macro_f1: 0.7135922330097088 0.7061891712150948\n",
      "train loss per epoch 0.5457878210901981\n",
      "Validation loss per epoch: 0.8537002049060991\n",
      "*************** Starting with epoch:  24 ***********************\n",
      "epoch : 24 Train accuracy and macro_f1: 0.8493975903614458 0.8470258874664394\n",
      "epoch : 24 Validation accuracy, macro_f1: 0.7184466019417476 0.7093729482183572\n",
      "train loss per epoch 0.5385930051112727\n",
      "Validation loss per epoch: 0.8541035068682531\n",
      "*************** Starting with epoch:  25 ***********************\n",
      "epoch : 25 Train accuracy and macro_f1: 0.8542168674698796 0.8518815786339733\n",
      "epoch : 25 Validation accuracy, macro_f1: 0.7135922330097088 0.7045422877123313\n",
      "train loss per epoch 0.5316358794067534\n",
      "Validation loss per epoch: 0.8573937138126603\n",
      "*************** Starting with epoch:  26 ***********************\n",
      "epoch : 26 Train accuracy and macro_f1: 0.8530120481927711 0.8506367616764187\n",
      "epoch : 26 Validation accuracy, macro_f1: 0.7087378640776699 0.7004660833886639\n",
      "train loss per epoch 0.5249495856361364\n",
      "Validation loss per epoch: 0.8660565786497686\n",
      "*************** Starting with epoch:  27 ***********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 27 Train accuracy and macro_f1: 0.8590361445783132 0.8564511192672684\n",
      "epoch : 27 Validation accuracy, macro_f1: 0.7135922330097088 0.7052884510305336\n",
      "train loss per epoch 0.5184910150378379\n",
      "Validation loss per epoch: 0.8751354639246626\n",
      "*************** Starting with epoch:  28 ***********************\n",
      "epoch : 28 Train accuracy and macro_f1: 0.8566265060240964 0.8541514042258962\n",
      "epoch : 28 Validation accuracy, macro_f1: 0.7184466019417476 0.7097718467498924\n",
      "train loss per epoch 0.5122274529153759\n",
      "Validation loss per epoch: 0.8843723910236821\n",
      "*************** Starting with epoch:  29 ***********************\n",
      "epoch : 29 Train accuracy and macro_f1: 0.8578313253012049 0.8553844526006017\n",
      "epoch : 29 Validation accuracy, macro_f1: 0.7233009708737864 0.7145679012345679\n",
      "train loss per epoch 0.5061456655292494\n",
      "Validation loss per epoch: 0.8945919415615138\n"
     ]
    }
   ],
   "source": [
    "###########.........Start Training...........\n",
    "model = JointDLT()\n",
    "##### Hyperparameter\n",
    "#learning_rate=0.05\n",
    "learning_rate=0.01\n",
    "epochs = 30\n",
    "#opt=\"ADAM\"\n",
    "#opt=\"SGD\" \n",
    "opt=\"ADA\"\n",
    "if(opt==\"SGD\"):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "elif(opt==\"ADA\"):\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=learning_rate, eps=1e-06, weight_decay=0.0001)\n",
    "elif(opt==\"ADAM\"):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "\n",
    "    \n",
    "loss_function = nn.NLLLoss()\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "check_val_acc = 0\n",
    "losses = []\n",
    "per_epoch_train_loss =[]\n",
    "per_epoch_val_loss =[]\n",
    "per_epoch_train_f1 =[]\n",
    "per_epoch_val_f1 = []\n",
    "for epoch in range(epochs): \n",
    "    print('*************** Starting with epoch: ', epoch, '***********************')\n",
    "    for i in range (0,len(train_data)):\n",
    "        #model_des.zero_grad()\n",
    "        #model_loc.zero_grad()\n",
    "        model.zero_grad()\n",
    "        #####Run forward pass.\n",
    "      \n",
    "        prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_twt[i])\n",
    "        \n",
    "        #print(\"prediction_joint :\", torch.argmax(prediction_joint, dim=1)) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        #Compute the loss, gradients, and update the parameters by\n",
    "        #calling optimizer.step()\n",
    "        loss = loss_function(prediction_joint, train_gt[i])\n",
    "        #if (i%200 == 0):\n",
    "            #print (\"loss per example\", loss.item())\n",
    "        losses.append(loss.item())\n",
    "        loss.backward(retain_graph=True)  #backpropagation\n",
    "        optimizer.step()\n",
    "    accuracy, macro_f1 = make_prediction_tr(model, training_data_des, training_data_loc, training_data_twt, train_gt)\n",
    "    print('epoch :', epoch, 'Train accuracy and macro_f1:', accuracy, macro_f1)\n",
    "    per_epoch_train_f1.append(macro_f1)\n",
    "    val_accuracy, val_macro_f1, val_loss = make_prediction_val(model, validation_data_des, validation_data_loc, validation_data_twt, valid_gt)\n",
    "    per_epoch_val_f1.append(val_macro_f1)\n",
    "    print('epoch :', epoch, 'Validation accuracy, macro_f1:', val_accuracy, val_macro_f1)\n",
    "    per_epoch_train_loss.append(np.mean(losses))\n",
    "    print(\"train loss per epoch\", np.mean(losses))\n",
    "    per_epoch_val_loss.append(np.mean(val_loss))\n",
    "    print('Validation loss per epoch:', np.mean(val_loss))\n",
    "    torch.save(model.state_dict(),\"data/DLT_utype/joint_DLT_\"+str(epoch)+\".pt\")\n",
    "#     if (check_val_acc < val_macro_f1): #early stopping\n",
    "#         check_val_acc = val_macro_f1\n",
    "#         print (\"Model saved at epoch :\", epoch)\n",
    "#         torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "#         best_epoch = epoch\n",
    "        \n",
    "#print(\"Best model found at epoch : \", best_epoch)        \n",
    "#torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_plots(train_losses, val_losses, train_accs, test_accs):\n",
    "    \"\"\"Plot\n",
    "\n",
    "        Plot two figures: loss vs. epoch and accuracy vs. epoch\n",
    "    \"\"\"\n",
    "    n = len(train_losses)\n",
    "    xs = np.arange(n)\n",
    "\n",
    "    # plot losses\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_losses, '--', linewidth=2, label='train loss')\n",
    "    ax.plot(xs, val_losses, '-', linewidth=2, label='validation loss')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.savefig('loss_DLT_utype_2layer_cls.png')\n",
    "\n",
    "    # plot train and test accuracies\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_accs, '--', linewidth=2, label='train')\n",
    "    ax.plot(xs, test_accs, '-', linewidth=2, label='validation')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Macro-avg F1\")\n",
    "    ax.legend(loc='lower right')\n",
    "    plt.savefig('accuracy_DLT_utype_2layer_cls.png')\n",
    "    \n",
    "save_plots(per_epoch_train_loss, per_epoch_val_loss, per_epoch_train_f1, per_epoch_val_f1)\n",
    "# print(per_epoch_train_loss)\n",
    "# print(per_epoch_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction(training_data_des, training_data_loc, training_data_twt, ground_truths):\n",
    "    for epoch in range(0,30):\n",
    "        model = JointDLT()\n",
    "        model.load_state_dict(torch.load(\"data/DLT_utype/joint_DLT_\"+str(epoch)+\".pt\")) #best #Testing accuracy, macro_f1: 0.7862595419847328 0.7560951140518181\n",
    "        predictions =[]\n",
    "        for i in range (0,len(training_data_des)):\n",
    "            prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_twt[i])\n",
    "            pred = torch.argmax(prediction_joint, dim=1)\n",
    "            predictions.append(pred.item())\n",
    "        #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "        accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_des)\n",
    "        macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "        print('epoch :', epoch, 'Testing accuracy, macro_f1:', accuracy, macro_f1)\n",
    "        #return accuracy, macro_f1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "########.....Load Test data.......\n",
    "with open(\"data/test.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "test_data = data[:] \n",
    "#print(test_data, len(test_data)) #262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no location for user:  vaibhavatttc\n"
     ]
    }
   ],
   "source": [
    "#####prepare testing data for neural net #########\n",
    "testing_data_des, testing_data_loc, testing_data_twt =  nn_input(test_data,df)\n",
    "#testing_data_net =  nn_input_network(test_data,df)\n",
    "test_gt = find_groundtruth(test_data, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########........Calculate Validation Accuracy.......\n",
    "# test_accuracy, test_macro_f1 = make_prediction(testing_data_des, testing_data_loc, testing_data_twt, test_gt)\n",
    "# print('Testing accuracy, macro_f1:', test_accuracy, test_macro_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 Testing accuracy, macro_f1: 0.6030534351145038 0.5423692441862461\n",
      "epoch : 1 Testing accuracy, macro_f1: 0.6374045801526718 0.5851679633169319\n",
      "epoch : 2 Testing accuracy, macro_f1: 0.6717557251908397 0.6282697113054364\n",
      "epoch : 3 Testing accuracy, macro_f1: 0.6984732824427481 0.660349108319812\n",
      "epoch : 4 Testing accuracy, macro_f1: 0.7022900763358778 0.6652436497489153\n",
      "epoch : 5 Testing accuracy, macro_f1: 0.6984732824427481 0.6624564454026091\n",
      "epoch : 6 Testing accuracy, macro_f1: 0.7022900763358778 0.667350523565192\n",
      "epoch : 7 Testing accuracy, macro_f1: 0.7137404580152672 0.6782836039198479\n",
      "epoch : 8 Testing accuracy, macro_f1: 0.7213740458015268 0.6872103157446867\n",
      "epoch : 9 Testing accuracy, macro_f1: 0.7290076335877863 0.6960404940587867\n",
      "epoch : 10 Testing accuracy, macro_f1: 0.732824427480916 0.6999520087755382\n",
      "epoch : 11 Testing accuracy, macro_f1: 0.7480916030534351 0.7143273501643717\n",
      "epoch : 12 Testing accuracy, macro_f1: 0.7480916030534351 0.7134524601590471\n",
      "epoch : 13 Testing accuracy, macro_f1: 0.7519083969465649 0.717286409915892\n",
      "epoch : 14 Testing accuracy, macro_f1: 0.7557251908396947 0.7200086299892124\n",
      "epoch : 15 Testing accuracy, macro_f1: 0.7595419847328244 0.7237599453280875\n",
      "epoch : 16 Testing accuracy, macro_f1: 0.7595419847328244 0.7246713566555689\n",
      "epoch : 17 Testing accuracy, macro_f1: 0.7557251908396947 0.7218545455912256\n",
      "epoch : 18 Testing accuracy, macro_f1: 0.7595419847328244 0.7248026300306488\n",
      "epoch : 19 Testing accuracy, macro_f1: 0.7557251908396947 0.7236859266988391\n",
      "epoch : 20 Testing accuracy, macro_f1: 0.7595419847328244 0.7258037189494558\n",
      "epoch : 21 Testing accuracy, macro_f1: 0.7633587786259542 0.7294735932102734\n",
      "epoch : 22 Testing accuracy, macro_f1: 0.7595419847328244 0.7258037189494558\n",
      "epoch : 23 Testing accuracy, macro_f1: 0.7595419847328244 0.7258037189494558\n",
      "epoch : 24 Testing accuracy, macro_f1: 0.767175572519084 0.7359460851196585\n",
      "epoch : 25 Testing accuracy, macro_f1: 0.7633587786259542 0.7330882132199746\n",
      "epoch : 26 Testing accuracy, macro_f1: 0.767175572519084 0.7367313765989773\n",
      "epoch : 27 Testing accuracy, macro_f1: 0.7633587786259542 0.7330882132199746\n",
      "epoch : 28 Testing accuracy, macro_f1: 0.7633587786259542 0.7330882132199746\n",
      "epoch : 29 Testing accuracy, macro_f1: 0.7595419847328244 0.7286502592058147\n"
     ]
    }
   ],
   "source": [
    "make_prediction(testing_data_des, testing_data_loc, testing_data_twt, test_gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
