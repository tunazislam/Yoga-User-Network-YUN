{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10c4404b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "import spacy  # For preprocessing\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p  #pip install tweet-preprocessor\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation as punc\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "#from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.models as gsm\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import regex\n",
    "import emoji\n",
    "# Internal dependencies\n",
    "import word_emoji2vec as we2v\n",
    "#from word_emoji2vec import Word_Emoji2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed #python -m spacy download en\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## load embeddings #######\n",
    "loc_emb = torch.load('data/locationEmbeddings.pt') \n",
    "des_emb = torch.load('data/descriptionEmbeddings.pt') \n",
    "twt_emb = torch.load('data/tweetsEmbeddings.pt') \n",
    "\n",
    "#load network embedding\n",
    "#net_emb = gsm.KeyedVectors.load_word2vec_format('data/userNetworkEmd.emd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user = net_emb ['000mrs000']\n",
    "#print(user)\n",
    "#print(type(net_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load 1300 user location, description, yoga tweets, utype, umotivation\n",
    "df = pd.read_csv(\"data/yoga_user_name_loc_des_mergetweets_yoga_1300_lb.csv\") \n",
    "#print (df) #[1308 rows x 7 columns] name, location, description, text, utype, umotivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load train users and split into train and validation #######\n",
    "with open(\"data/train.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "random.seed(1)\n",
    "random.shuffle(data)\n",
    "\n",
    "train_data = data[:830] #80% train  \n",
    "#print(train_data, len(train_data)) #830\n",
    "valid_data = data[830:] #20% validation\n",
    "#print(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create BiLSTMAttention Model for Description\n",
    "class BiLSTMDesAtt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiLSTMDesAtt, self).__init__() \n",
    "        self.lstm = nn.LSTM(300, 150//2 , num_layers=1, bidirectional=True ) #BiLSTM with attention \n",
    "        #self.lstm = nn.LSTM(300, 150 , num_layers=1, bidirectional=False) #LSTM with attention\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        self.hidden = self.init_hidden() # <- change here \n",
    "        self.attn_fc = torch.nn.Linear(300, 1) #attention layer\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        #(2*self.num_layers, batch_size, self.hidden_dim // 2)\n",
    "        return (torch.zeros(2 * 1, 1, 150//2), torch.zeros(2 * 1, 1, 150//2)) # <- change here: first dim of hidden needs to be doubled\n",
    "        #return (torch.zeros(1 * 1, 1, 150), torch.zeros(1 * 1, 1, 150))#LSTM with attention\n",
    "    def attention(self, rnn_out, state):\n",
    "        #print(\"rnn_out\", rnn_out.size()) #torch.Size([13, 1, 150])\n",
    "        #rnn_out = rnn_out.squeeze(0).unsqueeze(1) \n",
    "        #rnn_out = rnn_out.permute(2,0,1) \n",
    "        rnn_out = rnn_out.permute(1,0,2) \n",
    "        #print(\"permute rnn_out\", rnn_out.size()) #torch.Size([150, 13, 1])\n",
    "        #print(\"state\", state.size()) #torch.Size([2, 1, 75])\n",
    "        merged_state = torch.cat([s for s in state],1)\n",
    "        #print(\"merged_state\", merged_state.size()) #torch.Size([1, 150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).size()) #torch.Size([150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).size()) #torch.Size([150, 1])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).unsqueeze(2).size()) # torch.Size([150, 1, 1])\n",
    "        #merged_state = merged_state.squeeze(0).unsqueeze(2)\n",
    "        merged_state = merged_state.squeeze(0).unsqueeze(1).unsqueeze(2)\n",
    "        #print(\"merged_state2 :\", merged_state.size()) #torch.Size([150, 1, 1])\n",
    "        merged_state = merged_state.permute(1,0,2)\n",
    "        # (batch, seq_len, cell_size) * (batch, cell_size, 1) = (batch, seq_len, 1)\n",
    "        weights = torch.bmm(rnn_out, merged_state)\n",
    "        #print(\"weights\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        #weights = torch.nn.functional.softmax(weights.squeeze(2)).unsqueeze(2)\n",
    "        weights = F.log_softmax(weights.squeeze(2),dim = 1).unsqueeze(2)\n",
    "         #F.log_softmax(x, dim = 1)\n",
    "        #print(\"weights2 :\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        # (batch, cell_size, seq_len) * (batch, seq_len, 1) = (batch, cell_size, 1)\n",
    "        return torch.bmm(torch.transpose(rnn_out, 1, 2), weights).squeeze(2)\n",
    "    # end method attention\n",
    "\n",
    "    def forward(self, X):\n",
    "        #print(X.size()) # torch.Size([13, 300])\n",
    "        #print('resize', x.view(len(x),1,-1), x.view(len(x),1,-1).size()) #torch.Size([13, 1, 300])\n",
    "        lstm_out, hidden = self.lstm(X.view(len(X),1, -1))\n",
    "        #print('lstm_out', lstm_out, lstm_out.size()) # torch.Size([13, 1, 150])\n",
    "        #print('hidden[0] = h_n', hidden[0], hidden[0].size()) # torch.Size([2, 1, 75])\n",
    "        #print('hidden[1] = c_n', hidden[1], hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        h_n, c_n = hidden\n",
    "        #print('h_n', h_n, h_n.size()) # torch.Size([2, 1, 75])\n",
    "        #print('c_n', c_n, hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        attn_out = self.attention(lstm_out, h_n)\n",
    "        #print(\"attn_out\", attn_out.size()) #torch.Size([150, 1])\n",
    "        #logits = self.fc2(attn_out)\n",
    "        #logits = self.fc2(attn_out.permute(1,0))\n",
    "        #print(\"logits\", logits, logits.size())\n",
    "        #return logits \n",
    "        return attn_out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create BiLSTMAttention Model for Description\n",
    "class BiLSTMTwtAtt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiLSTMTwtAtt, self).__init__() \n",
    "        self.lstm = nn.LSTM(300, 150//2 , num_layers=1, bidirectional=True ) #BiLSTM with attention \n",
    "        #self.lstm = nn.LSTM(300, 150 , num_layers=1, bidirectional=False) #LSTM with attention\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        self.hidden = self.init_hidden() # <- change here \n",
    "        self.attn_fc = torch.nn.Linear(300, 1) #attention layer\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        #(2*self.num_layers, batch_size, self.hidden_dim // 2)\n",
    "        return (torch.zeros(2 * 1, 1, 150//2), torch.zeros(2 * 1, 1, 150//2)) # <- change here: first dim of hidden needs to be doubled\n",
    "        #return (torch.zeros(1 * 1, 1, 150), torch.zeros(1 * 1, 1, 150))#LSTM with attention\n",
    "    def attention(self, rnn_out, state):\n",
    "        #print(\"rnn_out\", rnn_out.size()) #torch.Size([13, 1, 150])\n",
    "        #rnn_out = rnn_out.squeeze(0).unsqueeze(1) \n",
    "        #rnn_out = rnn_out.permute(2,0,1) \n",
    "        rnn_out = rnn_out.permute(1,0,2) \n",
    "        #print(\"permute rnn_out\", rnn_out.size()) #torch.Size([150, 13, 1])\n",
    "        #print(\"state\", state.size()) #torch.Size([2, 1, 75])\n",
    "        merged_state = torch.cat([s for s in state],1)\n",
    "        #print(\"merged_state\", merged_state.size()) #torch.Size([1, 150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).size()) #torch.Size([150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).size()) #torch.Size([150, 1])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).unsqueeze(2).size()) # torch.Size([150, 1, 1])\n",
    "        #merged_state = merged_state.squeeze(0).unsqueeze(2)\n",
    "        merged_state = merged_state.squeeze(0).unsqueeze(1).unsqueeze(2)\n",
    "        #print(\"merged_state2 :\", merged_state.size()) #torch.Size([150, 1, 1])\n",
    "        merged_state = merged_state.permute(1,0,2)\n",
    "        # (batch, seq_len, cell_size) * (batch, cell_size, 1) = (batch, seq_len, 1)\n",
    "        weights = torch.bmm(rnn_out, merged_state)\n",
    "        #print(\"weights\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        #weights = torch.nn.functional.softmax(weights.squeeze(2)).unsqueeze(2)\n",
    "        weights = F.log_softmax(weights.squeeze(2),dim = 1).unsqueeze(2)\n",
    "         #F.log_softmax(x, dim = 1)\n",
    "        #print(\"weights2 :\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        # (batch, cell_size, seq_len) * (batch, seq_len, 1) = (batch, cell_size, 1)\n",
    "        return torch.bmm(torch.transpose(rnn_out, 1, 2), weights).squeeze(2)\n",
    "    # end method attention\n",
    "\n",
    "    def forward(self, X):\n",
    "        #print(X.size()) # torch.Size([13, 300])\n",
    "        #print('resize', x.view(len(x),1,-1), x.view(len(x),1,-1).size()) #torch.Size([13, 1, 300])\n",
    "        lstm_out, hidden = self.lstm(X.view(len(X),1, -1))\n",
    "        #print('lstm_out', lstm_out, lstm_out.size()) # torch.Size([13, 1, 150])\n",
    "        #print('hidden[0] = h_n', hidden[0], hidden[0].size()) # torch.Size([2, 1, 75])\n",
    "        #print('hidden[1] = c_n', hidden[1], hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        h_n, c_n = hidden\n",
    "        #print('h_n', h_n, h_n.size()) # torch.Size([2, 1, 75])\n",
    "        #print('c_n', c_n, hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        attn_out = self.attention(lstm_out, h_n)\n",
    "        #print(\"attn_out\", attn_out.size()) #torch.Size([150, 1])\n",
    "        #logits = self.fc2(attn_out)\n",
    "        #logits = self.fc2(attn_out.permute(1,0))\n",
    "        #print(\"logits\", logits, logits.size())\n",
    "        #return logits \n",
    "        return attn_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create LSTM Model for Location #############\n",
    "class LSTMLoc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMLoc, self).__init__()\n",
    "        self.lstm = nn.LSTM(300, 150, num_layers=1)\n",
    "        self.fc2 = nn.Linear(150, 50) \n",
    "        self.hidden = self.init_hidden() # <- change here \n",
    "\n",
    "    def init_hidden(self):\n",
    "        #(2*self.num_layers, batch_size, self.hidden_dim // 2)# <- change here: first dim of hidden needs to be doubled\n",
    "        return (torch.zeros(1, 1, 150), torch.zeros(1, 1, 150)) \n",
    "    def forward(self, x):\n",
    "        #x=embeds.permute(1,0,2)\n",
    "        #print('resize', x.view(len(x),1,-1), x.view(len(x),1,-1).size()) #torch.Size([13, 1, 300])\n",
    "        #lstm_out, self.hidden = self.lstm(x.view(len(x),1, -1), self.hidden)\n",
    "        lstm_out, _ = self.lstm(x.view(len(x),1, -1))\n",
    "        #lstm_out, _ = self.lstm(x.view(len(x),1,-1)) \n",
    "        #print('lstm_out', lstm_out, lstm_out.size()) # torch.Size([13, 1, 150])\n",
    "        #print('self.hidden[0]', self.hidden[0], self.hidden[0].size()) # torch.Size([1, 1, 150])\n",
    "        #print(\"lstm_out[-1]\", lstm_out[-1], lstm_out[-1].size())  # torch.Size([1, 150])\n",
    "        #x = self.fc2(lstm_out[-1])  \n",
    "        #out = F.log_softmax(x, dim = 1)\n",
    "        #return out\n",
    "        #return x\n",
    "        return lstm_out[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create Model \n",
    "class NetworkMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkMLP, self).__init__() \n",
    "        self.fc1 = nn.Linear(300, 150)\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #print(X.size()) # torch.Size([300])\n",
    "        #print('resize', X.view(1,len(X)).size()) #resize torch.Size([1, 300])\n",
    "        z1 = self.fc1(X.view(1,len(X)))\n",
    "        #print('z1', z1, z1.size()) # torch.Size([1, 150])\n",
    "        h1 = F.relu(z1)\n",
    "        return h1\n",
    "        #logits = self.fc2(h1) #without attention\n",
    "        #print(\"logits\", logits, logits.size()) #torch.Size([1, 3])\n",
    "        #return logits \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointDLT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JointDLT, self).__init__()\n",
    "        self.model_des = BiLSTMDesAtt()\n",
    "        self.model_loc = LSTMLoc()\n",
    "        #self.model_twt = BiLSTMDesAtt()\n",
    "        self.model_twt = BiLSTMTwtAtt()\n",
    "        #self.model_net = NetworkMLP()\n",
    "\n",
    "        self.fc1 = nn.Linear(450, 200) \n",
    "        self.fc2 = nn.Linear(200, 3)\n",
    "#        self.fc1 = nn.Linear(450, 3)\n",
    "    def forward(self, x_d, x_l, x_t): \n",
    "        prediction_des = self.model_des(x_d)\n",
    "        #print(prediction_des, prediction_des.size())\n",
    "        prediction_loc = self.model_loc(x_l)\n",
    "        #print(prediction_loc, prediction_loc.size())\n",
    "        prediction_twt = self.model_twt(x_t)\n",
    "        #prediction_net = self.model_net(x_n)\n",
    "        concat_pred = torch.cat((prediction_des, prediction_loc, prediction_twt), 1) #concat with dim= 1\n",
    "        #print(concat_pred, concat_pred.size()) \n",
    "#         out = F.log_softmax(self.fc(concat_pred), dim = 1)\n",
    "#         return out\n",
    "        out = self.fc1(concat_pred)\n",
    "        out = self.fc2(F.relu(out))\n",
    "        out = F.log_softmax(out, dim = 1)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare data for neural net input #########\n",
    "def nn_input(train_data,df):\n",
    "    #ground_truths = []\n",
    "    training_data_des =[]\n",
    "    training_data_loc=[]\n",
    "    training_data_twt =[]\n",
    "    for i in range (0, len(train_data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (train_data[i] == df.name[j]):\n",
    "                if (not des_emb[train_data[i]]) and (not loc_emb[train_data[i]]) and (twt_emb[train_data[i]]):\n",
    "                    print ('no description and location for user: ', train_data[i])\n",
    "                    training_data_des.append(torch.zeros(1, 300))\n",
    "                    training_data_loc.append(torch.zeros(1, 300))\n",
    "                    sent_tensor_twt = torch.stack(twt_emb[train_data[i]],dim = 1)\n",
    "                    training_data_twt.append(sent_tensor_twt[-1])\n",
    "                    break\n",
    "                \n",
    "                elif (des_emb[train_data[i]]) and (not loc_emb[train_data[i]]) and (twt_emb[train_data[i]]): \n",
    "                    print ('no location for user: ', train_data[i])\n",
    "                    sent_tensor_des = torch.stack(des_emb[train_data[i]],dim = 1)\n",
    "                    training_data_des.append(sent_tensor_des[-1])\n",
    "                    training_data_loc.append(torch.zeros(1, 300))\n",
    "                    sent_tensor_twt = torch.stack(twt_emb[train_data[i]],dim = 1)\n",
    "                    training_data_twt.append(sent_tensor_twt[-1])\n",
    "                    break\n",
    "                    \n",
    "                elif (not des_emb[train_data[i]]) and (loc_emb[train_data[i]]) and (twt_emb[train_data[i]]): \n",
    "                    print ('no description for user: ', train_data[i])\n",
    "                    training_data_des.append(torch.zeros(1, 300))\n",
    "                    sent_tensor_loc = torch.stack(loc_emb[train_data[i]],dim = 1)\n",
    "                    training_data_loc.append(sent_tensor_loc[-1])\n",
    "                    sent_tensor_twt = torch.stack(twt_emb[train_data[i]],dim = 1)\n",
    "                    training_data_twt.append(sent_tensor_twt[-1])\n",
    "                    break    \n",
    "               \n",
    "                elif (des_emb[train_data[i]]) and (loc_emb[train_data[i]]) and (twt_emb[train_data[i]]): \n",
    "                    sent_tensor_des = torch.stack(des_emb[train_data[i]],dim = 1)\n",
    "                    training_data_des.append(sent_tensor_des[-1])\n",
    "                    sent_tensor_loc = torch.stack(loc_emb[train_data[i]],dim = 1)\n",
    "                    training_data_loc.append(sent_tensor_loc[-1])\n",
    "                    sent_tensor_twt = torch.stack(twt_emb[train_data[i]],dim = 1)\n",
    "                    training_data_twt.append(sent_tensor_twt[-1])\n",
    "                    break\n",
    "    return training_data_des, training_data_loc, training_data_twt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare data for neural net #########\n",
    "def nn_input_network(train_data,df):\n",
    "    training_data =[]\n",
    "    for i in range (0, len(train_data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (train_data[i] == df.name[j]):\n",
    "                #print(train_data[i]) #print username\n",
    "                utype =  [int(df.utype[j])]\n",
    "                umotivation = [int(float(df.umotivation[j]))]\n",
    "                #print (\"net_emb[train_data[i]] : \", net_emb[train_data[i]], type(net_emb[train_data[i]]), torch.Tensor(net_emb[train_data[i]]), type(torch.Tensor(net_emb[train_data[i]])))\n",
    "                #count = 0\n",
    "                if(train_data[i] not in net_emb ):\n",
    "                    net_emb[train_data[i]] = np.zeros(300) #For users not appearing in the mention network, we set their network embedding vectors as 0.\n",
    "                    #count = count + 1\n",
    "                #print(count)\n",
    "                #print(net_emb[train_data[i]]) #ok\n",
    "                ####.....convert ndarray to torch.tensor........\n",
    "                net_emb_tensor = torch.Tensor(net_emb[train_data[i]])\n",
    "                #print(net_emb_tensor) #ok\n",
    "                training_data.append(net_emb_tensor)\n",
    "                break\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Ground Truth #########\n",
    "def find_groundtruth(data, df):\n",
    "    ground_truths = []\n",
    "    for i in range (0, len(data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (data[i] == df.name[j]):\n",
    "                #print(data[i]) #print username\n",
    "                utype =  [int(df.utype[j])]\n",
    "                umotivation = [int(float(df.umotivation[j]))]\n",
    "                #target_type = torch.tensor(utype, dtype=torch.long) #for user type\n",
    "                target_type = torch.tensor(umotivation, dtype=torch.long) #for user motivation\n",
    "                ground_truths.append(target_type)\n",
    "    return ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_tr(model, training_data_des, training_data_loc, training_data_twt, ground_truths):\n",
    "    predictions =[]\n",
    "    for i in range (0,len(training_data_des)):\n",
    "        prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_twt[i])\n",
    "        \n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_des)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    \n",
    "    return accuracy, macro_f1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_val(model, training_data_des, training_data_loc, training_data_twt, ground_truths):\n",
    "    predictions =[]\n",
    "    val_losses = []\n",
    "    loss_function = nn.NLLLoss()\n",
    "    for i in range (0,len(training_data_des)):\n",
    "        prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_twt[i])\n",
    "        val_loss = loss_function(prediction_joint, ground_truths[i])\n",
    "        val_losses.append(val_loss.item())\n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_des)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    \n",
    "    return accuracy, macro_f1, val_losses\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no description for user:  bchi49\n",
      "no location for user:  Christoph_Tran\n",
      "no description for user:  viecestlavie\n",
      "no description for user:  crystalization_\n",
      "no location for user:  yogitimesonline\n",
      "no description for user:  mimmosamami\n",
      "no description for user:  wenmarbyoga\n",
      "no location for user:  cipherEquality\n",
      "no description for user:  YogaLifeLine\n",
      "no location for user:  thewaywecame\n"
     ]
    }
   ],
   "source": [
    "##########......prepare training and validation data\n",
    "# ground truth training\n",
    "train_gt = find_groundtruth(train_data, df)\n",
    "#####prepare training data for neural net #########\n",
    "#training_data_net =  nn_input_network(train_data,df)\n",
    "#print(training_data_net, len(training_data_net)) #ok\n",
    "training_data_des, training_data_loc, training_data_twt =  nn_input(train_data,df)\n",
    "\n",
    "# ground truth validation\n",
    "valid_gt = find_groundtruth(valid_data, df)\n",
    "#####prepare validation data for neural net #########\n",
    "#validation_data_net =  nn_input_network(valid_data,df)\n",
    "validation_data_des, validation_data_loc, validation_data_twt =  nn_input(valid_data,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Starting with epoch:  0 ***********************\n",
      "epoch : 0 Train accuracy and macro_f1: 0.5373493975903615 0.3435499968632551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tunaz/miniconda2/envs/py3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 Validation accuracy, macro_f1: 0.587378640776699 0.3841018080761866\n",
      "train loss per epoch 1.0078239087127598\n",
      "Validation loss per epoch: 1.132395930154231\n",
      "*************** Starting with epoch:  1 ***********************\n",
      "epoch : 1 Train accuracy and macro_f1: 0.5831325301204819 0.3849059308762875\n",
      "epoch : 1 Validation accuracy, macro_f1: 0.5970873786407767 0.3942754859647362\n",
      "train loss per epoch 0.8943624018377299\n",
      "Validation loss per epoch: 1.0044073218714844\n",
      "*************** Starting with epoch:  2 ***********************\n",
      "epoch : 2 Train accuracy and macro_f1: 0.6180722891566265 0.41506852867571736\n",
      "epoch : 2 Validation accuracy, macro_f1: 0.6553398058252428 0.43972327167459885\n",
      "train loss per epoch 0.8326454072240665\n",
      "Validation loss per epoch: 0.8977980671215404\n",
      "*************** Starting with epoch:  3 ***********************\n",
      "epoch : 3 Train accuracy and macro_f1: 0.6493975903614457 0.4531012766102504\n",
      "epoch : 3 Validation accuracy, macro_f1: 0.6699029126213593 0.45034958196841535\n",
      "train loss per epoch 0.790429816702493\n",
      "Validation loss per epoch: 0.8443350897903003\n",
      "*************** Starting with epoch:  4 ***********************\n",
      "epoch : 4 Train accuracy and macro_f1: 0.6819277108433734 0.47855404402048757\n",
      "epoch : 4 Validation accuracy, macro_f1: 0.7038834951456311 0.47471905570377554\n",
      "train loss per epoch 0.7585092451531126\n",
      "Validation loss per epoch: 0.7850968473618036\n",
      "*************** Starting with epoch:  5 ***********************\n",
      "epoch : 5 Train accuracy and macro_f1: 0.6963855421686747 0.5016935303808293\n",
      "epoch : 5 Validation accuracy, macro_f1: 0.7135922330097088 0.4814437984496123\n",
      "train loss per epoch 0.7327166084265598\n",
      "Validation loss per epoch: 0.7550283372040513\n",
      "*************** Starting with epoch:  6 ***********************\n",
      "epoch : 6 Train accuracy and macro_f1: 0.7144578313253012 0.5148269184216897\n",
      "epoch : 6 Validation accuracy, macro_f1: 0.7087378640776699 0.4781149670070826\n",
      "train loss per epoch 0.7111358257105154\n",
      "Validation loss per epoch: 0.7245684330197937\n",
      "*************** Starting with epoch:  7 ***********************\n",
      "epoch : 7 Train accuracy and macro_f1: 0.7265060240963855 0.5464781190284635\n",
      "epoch : 7 Validation accuracy, macro_f1: 0.7281553398058253 0.49140528087896507\n",
      "train loss per epoch 0.692313246619018\n",
      "Validation loss per epoch: 0.706956134014989\n",
      "*************** Starting with epoch:  8 ***********************\n",
      "epoch : 8 Train accuracy and macro_f1: 0.7397590361445783 0.5668017530762629\n",
      "epoch : 8 Validation accuracy, macro_f1: 0.7330097087378641 0.49470106944981324\n",
      "train loss per epoch 0.675903364689335\n",
      "Validation loss per epoch: 0.6952508203866123\n",
      "*************** Starting with epoch:  9 ***********************\n",
      "epoch : 9 Train accuracy and macro_f1: 0.7506024096385542 0.5744528096577238\n",
      "epoch : 9 Validation accuracy, macro_f1: 0.7330097087378641 0.49471091146210694\n",
      "train loss per epoch 0.661118568861857\n",
      "Validation loss per epoch: 0.6912656453917327\n",
      "*************** Starting with epoch:  10 ***********************\n",
      "epoch : 10 Train accuracy and macro_f1: 0.7662650602409639 0.5854704396122455\n",
      "epoch : 10 Validation accuracy, macro_f1: 0.7378640776699029 0.4979394056473165\n",
      "train loss per epoch 0.6477768031775193\n",
      "Validation loss per epoch: 0.680676601456424\n",
      "*************** Starting with epoch:  11 ***********************\n",
      "epoch : 11 Train accuracy and macro_f1: 0.772289156626506 0.5983018609729277\n",
      "epoch : 11 Validation accuracy, macro_f1: 0.7378640776699029 0.4978666537860857\n",
      "train loss per epoch 0.6354866364278389\n",
      "Validation loss per epoch: 0.6720544036966071\n",
      "*************** Starting with epoch:  12 ***********************\n",
      "epoch : 12 Train accuracy and macro_f1: 0.7843373493975904 0.6258553987898304\n",
      "epoch : 12 Validation accuracy, macro_f1: 0.7475728155339806 0.5055685055685055\n",
      "train loss per epoch 0.6242115627953125\n",
      "Validation loss per epoch: 0.6669642385909135\n",
      "*************** Starting with epoch:  13 ***********************\n",
      "epoch : 13 Train accuracy and macro_f1: 0.791566265060241 0.6399783288172006\n",
      "epoch : 13 Validation accuracy, macro_f1: 0.7378640776699029 0.49909385113268606\n",
      "train loss per epoch 0.6136683730256668\n",
      "Validation loss per epoch: 0.6653387666074106\n",
      "*************** Starting with epoch:  14 ***********************\n",
      "epoch : 14 Train accuracy and macro_f1: 0.7963855421686747 0.6521060603027816\n",
      "epoch : 14 Validation accuracy, macro_f1: 0.7378640776699029 0.5003333821209608\n",
      "train loss per epoch 0.6038964511663933\n",
      "Validation loss per epoch: 0.6602828112765423\n",
      "*************** Starting with epoch:  15 ***********************\n",
      "epoch : 15 Train accuracy and macro_f1: 0.8048192771084337 0.6649474049442047\n",
      "epoch : 15 Validation accuracy, macro_f1: 0.7378640776699029 0.5003333821209608\n",
      "train loss per epoch 0.5947333675428575\n",
      "Validation loss per epoch: 0.6598826603403369\n",
      "*************** Starting with epoch:  16 ***********************\n",
      "epoch : 16 Train accuracy and macro_f1: 0.8156626506024096 0.6724595760563462\n",
      "epoch : 16 Validation accuracy, macro_f1: 0.7378640776699029 0.5003333821209608\n",
      "train loss per epoch 0.5859955146565702\n",
      "Validation loss per epoch: 0.6614672550298635\n",
      "*************** Starting with epoch:  17 ***********************\n",
      "epoch : 17 Train accuracy and macro_f1: 0.8180722891566266 0.6838686452482152\n",
      "epoch : 17 Validation accuracy, macro_f1: 0.7475728155339806 0.506833268254588\n",
      "train loss per epoch 0.5776903715702939\n",
      "Validation loss per epoch: 0.6633352753028129\n",
      "*************** Starting with epoch:  18 ***********************\n",
      "epoch : 18 Train accuracy and macro_f1: 0.8253012048192772 0.6872319932998326\n",
      "epoch : 18 Validation accuracy, macro_f1: 0.7427184466019418 0.5034827328060411\n",
      "train loss per epoch 0.5697737809514081\n",
      "Validation loss per epoch: 0.6648219071545647\n",
      "*************** Starting with epoch:  19 ***********************\n",
      "epoch : 19 Train accuracy and macro_f1: 0.8301204819277108 0.688988410729264\n",
      "epoch : 19 Validation accuracy, macro_f1: 0.7427184466019418 0.5034827328060411\n",
      "train loss per epoch 0.562083691166481\n",
      "Validation loss per epoch: 0.6678487930483031\n",
      "*************** Starting with epoch:  20 ***********************\n",
      "epoch : 20 Train accuracy and macro_f1: 0.8325301204819278 0.6906604131277225\n",
      "epoch : 20 Validation accuracy, macro_f1: 0.7378640776699029 0.5015044479330194\n",
      "train loss per epoch 0.5546812892404833\n",
      "Validation loss per epoch: 0.6722439764772804\n",
      "*************** Starting with epoch:  21 ***********************\n",
      "epoch : 21 Train accuracy and macro_f1: 0.8397590361445784 0.7034060276256633\n",
      "epoch : 21 Validation accuracy, macro_f1: 0.7378640776699029 0.5015044479330194\n",
      "train loss per epoch 0.5475365234867502\n",
      "Validation loss per epoch: 0.6752404107630832\n",
      "*************** Starting with epoch:  22 ***********************\n",
      "epoch : 22 Train accuracy and macro_f1: 0.8433734939759037 0.7206966054640231\n",
      "epoch : 22 Validation accuracy, macro_f1: 0.7427184466019418 0.5047560626507995\n",
      "train loss per epoch 0.5406141140390526\n",
      "Validation loss per epoch: 0.6802621501163372\n",
      "*************** Starting with epoch:  23 ***********************\n",
      "epoch : 23 Train accuracy and macro_f1: 0.8457831325301205 0.7150828439626927\n",
      "epoch : 23 Validation accuracy, macro_f1: 0.7427184466019418 0.5047560626507995\n",
      "train loss per epoch 0.5338729693662926\n",
      "Validation loss per epoch: 0.6877750887454135\n",
      "*************** Starting with epoch:  24 ***********************\n",
      "epoch : 24 Train accuracy and macro_f1: 0.8518072289156626 0.7335822217090503\n",
      "epoch : 24 Validation accuracy, macro_f1: 0.7427184466019418 0.5047560626507995\n",
      "train loss per epoch 0.5273146452832047\n",
      "Validation loss per epoch: 0.6891663919374781\n",
      "*************** Starting with epoch:  25 ***********************\n",
      "epoch : 25 Train accuracy and macro_f1: 0.8506024096385543 0.7256997228599662\n",
      "epoch : 25 Validation accuracy, macro_f1: 0.7475728155339806 0.5080019636720667\n",
      "train loss per epoch 0.5209336492933089\n",
      "Validation loss per epoch: 0.6952897038274598\n",
      "*************** Starting with epoch:  26 ***********************\n",
      "epoch : 26 Train accuracy and macro_f1: 0.8542168674698796 0.7371637752705347\n",
      "epoch : 26 Validation accuracy, macro_f1: 0.7572815533980582 0.5144785115303984\n",
      "train loss per epoch 0.5147275453790069\n",
      "Validation loss per epoch: 0.7015257634005501\n",
      "*************** Starting with epoch:  27 ***********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 27 Train accuracy and macro_f1: 0.8542168674698796 0.744091864747864\n",
      "epoch : 27 Validation accuracy, macro_f1: 0.7524271844660194 0.5110898081917918\n",
      "train loss per epoch 0.5086636729461599\n",
      "Validation loss per epoch: 0.7087323746634918\n",
      "*************** Starting with epoch:  28 ***********************\n",
      "epoch : 28 Train accuracy and macro_f1: 0.8578313253012049 0.7465715332412431\n",
      "epoch : 28 Validation accuracy, macro_f1: 0.7475728155339806 0.5078616352201258\n",
      "train loss per epoch 0.5027438987314328\n",
      "Validation loss per epoch: 0.7136560626400327\n",
      "*************** Starting with epoch:  29 ***********************\n",
      "epoch : 29 Train accuracy and macro_f1: 0.8614457831325302 0.7557688967059693\n",
      "epoch : 29 Validation accuracy, macro_f1: 0.7524271844660194 0.5110898081917918\n",
      "train loss per epoch 0.49690996755439093\n",
      "Validation loss per epoch: 0.7231029954928796\n"
     ]
    }
   ],
   "source": [
    "###########.........Start Training...........\n",
    "model = JointDLT()\n",
    "##### Hyperparameter\n",
    "#learning_rate=0.05\n",
    "learning_rate=0.01\n",
    "epochs = 30\n",
    "#opt=\"ADAM\"\n",
    "#opt=\"SGD\" \n",
    "opt=\"ADA\"\n",
    "if(opt==\"SGD\"):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "elif(opt==\"ADA\"):\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=learning_rate, eps=1e-06, weight_decay=0.0001)\n",
    "elif(opt==\"ADAM\"):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "\n",
    "    \n",
    "loss_function = nn.NLLLoss()\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "check_val_acc = 0\n",
    "losses = []\n",
    "per_epoch_train_loss =[]\n",
    "per_epoch_val_loss =[]\n",
    "per_epoch_train_f1 =[]\n",
    "per_epoch_val_f1 = []\n",
    "for epoch in range(epochs): \n",
    "    print('*************** Starting with epoch: ', epoch, '***********************')\n",
    "    for i in range (0,len(train_data)):\n",
    "        #model_des.zero_grad()\n",
    "        #model_loc.zero_grad()\n",
    "        model.zero_grad()\n",
    "        #####Run forward pass.\n",
    "      \n",
    "        prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_twt[i])\n",
    "        \n",
    "        #print(\"prediction_joint :\", torch.argmax(prediction_joint, dim=1)) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        #Compute the loss, gradients, and update the parameters by\n",
    "        #calling optimizer.step()\n",
    "        loss = loss_function(prediction_joint, train_gt[i])\n",
    "        #if (i%200 == 0):\n",
    "            #print (\"loss per example\", loss.item())\n",
    "        losses.append(loss.item())\n",
    "        loss.backward(retain_graph=True)  #backpropagation\n",
    "        optimizer.step()\n",
    "    accuracy, macro_f1 = make_prediction_tr(model, training_data_des, training_data_loc, training_data_twt, train_gt)\n",
    "    print('epoch :', epoch, 'Train accuracy and macro_f1:', accuracy, macro_f1)\n",
    "    per_epoch_train_f1.append(macro_f1)\n",
    "    val_accuracy, val_macro_f1, val_loss = make_prediction_val(model, validation_data_des, validation_data_loc, validation_data_twt, valid_gt)\n",
    "    per_epoch_val_f1.append(val_macro_f1)\n",
    "    print('epoch :', epoch, 'Validation accuracy, macro_f1:', val_accuracy, val_macro_f1)\n",
    "    per_epoch_train_loss.append(np.mean(losses))\n",
    "    print(\"train loss per epoch\", np.mean(losses))\n",
    "    per_epoch_val_loss.append(np.mean(val_loss))\n",
    "    print('Validation loss per epoch:', np.mean(val_loss))\n",
    "    torch.save(model.state_dict(),\"data/DLT_umotivation/joint_DLT_\"+str(epoch)+\".pt\")\n",
    "#     if (check_val_acc < val_macro_f1): #early stopping\n",
    "#         check_val_acc = val_macro_f1\n",
    "#         print (\"Model saved at epoch :\", epoch)\n",
    "#         torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "#         best_epoch = epoch\n",
    "        \n",
    "#print(\"Best model found at epoch : \", best_epoch)        \n",
    "#torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_plots(train_losses, val_losses, train_accs, test_accs):\n",
    "    \"\"\"Plot\n",
    "\n",
    "        Plot two figures: loss vs. epoch and accuracy vs. epoch\n",
    "    \"\"\"\n",
    "    n = len(train_losses)\n",
    "    xs = np.arange(n)\n",
    "\n",
    "    # plot losses\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_losses, '--', linewidth=2, label='train loss')\n",
    "    ax.plot(xs, val_losses, '-', linewidth=2, label='validation loss')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.savefig('loss_DLT_umotivation_2layer_cls.png')\n",
    "\n",
    "    # plot train and test accuracies\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_accs, '--', linewidth=2, label='train')\n",
    "    ax.plot(xs, test_accs, '-', linewidth=2, label='validation')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Macro-avg F1\")\n",
    "    ax.legend(loc='lower right')\n",
    "    plt.savefig('accuracy_DLT_umotivation_2layer_cls.png')\n",
    "    \n",
    "save_plots(per_epoch_train_loss, per_epoch_val_loss, per_epoch_train_f1, per_epoch_val_f1)\n",
    "# print(per_epoch_train_loss)\n",
    "# print(per_epoch_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction(training_data_des, training_data_loc, training_data_twt, ground_truths):\n",
    "    for epoch in range(0,30):\n",
    "        model = JointDLT()\n",
    "        model.load_state_dict(torch.load(\"data/DLT_umotivation/joint_DLT_\"+str(epoch)+\".pt\")) #best #Testing accuracy, macro_f1: 0.7862595419847328 0.7560951140518181\n",
    "        predictions =[]\n",
    "        for i in range (0,len(training_data_des)):\n",
    "            prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_twt[i])\n",
    "            pred = torch.argmax(prediction_joint, dim=1)\n",
    "            predictions.append(pred.item())\n",
    "        #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "        accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_des)\n",
    "        macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "        print('epoch :', epoch, 'Testing accuracy, macro_f1:', accuracy, macro_f1)\n",
    "        #return accuracy, macro_f1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "########.....Load Test data.......\n",
    "with open(\"data/test.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "test_data = data[:] \n",
    "#print(test_data, len(test_data)) #262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no location for user:  vaibhavatttc\n"
     ]
    }
   ],
   "source": [
    "#####prepare testing data for neural net #########\n",
    "testing_data_des, testing_data_loc, testing_data_twt =  nn_input(test_data,df)\n",
    "#testing_data_net =  nn_input_network(test_data,df)\n",
    "test_gt = find_groundtruth(test_data, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########........Calculate Validation Accuracy.......\n",
    "# test_accuracy, test_macro_f1 = make_prediction(testing_data_des, testing_data_loc, testing_data_twt, test_gt)\n",
    "# print('Testing accuracy, macro_f1:', test_accuracy, test_macro_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 Testing accuracy, macro_f1: 0.6641221374045801 0.4203238084696883\n",
      "epoch : 1 Testing accuracy, macro_f1: 0.7099236641221374 0.46755778334725706\n",
      "epoch : 2 Testing accuracy, macro_f1: 0.7404580152671756 0.4947377971330067\n",
      "epoch : 3 Testing accuracy, macro_f1: 0.7595419847328244 0.5109405699507968\n",
      "epoch : 4 Testing accuracy, macro_f1: 0.7709923664122137 0.5204054414510536\n",
      "epoch : 5 Testing accuracy, macro_f1: 0.7709923664122137 0.5209743793973184\n",
      "epoch : 6 Testing accuracy, macro_f1: 0.7786259541984732 0.5266162219567238\n",
      "epoch : 7 Testing accuracy, macro_f1: 0.7900763358778626 0.5362416364402282\n",
      "epoch : 8 Testing accuracy, macro_f1: 0.7862595419847328 0.5336740041928721\n",
      "epoch : 9 Testing accuracy, macro_f1: 0.7862595419847328 0.5336740041928721\n",
      "epoch : 10 Testing accuracy, macro_f1: 0.7862595419847328 0.5336740041928721\n",
      "epoch : 11 Testing accuracy, macro_f1: 0.7862595419847328 0.5336740041928721\n",
      "epoch : 12 Testing accuracy, macro_f1: 0.7900763358778626 0.5366698811722593\n",
      "epoch : 13 Testing accuracy, macro_f1: 0.7862595419847328 0.5336740041928721\n",
      "epoch : 14 Testing accuracy, macro_f1: 0.7862595419847328 0.5336740041928721\n",
      "epoch : 15 Testing accuracy, macro_f1: 0.7786259541984732 0.5285571360215755\n",
      "epoch : 16 Testing accuracy, macro_f1: 0.7786259541984732 0.5285571360215755\n",
      "epoch : 17 Testing accuracy, macro_f1: 0.7786259541984732 0.5285571360215755\n",
      "epoch : 18 Testing accuracy, macro_f1: 0.7824427480916031 0.5738722522227676\n",
      "epoch : 19 Testing accuracy, macro_f1: 0.7824427480916031 0.5738722522227676\n",
      "epoch : 20 Testing accuracy, macro_f1: 0.7862595419847328 0.5749672319161138\n",
      "epoch : 21 Testing accuracy, macro_f1: 0.7862595419847328 0.5749672319161138\n",
      "epoch : 22 Testing accuracy, macro_f1: 0.7900763358778626 0.5775288219324161\n",
      "epoch : 23 Testing accuracy, macro_f1: 0.7900763358778626 0.5775288219324161\n",
      "epoch : 24 Testing accuracy, macro_f1: 0.7900763358778626 0.5771288150320408\n",
      "epoch : 25 Testing accuracy, macro_f1: 0.7938931297709924 0.5800977649845777\n",
      "epoch : 26 Testing accuracy, macro_f1: 0.7900763358778626 0.5775541125541125\n",
      "epoch : 27 Testing accuracy, macro_f1: 0.7900763358778626 0.5775541125541125\n",
      "epoch : 28 Testing accuracy, macro_f1: 0.7900763358778626 0.5775541125541125\n",
      "epoch : 29 Testing accuracy, macro_f1: 0.7938931297709924 0.5800977649845777\n"
     ]
    }
   ],
   "source": [
    "make_prediction(testing_data_des, testing_data_loc, testing_data_twt, test_gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
