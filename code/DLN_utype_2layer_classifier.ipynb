{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x128b375f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "import spacy  # For preprocessing\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p  #pip install tweet-preprocessor\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation as punc\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "#from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.models as gsm\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import regex\n",
    "import emoji\n",
    "# Internal dependencies\n",
    "import word_emoji2vec as we2v\n",
    "#from word_emoji2vec import Word_Emoji2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed #python -m spacy download en\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## load embeddings #######\n",
    "loc_emb = torch.load('data/locationEmbeddings.pt') \n",
    "des_emb = torch.load('data/descriptionEmbeddings.pt') \n",
    "#twt_emb = torch.load('data/tweetsEmbeddings.pt') \n",
    "\n",
    "#load network embedding\n",
    "net_emb = gsm.KeyedVectors.load_word2vec_format('data/userNetworkEmd.emd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.keyedvectors.Word2VecKeyedVectors'>\n"
     ]
    }
   ],
   "source": [
    "#user = net_emb ['000mrs000']\n",
    "#print(user)\n",
    "print(type(net_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load 1300 user location, description, yoga tweets, utype, umotivation\n",
    "df = pd.read_csv(\"data/yoga_user_name_loc_des_mergetweets_yoga_1300_lb.csv\") \n",
    "#print (df) #[1308 rows x 7 columns] name, location, description, text, utype, umotivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load train users and split into train and validation #######\n",
    "with open(\"data/train.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "random.seed(1)\n",
    "random.shuffle(data)\n",
    "\n",
    "train_data = data[:830] #80% train  \n",
    "#print(train_data, len(train_data)) #830\n",
    "valid_data = data[830:] #20% validation\n",
    "#print(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create BiLSTMAttention Model for Description\n",
    "class BiLSTMDesAtt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiLSTMDesAtt, self).__init__() \n",
    "        self.lstm = nn.LSTM(300, 150//2 , num_layers=1, bidirectional=True ) #BiLSTM with attention \n",
    "        #self.lstm = nn.LSTM(300, 150 , num_layers=1, bidirectional=False) #LSTM with attention\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        self.hidden = self.init_hidden() # <- change here \n",
    "        self.attn_fc = torch.nn.Linear(300, 1) #attention layer\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        #(2*self.num_layers, batch_size, self.hidden_dim // 2)\n",
    "        return (torch.zeros(2 * 1, 1, 150//2), torch.zeros(2 * 1, 1, 150//2)) # <- change here: first dim of hidden needs to be doubled\n",
    "        #return (torch.zeros(1 * 1, 1, 150), torch.zeros(1 * 1, 1, 150))#LSTM with attention\n",
    "    def attention(self, rnn_out, state):\n",
    "        #print(\"rnn_out\", rnn_out.size()) #torch.Size([13, 1, 150])\n",
    "        #rnn_out = rnn_out.squeeze(0).unsqueeze(1) \n",
    "        #rnn_out = rnn_out.permute(2,0,1) \n",
    "        rnn_out = rnn_out.permute(1,0,2) \n",
    "        #print(\"permute rnn_out\", rnn_out.size()) #torch.Size([150, 13, 1])\n",
    "        #print(\"state\", state.size()) #torch.Size([2, 1, 75])\n",
    "        merged_state = torch.cat([s for s in state],1)\n",
    "        #print(\"merged_state\", merged_state.size()) #torch.Size([1, 150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).size()) #torch.Size([150])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).size()) #torch.Size([150, 1])\n",
    "        #print(\"merged_state2 :\", merged_state.squeeze(0).unsqueeze(1).unsqueeze(2).size()) # torch.Size([150, 1, 1])\n",
    "        #merged_state = merged_state.squeeze(0).unsqueeze(2)\n",
    "        merged_state = merged_state.squeeze(0).unsqueeze(1).unsqueeze(2)\n",
    "        #print(\"merged_state2 :\", merged_state.size()) #torch.Size([150, 1, 1])\n",
    "        merged_state = merged_state.permute(1,0,2)\n",
    "        # (batch, seq_len, cell_size) * (batch, cell_size, 1) = (batch, seq_len, 1)\n",
    "        weights = torch.bmm(rnn_out, merged_state)\n",
    "        #print(\"weights\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        #weights = torch.nn.functional.softmax(weights.squeeze(2)).unsqueeze(2)\n",
    "        weights = F.log_softmax(weights.squeeze(2),dim = 1).unsqueeze(2)\n",
    "         #F.log_softmax(x, dim = 1)\n",
    "        #print(\"weights2 :\", weights.size()) #torch.Size([150, 13, 1])\n",
    "        # (batch, cell_size, seq_len) * (batch, seq_len, 1) = (batch, cell_size, 1)\n",
    "        return torch.bmm(torch.transpose(rnn_out, 1, 2), weights).squeeze(2)\n",
    "    # end method attention\n",
    "\n",
    "    def forward(self, X):\n",
    "        #print(X.size()) # torch.Size([13, 300])\n",
    "        #print('resize', x.view(len(x),1,-1), x.view(len(x),1,-1).size()) #torch.Size([13, 1, 300])\n",
    "        lstm_out, hidden = self.lstm(X.view(len(X),1, -1))\n",
    "        #print('lstm_out', lstm_out, lstm_out.size()) # torch.Size([13, 1, 150])\n",
    "        #print('hidden[0] = h_n', hidden[0], hidden[0].size()) # torch.Size([2, 1, 75])\n",
    "        #print('hidden[1] = c_n', hidden[1], hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        h_n, c_n = hidden\n",
    "        #print('h_n', h_n, h_n.size()) # torch.Size([2, 1, 75])\n",
    "        #print('c_n', c_n, hidden[1].size()) # torch.Size([2, 1, 75])\n",
    "        attn_out = self.attention(lstm_out, h_n)\n",
    "        #print(\"attn_out\", attn_out.size()) #torch.Size([150, 1])\n",
    "        #logits = self.fc2(attn_out)\n",
    "        #logits = self.fc2(attn_out.permute(1,0))\n",
    "        #print(\"logits\", logits, logits.size())\n",
    "        #return logits \n",
    "        return attn_out\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create LSTM Model for Location #############\n",
    "class LSTMLoc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMLoc, self).__init__()\n",
    "        self.lstm = nn.LSTM(300, 150, num_layers=1)\n",
    "        self.fc2 = nn.Linear(150, 50) \n",
    "        self.hidden = self.init_hidden() # <- change here \n",
    "\n",
    "    def init_hidden(self):\n",
    "        #(2*self.num_layers, batch_size, self.hidden_dim // 2)# <- change here: first dim of hidden needs to be doubled\n",
    "        return (torch.zeros(1, 1, 150), torch.zeros(1, 1, 150)) \n",
    "    def forward(self, x):\n",
    "        #x=embeds.permute(1,0,2)\n",
    "        #print('resize', x.view(len(x),1,-1), x.view(len(x),1,-1).size()) #torch.Size([13, 1, 300])\n",
    "        #lstm_out, self.hidden = self.lstm(x.view(len(x),1, -1), self.hidden)\n",
    "        lstm_out, _ = self.lstm(x.view(len(x),1, -1))\n",
    "        #lstm_out, _ = self.lstm(x.view(len(x),1,-1)) \n",
    "        #print('lstm_out', lstm_out, lstm_out.size()) # torch.Size([13, 1, 150])\n",
    "        #print('self.hidden[0]', self.hidden[0], self.hidden[0].size()) # torch.Size([1, 1, 150])\n",
    "        #print(\"lstm_out[-1]\", lstm_out[-1], lstm_out[-1].size())  # torch.Size([1, 150])\n",
    "        #x = self.fc2(lstm_out[-1])  \n",
    "        #out = F.log_softmax(x, dim = 1)\n",
    "        #return out\n",
    "        #return x\n",
    "        return lstm_out[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create Model \n",
    "class NetworkMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkMLP, self).__init__() \n",
    "        self.fc1 = nn.Linear(300, 150)\n",
    "        \n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        \n",
    "        #self.fc1 = nn.Linear(300, 50)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #print(X.size()) # torch.Size([300])\n",
    "        #print('resize', X.view(1,len(X)).size()) #resize torch.Size([1, 300])\n",
    "        z1 = self.fc1(X.view(1,len(X)))\n",
    "        #print('z1', z1, z1.size()) # torch.Size([1, 150])\n",
    "        h1 = F.relu(z1) \n",
    "        #logits = self.fc2(h1) #without attention\n",
    "        #print(\"logits\", logits, logits.size()) #torch.Size([1, 3])\n",
    "        #return logits \n",
    "        return h1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointDLN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JointDLN, self).__init__()\n",
    "        self.model_des = BiLSTMDesAtt()\n",
    "        self.model_loc = LSTMLoc()\n",
    "        self.model_net = NetworkMLP()\n",
    "        #self.fc = nn.Linear(150, 3)  #3*50 = 150\n",
    "        self.fc1 = nn.Linear(450, 200) #3*150 = 450\n",
    "        self.fc2 = nn.Linear(200, 3) #epoch 3rd\n",
    "#        self.fc1 = nn.Linear(450, 3) #epoch 4th,5,6\n",
    "    def forward(self, x_d, x_l, x_n): \n",
    "        prediction_des = self.model_des(x_d)\n",
    "        #print(prediction_des, prediction_des.size()) #torch.Size([1, 3])\n",
    "        prediction_loc = self.model_loc(x_l)\n",
    "        #print(prediction_loc, prediction_loc.size()) #torch.Size([1, 3])\n",
    "        prediction_net = self.model_net(x_n)\n",
    "        #print(prediction_net, prediction_net.size()) #torch.Size([1, 3])\n",
    "        concat_pred = torch.cat((prediction_des, prediction_loc, prediction_net), 1) #concat with dim= 1\n",
    "        #print(concat_pred, concat_pred.size()) #torch.Size([1, 6])\n",
    "        out = self.fc1(concat_pred)\n",
    "        out = self.fc2(F.relu(out))\n",
    "        out = F.log_softmax(out, dim = 1)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare data for neural net input #########\n",
    "def nn_input(train_data,df):\n",
    "    #ground_truths = []\n",
    "    training_data_des =[]\n",
    "    training_data_loc=[]\n",
    "    for i in range (0, len(train_data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (train_data[i] == df.name[j]):\n",
    "                if (not des_emb[train_data[i]]) and (not loc_emb[train_data[i]]):\n",
    "                    print ('no description and location for user: ', train_data[i])\n",
    "                    training_data_des.append(torch.zeros(1, 300))\n",
    "                    training_data_loc.append(torch.zeros(1, 300))\n",
    "                    break\n",
    "                \n",
    "                elif (des_emb[train_data[i]]) and (not loc_emb[train_data[i]]): \n",
    "                    print ('no location for user: ', train_data[i])\n",
    "                    sent_tensor_des = torch.stack(des_emb[train_data[i]],dim = 1)\n",
    "                    training_data_des.append(sent_tensor_des[-1])\n",
    "                    training_data_loc.append(torch.zeros(1, 300))\n",
    "                    break\n",
    "                    \n",
    "                elif (not des_emb[train_data[i]]) and (loc_emb[train_data[i]]): \n",
    "                    print ('no description for user: ', train_data[i])\n",
    "                    training_data_des.append(torch.zeros(1, 300))\n",
    "                    sent_tensor_loc = torch.stack(loc_emb[train_data[i]],dim = 1)\n",
    "                    training_data_loc.append(sent_tensor_loc[-1])\n",
    "                    break    \n",
    "               \n",
    "                else:\n",
    "                    sent_tensor_des = torch.stack(des_emb[train_data[i]],dim = 1)\n",
    "                    training_data_des.append(sent_tensor_des[-1])\n",
    "                    sent_tensor_loc = torch.stack(loc_emb[train_data[i]],dim = 1)\n",
    "                    training_data_loc.append(sent_tensor_loc[-1])\n",
    "                    break\n",
    "    return training_data_des, training_data_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare data for neural net #########\n",
    "def nn_input_network(train_data,df):\n",
    "    training_data =[]\n",
    "    for i in range (0, len(train_data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (train_data[i] == df.name[j]):\n",
    "                #print(train_data[i]) #print username\n",
    "                utype =  [int(df.utype[j])]\n",
    "                umotivation = [int(float(df.umotivation[j]))]\n",
    "                #print (\"net_emb[train_data[i]] : \", net_emb[train_data[i]], type(net_emb[train_data[i]]), torch.Tensor(net_emb[train_data[i]]), type(torch.Tensor(net_emb[train_data[i]])))\n",
    "                #count = 0\n",
    "                if(train_data[i] not in net_emb ):\n",
    "                    net_emb[train_data[i]] = np.zeros(300) #For users not appearing in the mention network, we set their network embedding vectors as 0.\n",
    "                    #count = count + 1\n",
    "                #print(count)\n",
    "                #print(net_emb[train_data[i]]) #ok\n",
    "                ####.....convert ndarray to torch.tensor........\n",
    "                net_emb_tensor = torch.Tensor(net_emb[train_data[i]])\n",
    "                #print(net_emb_tensor) #ok\n",
    "                training_data.append(net_emb_tensor)\n",
    "                break\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Ground Truth #########\n",
    "def find_groundtruth(data, df):\n",
    "    ground_truths = []\n",
    "    for i in range (0, len(data)):\n",
    "    #for i in range (0, 10):\n",
    "        for j in range (0,df.shape[0]):\n",
    "            if (data[i] == df.name[j]):\n",
    "                #print(data[i]) #print username\n",
    "                utype =  [int(df.utype[j])]\n",
    "                umotivation = [int(float(df.umotivation[j]))]\n",
    "                target_type = torch.tensor(utype, dtype=torch.long) #for user type\n",
    "                #target_type = torch.tensor(umotivation, dtype=torch.long) #for user motivation\n",
    "                ground_truths.append(target_type)\n",
    "    return ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_tr(model, training_data_des, training_data_loc, training_data_net, ground_truths):\n",
    "    predictions =[]\n",
    "    for i in range (0,len(training_data_des)):\n",
    "        prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_net[i])\n",
    "        \n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_des)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    return accuracy, macro_f1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction_val(model, training_data_des, training_data_loc, training_data_net, ground_truths):\n",
    "    predictions =[]\n",
    "    val_losses = []\n",
    "    loss_function = nn.NLLLoss()\n",
    "    for i in range (0,len(training_data_des)):\n",
    "        prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_net[i])\n",
    "        val_loss = loss_function(prediction_joint, ground_truths[i])\n",
    "        val_losses.append(val_loss.item())\n",
    "        #prediction = model(data[i])\n",
    "        pred = torch.argmax(prediction_joint, dim=1)\n",
    "        #print(\"pred :\", pred) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        predictions.append(pred.item())\n",
    "    #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_des)\n",
    "    macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "    \n",
    "    #print(type(predictions), type(ground_truths))\n",
    "    #print(\"predictions\", predictions)\n",
    "    #print(\"ground_truths\", ground_truths)\n",
    "    \n",
    "    return accuracy, macro_f1, val_losses\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no description for user:  bchi49\n",
      "no location for user:  Christoph_Tran\n",
      "no description for user:  viecestlavie\n",
      "no description for user:  crystalization_\n",
      "no location for user:  yogitimesonline\n",
      "no description for user:  mimmosamami\n",
      "no description for user:  wenmarbyoga\n",
      "no location for user:  cipherEquality\n",
      "no description for user:  YogaLifeLine\n",
      "no location for user:  thewaywecame\n"
     ]
    }
   ],
   "source": [
    "##########......prepare training and validation data\n",
    "# ground truth training\n",
    "train_gt = find_groundtruth(train_data, df)\n",
    "#####prepare training data for neural net #########\n",
    "training_data_net =  nn_input_network(train_data,df)\n",
    "#print(training_data_net, len(training_data_net)) #ok\n",
    "training_data_des, training_data_loc =  nn_input(train_data,df)\n",
    "\n",
    "# ground truth validation\n",
    "valid_gt = find_groundtruth(valid_data, df)\n",
    "#####prepare validation data for neural net #########\n",
    "validation_data_net =  nn_input_network(valid_data,df)\n",
    "validation_data_des, validation_data_loc =  nn_input(valid_data,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Starting with epoch:  0 ***********************\n",
      "epoch : 0 Train accuracy and macro_f1: 0.5783132530120482 0.44191857286778374\n",
      "epoch : 0 Validation accuracy, macro_f1: 0.587378640776699 0.44464940867818564\n",
      "train loss per epoch 1.0282730565731784\n",
      "Validation loss per epoch: 0.946692159164299\n",
      "*************** Starting with epoch:  1 ***********************\n",
      "epoch : 1 Train accuracy and macro_f1: 0.6421686746987951 0.560207734560579\n",
      "epoch : 1 Validation accuracy, macro_f1: 0.6699029126213593 0.5812045679647498\n",
      "train loss per epoch 0.9815850141536758\n",
      "Validation loss per epoch: 0.8573384270505998\n",
      "*************** Starting with epoch:  2 ***********************\n",
      "epoch : 2 Train accuracy and macro_f1: 0.6783132530120481 0.638746283215184\n",
      "epoch : 2 Validation accuracy, macro_f1: 0.6893203883495146 0.6302788227258362\n",
      "train loss per epoch 0.9343015796448811\n",
      "Validation loss per epoch: 0.7631088269567027\n",
      "*************** Starting with epoch:  3 ***********************\n",
      "epoch : 3 Train accuracy and macro_f1: 0.7024096385542169 0.675265815750364\n",
      "epoch : 3 Validation accuracy, macro_f1: 0.7038834951456311 0.6542489541252301\n",
      "train loss per epoch 0.887212389151016\n",
      "Validation loss per epoch: 0.6800661118863855\n",
      "*************** Starting with epoch:  4 ***********************\n",
      "epoch : 4 Train accuracy and macro_f1: 0.736144578313253 0.7206839849079606\n",
      "epoch : 4 Validation accuracy, macro_f1: 0.7135922330097088 0.6716290726817044\n",
      "train loss per epoch 0.8439508563280106\n",
      "Validation loss per epoch: 0.6223527800689623\n",
      "*************** Starting with epoch:  5 ***********************\n",
      "epoch : 5 Train accuracy and macro_f1: 0.755421686746988 0.7409481676665556\n",
      "epoch : 5 Validation accuracy, macro_f1: 0.7330097087378641 0.6997281417170921\n",
      "train loss per epoch 0.8064917964928121\n",
      "Validation loss per epoch: 0.5886978368157322\n",
      "*************** Starting with epoch:  6 ***********************\n",
      "epoch : 6 Train accuracy and macro_f1: 0.7686746987951807 0.7536788479771065\n",
      "epoch : 6 Validation accuracy, macro_f1: 0.7378640776699029 0.7090608958436827\n",
      "train loss per epoch 0.7746922967253371\n",
      "Validation loss per epoch: 0.5694373831586931\n",
      "*************** Starting with epoch:  7 ***********************\n",
      "epoch : 7 Train accuracy and macro_f1: 0.7831325301204819 0.7698351852359676\n",
      "epoch : 7 Validation accuracy, macro_f1: 0.7427184466019418 0.7164859903469981\n",
      "train loss per epoch 0.7476330914097019\n",
      "Validation loss per epoch: 0.5595080913270561\n",
      "*************** Starting with epoch:  8 ***********************\n",
      "epoch : 8 Train accuracy and macro_f1: 0.7927710843373494 0.782222132004009\n",
      "epoch : 8 Validation accuracy, macro_f1: 0.7427184466019418 0.7128405401124575\n",
      "train loss per epoch 0.7243946596840459\n",
      "Validation loss per epoch: 0.555139463214041\n",
      "*************** Starting with epoch:  9 ***********************\n",
      "epoch : 9 Train accuracy and macro_f1: 0.7951807228915663 0.7865117157268058\n",
      "epoch : 9 Validation accuracy, macro_f1: 0.7475728155339806 0.7213595903357733\n",
      "train loss per epoch 0.7042431151651475\n",
      "Validation loss per epoch: 0.5549592494385914\n",
      "*************** Starting with epoch:  10 ***********************\n",
      "epoch : 10 Train accuracy and macro_f1: 0.7987951807228916 0.7903582822538477\n",
      "epoch : 10 Validation accuracy, macro_f1: 0.7572815533980582 0.7295461066161705\n",
      "train loss per epoch 0.6865961788093665\n",
      "Validation loss per epoch: 0.5570055004751798\n",
      "*************** Starting with epoch:  11 ***********************\n",
      "epoch : 11 Train accuracy and macro_f1: 0.8036144578313253 0.7954484763554904\n",
      "epoch : 11 Validation accuracy, macro_f1: 0.7572815533980582 0.7295461066161705\n",
      "train loss per epoch 0.6709822842245361\n",
      "Validation loss per epoch: 0.560333849012273\n",
      "*************** Starting with epoch:  12 ***********************\n",
      "epoch : 12 Train accuracy and macro_f1: 0.8096385542168675 0.8018773098796733\n",
      "epoch : 12 Validation accuracy, macro_f1: 0.7572815533980582 0.7295461066161705\n",
      "train loss per epoch 0.6570296244227963\n",
      "Validation loss per epoch: 0.5646752441681705\n",
      "*************** Starting with epoch:  13 ***********************\n",
      "epoch : 13 Train accuracy and macro_f1: 0.8144578313253013 0.8072075612391854\n",
      "epoch : 13 Validation accuracy, macro_f1: 0.7524271844660194 0.7244377833510803\n",
      "train loss per epoch 0.6444389622511019\n",
      "Validation loss per epoch: 0.5695819591434257\n",
      "*************** Starting with epoch:  14 ***********************\n",
      "epoch : 14 Train accuracy and macro_f1: 0.8168674698795181 0.8090724968167744\n",
      "epoch : 14 Validation accuracy, macro_f1: 0.7572815533980582 0.7327821132168958\n",
      "train loss per epoch 0.6329708428172223\n",
      "Validation loss per epoch: 0.5747888238684645\n",
      "*************** Starting with epoch:  15 ***********************\n",
      "epoch : 15 Train accuracy and macro_f1: 0.8204819277108434 0.8141306312508038\n",
      "epoch : 15 Validation accuracy, macro_f1: 0.7718446601941747 0.7497836546223643\n",
      "train loss per epoch 0.6224430332431592\n",
      "Validation loss per epoch: 0.5800768252715324\n",
      "*************** Starting with epoch:  16 ***********************\n",
      "epoch : 16 Train accuracy and macro_f1: 0.8253012048192772 0.8182876194374459\n",
      "epoch : 16 Validation accuracy, macro_f1: 0.7766990291262136 0.7573501252025335\n",
      "train loss per epoch 0.6127062522080838\n",
      "Validation loss per epoch: 0.5856364308630378\n",
      "*************** Starting with epoch:  17 ***********************\n",
      "epoch : 17 Train accuracy and macro_f1: 0.8301204819277108 0.8233931881592894\n",
      "epoch : 17 Validation accuracy, macro_f1: 0.7766990291262136 0.7573501252025335\n",
      "train loss per epoch 0.6036373260010837\n",
      "Validation loss per epoch: 0.5912690726877416\n",
      "*************** Starting with epoch:  18 ***********************\n",
      "epoch : 18 Train accuracy and macro_f1: 0.8313253012048193 0.8246672729882656\n",
      "epoch : 18 Validation accuracy, macro_f1: 0.7815533980582524 0.7614736244873231\n",
      "train loss per epoch 0.5951420101358986\n",
      "Validation loss per epoch: 0.5971048571241712\n",
      "*************** Starting with epoch:  19 ***********************\n",
      "epoch : 19 Train accuracy and macro_f1: 0.8397590361445784 0.8339657177722272\n",
      "epoch : 19 Validation accuracy, macro_f1: 0.7815533980582524 0.7614736244873231\n",
      "train loss per epoch 0.5871362564057471\n",
      "Validation loss per epoch: 0.6033564687353893\n",
      "*************** Starting with epoch:  20 ***********************\n",
      "epoch : 20 Train accuracy and macro_f1: 0.8397590361445784 0.8339657177722272\n",
      "epoch : 20 Validation accuracy, macro_f1: 0.7815533980582524 0.7614736244873231\n",
      "train loss per epoch 0.5795586178375262\n",
      "Validation loss per epoch: 0.6096844221781759\n",
      "*************** Starting with epoch:  21 ***********************\n",
      "epoch : 21 Train accuracy and macro_f1: 0.844578313253012 0.839403865106661\n",
      "epoch : 21 Validation accuracy, macro_f1: 0.7864077669902912 0.7655973667514827\n",
      "train loss per epoch 0.5723555257978471\n",
      "Validation loss per epoch: 0.6161736905285455\n",
      "*************** Starting with epoch:  22 ***********************\n",
      "epoch : 22 Train accuracy and macro_f1: 0.8493975903614458 0.8445323499109058\n",
      "epoch : 22 Validation accuracy, macro_f1: 0.7864077669902912 0.7655973667514827\n",
      "train loss per epoch 0.5654849012432578\n",
      "Validation loss per epoch: 0.622782122524618\n",
      "*************** Starting with epoch:  23 ***********************\n",
      "epoch : 23 Train accuracy and macro_f1: 0.8506024096385543 0.845581667200662\n",
      "epoch : 23 Validation accuracy, macro_f1: 0.7864077669902912 0.7655973667514827\n",
      "train loss per epoch 0.5589122468328859\n",
      "Validation loss per epoch: 0.6294584278632136\n",
      "*************** Starting with epoch:  24 ***********************\n",
      "epoch : 24 Train accuracy and macro_f1: 0.8518072289156626 0.8470815144320801\n",
      "epoch : 24 Validation accuracy, macro_f1: 0.7864077669902912 0.7655973667514827\n",
      "train loss per epoch 0.5526027107080781\n",
      "Validation loss per epoch: 0.636156130618262\n",
      "*************** Starting with epoch:  25 ***********************\n",
      "epoch : 25 Train accuracy and macro_f1: 0.8554216867469879 0.8513370073638574\n",
      "epoch : 25 Validation accuracy, macro_f1: 0.7815533980582524 0.7614736244873231\n",
      "train loss per epoch 0.5465299744038145\n",
      "Validation loss per epoch: 0.6424547629159632\n",
      "*************** Starting with epoch:  26 ***********************\n",
      "epoch : 26 Train accuracy and macro_f1: 0.8578313253012049 0.8538672526343496\n",
      "epoch : 26 Validation accuracy, macro_f1: 0.7815533980582524 0.7614736244873231\n",
      "train loss per epoch 0.5406696958195573\n",
      "Validation loss per epoch: 0.6494855120488741\n",
      "*************** Starting with epoch:  27 ***********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 27 Train accuracy and macro_f1: 0.8590361445783132 0.8551553493513856\n",
      "epoch : 27 Validation accuracy, macro_f1: 0.7815533980582524 0.7614736244873231\n",
      "train loss per epoch 0.5350020254720098\n",
      "Validation loss per epoch: 0.6566657188881948\n",
      "*************** Starting with epoch:  28 ***********************\n",
      "epoch : 28 Train accuracy and macro_f1: 0.8602409638554217 0.8564461055764613\n",
      "epoch : 28 Validation accuracy, macro_f1: 0.7815533980582524 0.7614736244873231\n",
      "train loss per epoch 0.5295125583320621\n",
      "Validation loss per epoch: 0.6640085991725181\n",
      "*************** Starting with epoch:  29 ***********************\n",
      "epoch : 29 Train accuracy and macro_f1: 0.8614457831325302 0.8579216967354584\n",
      "epoch : 29 Validation accuracy, macro_f1: 0.7766990291262136 0.7585470085470085\n",
      "train loss per epoch 0.5241860454730002\n",
      "Validation loss per epoch: 0.6718274955321284\n"
     ]
    }
   ],
   "source": [
    "###########.........Start Training...........\n",
    "model = JointDLN()\n",
    "##### Hyperparameter\n",
    "#learning_rate=0.005\n",
    "learning_rate=0.01\n",
    "epochs = 30\n",
    "#opt=\"ADAM\"\n",
    "#opt=\"SGD\" \n",
    "opt=\"ADA\"\n",
    "if(opt==\"SGD\"):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "elif(opt==\"ADA\"):\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=learning_rate, eps=1e-06, weight_decay=0.0001)\n",
    "elif(opt==\"ADAM\"):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "\n",
    "    \n",
    "loss_function = nn.NLLLoss()\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "check_val_acc = 0\n",
    "losses = []\n",
    "per_epoch_train_loss =[]\n",
    "per_epoch_val_loss =[]\n",
    "per_epoch_train_f1 =[]\n",
    "per_epoch_val_f1 = []\n",
    "for epoch in range(epochs): \n",
    "    print('*************** Starting with epoch: ', epoch, '***********************')\n",
    "    for i in range (0,len(train_data)):\n",
    "        #model_des.zero_grad()\n",
    "        #model_loc.zero_grad()\n",
    "        model.zero_grad()\n",
    "        #####Run forward pass.\n",
    "      \n",
    "        prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_net[i])\n",
    "        \n",
    "        #print(\"prediction_joint :\", torch.argmax(prediction_joint, dim=1)) #ok\n",
    "        #print(\"ground_truths :\", ground_truths[i]) #ok\n",
    "        #Compute the loss, gradients, and update the parameters by\n",
    "        #calling optimizer.step()\n",
    "        loss = loss_function(prediction_joint, train_gt[i])\n",
    "        #if (i%200 == 0):\n",
    "            #print (\"loss per example\", loss.item())\n",
    "        losses.append(loss.item())\n",
    "        loss.backward(retain_graph=True)  #backpropagation\n",
    "        optimizer.step()\n",
    "    accuracy, macro_f1 = make_prediction_tr(model, training_data_des, training_data_loc, training_data_net, train_gt)\n",
    "    print('epoch :', epoch, 'Train accuracy and macro_f1:', accuracy, macro_f1)\n",
    "    per_epoch_train_f1.append(macro_f1)\n",
    "    val_accuracy, val_macro_f1, val_loss = make_prediction_val(model, validation_data_des, validation_data_loc, validation_data_net, valid_gt)\n",
    "    per_epoch_val_f1.append(val_macro_f1)\n",
    "    print('epoch :', epoch, 'Validation accuracy, macro_f1:', val_accuracy, val_macro_f1)\n",
    "    per_epoch_train_loss.append(np.mean(losses))\n",
    "    print(\"train loss per epoch\", np.mean(losses))\n",
    "    per_epoch_val_loss.append(np.mean(val_loss))\n",
    "    print('Validation loss per epoch:', np.mean(val_loss))\n",
    "    \n",
    "    torch.save(model.state_dict(),\"data/DLN_utype_2layer/joint_DLN_\"+str(epoch)+\".pt\")\n",
    "#     if (check_val_acc < val_macro_f1): #early stopping\n",
    "#         check_val_acc = val_macro_f1\n",
    "#         print (\"Model saved at epoch :\", epoch)\n",
    "#         torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "#         best_epoch = epoch\n",
    "        \n",
    "#print(\"Best model found at epoch : \", best_epoch)        \n",
    "#torch.save(model.state_dict(),\"data/joint_DLT.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_plots(train_losses, val_losses, train_accs, test_accs):\n",
    "    \"\"\"Plot\n",
    "\n",
    "        Plot two figures: loss vs. epoch and accuracy vs. epoch\n",
    "    \"\"\"\n",
    "    n = len(train_losses)\n",
    "    xs = np.arange(n)\n",
    "\n",
    "    # plot losses\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_losses, '--', linewidth=2, label='train loss')\n",
    "    ax.plot(xs, val_losses, '-', linewidth=2, label='validation loss')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.savefig('loss_DLN_utype_try.png')\n",
    "\n",
    "    # plot train and test accuracies\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_accs, '--', linewidth=2, label='train')\n",
    "    ax.plot(xs, test_accs, '-', linewidth=2, label='validation')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Macro-avg F1\")\n",
    "    ax.legend(loc='lower right')\n",
    "    plt.savefig('accuracy_DLN_utype_try.png')\n",
    "    \n",
    "save_plots(per_epoch_train_loss, per_epoch_val_loss, per_epoch_train_f1, per_epoch_val_f1)\n",
    "# print(per_epoch_train_loss)\n",
    "# print(per_epoch_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###########........Load the trained model and make prediction and calculate accuracy.....\n",
    "def make_prediction(training_data_des, training_data_loc, training_data_net, ground_truths):\n",
    "    for epoch in range(0,30):\n",
    "        model = JointDLN()\n",
    "        model.load_state_dict(torch.load(\"data/DLN_utype_2layer/joint_DLN_\"+str(epoch)+\".pt\")) \n",
    "        predictions =[]\n",
    "        for i in range (0,len(training_data_des)):\n",
    "            prediction_joint = model(training_data_des[i], training_data_loc[i], training_data_net[i])\n",
    "            pred = torch.argmax(prediction_joint, dim=1)\n",
    "            predictions.append(pred.item())\n",
    "        #accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /10\n",
    "        accuracy = np.sum(np.array(predictions) == np.array(ground_truths)) /len(training_data_des)\n",
    "        macro_f1 = f1_score(ground_truths, predictions, average='macro')\n",
    "        print('epoch :', epoch, 'Testing accuracy, macro_f1:', accuracy, macro_f1)\n",
    "        #return accuracy, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "########.....Load Test data.......\n",
    "with open(\"data/test.txt\", \"r\") as f:\n",
    "    data = f.read().split('\\n')\n",
    "test_data = data[:] \n",
    "#print(test_data, len(test_data)) #262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no location for user:  vaibhavatttc\n"
     ]
    }
   ],
   "source": [
    "#####prepare testing data for neural net #########\n",
    "testing_data_des, testing_data_loc =  nn_input(test_data,df)\n",
    "testing_data_net =  nn_input_network(test_data,df)\n",
    "test_gt = find_groundtruth(test_data, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "############........Calculate Validation Accuracy.......\n",
    "# test_accuracy, test_macro_f1 = make_prediction(testing_data_des, testing_data_loc, testing_data_net, test_gt)\n",
    "# print('Testing accuracy, macro_f1:', test_accuracy, test_macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 Testing accuracy, macro_f1: 0.6259541984732825 0.4674961072164388\n",
      "epoch : 1 Testing accuracy, macro_f1: 0.7290076335877863 0.6410885907317537\n",
      "epoch : 2 Testing accuracy, macro_f1: 0.767175572519084 0.7033121916842847\n",
      "epoch : 3 Testing accuracy, macro_f1: 0.7824427480916031 0.7040548422639795\n",
      "epoch : 4 Testing accuracy, macro_f1: 0.7862595419847328 0.7145969270077792\n",
      "epoch : 5 Testing accuracy, macro_f1: 0.7824427480916031 0.7085608234676558\n",
      "epoch : 6 Testing accuracy, macro_f1: 0.7709923664122137 0.7096887510273336\n",
      "epoch : 7 Testing accuracy, macro_f1: 0.7709923664122137 0.7073161120832717\n",
      "epoch : 8 Testing accuracy, macro_f1: 0.7748091603053435 0.7150227373334944\n",
      "epoch : 9 Testing accuracy, macro_f1: 0.7633587786259542 0.7051285455672643\n",
      "epoch : 10 Testing accuracy, macro_f1: 0.7709923664122137 0.7160349646571076\n",
      "epoch : 11 Testing accuracy, macro_f1: 0.7709923664122137 0.7160152128573182\n",
      "epoch : 12 Testing accuracy, macro_f1: 0.7748091603053435 0.7193338554823812\n",
      "epoch : 13 Testing accuracy, macro_f1: 0.7748091603053435 0.7193338554823812\n",
      "epoch : 14 Testing accuracy, macro_f1: 0.7709923664122137 0.7160152128573182\n",
      "epoch : 15 Testing accuracy, macro_f1: 0.7748091603053435 0.723437249224078\n",
      "epoch : 16 Testing accuracy, macro_f1: 0.7748091603053435 0.723437249224078\n",
      "epoch : 17 Testing accuracy, macro_f1: 0.7709923664122137 0.7207171148634562\n",
      "epoch : 18 Testing accuracy, macro_f1: 0.7748091603053435 0.7252818370401188\n",
      "epoch : 19 Testing accuracy, macro_f1: 0.7709923664122137 0.7219741661846926\n",
      "epoch : 20 Testing accuracy, macro_f1: 0.7748091603053435 0.7292852024404524\n",
      "epoch : 21 Testing accuracy, macro_f1: 0.7709923664122137 0.7246480417699604\n",
      "epoch : 22 Testing accuracy, macro_f1: 0.767175572519084 0.7200512752008877\n",
      "epoch : 23 Testing accuracy, macro_f1: 0.7709923664122137 0.727124078001271\n",
      "epoch : 24 Testing accuracy, macro_f1: 0.7748091603053435 0.7340662475450666\n",
      "epoch : 25 Testing accuracy, macro_f1: 0.7709923664122137 0.7294145906217633\n",
      "epoch : 26 Testing accuracy, macro_f1: 0.7709923664122137 0.7294145906217633\n",
      "epoch : 27 Testing accuracy, macro_f1: 0.7709923664122137 0.7294145906217633\n",
      "epoch : 28 Testing accuracy, macro_f1: 0.7709923664122137 0.7294145906217633\n",
      "epoch : 29 Testing accuracy, macro_f1: 0.7709923664122137 0.7294677624084841\n"
     ]
    }
   ],
   "source": [
    "make_prediction(testing_data_des, testing_data_loc, testing_data_net, test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
